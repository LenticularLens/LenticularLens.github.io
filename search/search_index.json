{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"The Lenticular Lens Documentation A platform for addressing various aspects of the disambiguation of Entities . These aspects include the creation , manipulation , validation , provenance and visualisation of links. Developped in the context of RISIS & the Golden Agents project \u00b6 Work in progress At present, this documentation is not fully in the image of current Lenticular Lens . However, the currently work in progress UI is meant to be inline with the documentation. \u00b6","title":"Home"},{"location":"#the-lenticular-lens-documentation-a-platform-for-addressing-various-aspects-of-the-disambiguation-of-entities-these-aspects-include-the-creation-manipulation-validation-provenance-and-visualisation-of-links-developped-in-the-context-of-risis-the-golden-agents-project","text":"Work in progress","title":" The Lenticular Lens Documentation  A platform for addressing various aspects of the  disambiguation of Entities .  These aspects include the creation,  manipulation,  validation,  provenance and  visualisation  of links.  Developped in the context of RISIS &amp; the Golden Agents project"},{"location":"#at-present-this-documentation-is-not-fully-in-the-image-of-current-lenticular-lens-however-the-currently-work-in-progress-ui-is-meant-to-be-inline-with-the-documentation","text":"","title":" At present, this documentation is not fully in the image of current Lenticular Lens. However, the currently work in progress UI is meant to be inline with the documentation. "},{"location":"01.Introduction/","text":"INTRODUCTION \u00b6 Time and again, researchers are presented with problems for which they postulate and test hypotheses in order to provide us with robust explanations for research questions successfully investigated. Often enough, solid explanations for complex problems require exploring a multitude of datasources. This is the case, for example, in domains such as e-science (multiple scientific datasets), e-commerce (multiple product vendors), tourism (multiple data providers), e-social science, digital humanities, etc. 1. Context \u00b6 DATA INTEGRATION. The use of various datasources come at the expense of heterogeneity which obfuscates the path to data integration and thereby hinders accurately addressing complex problems. Dealing with multiple datasources or data providers highlights the freedom at which providers document facets of the same entity. Indeed, this feature of oriented freedom for entity descriptions can explain, to a certain extent, the inherent difficulty to integrate heterogeneous datasources. In the Semantic Web, this problem is partially circumvented as any pair of resources can be linked regardless to the uniformity of data representation or vocabulary used, i.e. uniformizing data/schema is not a prerequisite for data integration provided that links between co-referent entities across heterogeneous datasets exist. RESULT QUALITY. The quality of supporting evidence for accepting or rejecting the hypothesis under investigation for a complex problem greatly depends on the correctness of the links integrating the underlying datasources. This begs for questions regarding the aboutness and correctness of the links, such as: How to create correct links? More specifically, are there reliable tools or macthing algorithms for linking co-referent descriptions of entity scattered across various heterogeneous datasets? Can different tools or algorithms be combined? How to judge the applicability of links? Can their quality be estimated? Can they be improved, manipulated, visualised for validation purposes, reproduced? More specifically, is there a platform that supports all of the aforementioned concerns? LINK CONSTRUCTION. Through the years, a number of entity matching tools have been developed and tested. However, some of theses tools have been developed for specific datasets, while others have limited applicability as they have mainly been tested in domain specific areas using synthetic or simplistic data, generally from at most two datasets. For example, as research in social sciences is increasingly based on multiple heterogeneous datasources, it becomes problematic to be limited to the integration of two datasets. Furthermore, in practice, the heterogeneity, messiness, incompleteness of data raise the bar higher in terms of entity matching complexity. In other words, most matching algorithms have been successfully applied in limited and controlled environments. This motivates the need for having the means to (re)use and combine generic matching approaches in order to solve specific problems. ENTITY DISAMBIGUATION PROPOSAL. In this document, we present a tool that supports disambiguation over multiple datasets: the Lenticular Lens . As a domain agnostic approach, the Lenticular Lens tool reuses existing matching approaches to allow for the user to reach their goals in ways that alleviates some of the main aforementioned issues: User-dependent and context-specific link discovery. User-based explicit concept mapping. Integration of more than two datasets. Combining entity matching algorithms and results. Structure-based evaluation of identity link networks. Enabling visualisation to support link/cluster validation. Metadata for documenting the link aboutness and enabling reproducibility. The context dependent link discovery idea developed and implemented in the Lenticular Lens [ Idrissou 2017 , 2018 , 2019 ] is an extension of the Linkset and Lens concepts introduced by the [ OpenPhacts ] project in the quests for building an infrastructure for integrating pharmacological data. Our extension and broadening of these concepts enabled us to design and build a flexible tool for undertaking entity disambiguation in a broader perspective. 2. GUI Menus \u00b6 As a preview of what can be done with the Lenticular Lens tool, we list here the main menus composing the tool and provide a brief description of what can be done in each of the menu. CONTEXT This menu aims to specify the scope of the research by giving the researcher the opportunity to remind herself and other users the why of the research. This is done by providing a title, describing the goal and possibly linking the work done in this tool to a published result. DATA This menu provides means to: Select a GraphQL endpoint so that remote datasources can be located and made available to the user. The default selection is the Golden Agent\u2019s endpoint ; Select Datasources and Entity-types from the available list at the remote location so that information can be extracted and integrated in order to conduct an experiment; Define restrictions over selected Entity-types. Explore data based on pre-defined specifications (Datasource, Entity-type and Property-value Restrictions). LINKSET This menu provides means to: Specify the conditions in which to use a matching method or combined matching methods for the creation of a LINKSET, which is a set of links sharing the same specifications. Run the specification i.e create set of links and clusters. Get statistics on the result such as the total number of links found, how they cluster\u2026 Validate the resulting links by annotating them with flags such as accept or reject. Export the result in various format. LENS This menu provides means to: Specify the conditions in which to combine LINKSET(S) and/or LENS(ES) for the creation of a new LENS, specifically, the use of set like operations (Union, Intersection, Difference, Composition and In-Set) over linksets and lenses. Run the specification i.e combine Linkset(s) and/or Lens(es) and cluster the links. Get statistics on the result such as the total number of links found, how they cluster\u2026 Visualise and Validate the resulting links by annotating them with flags such as accept or reject. Export the result in various format. DATA INTEGRATION The menu here enables the user to materialise an entity-based integration of her selected datasources for the extraction of information vital to her analysis. The rest of the manual will first discuss Terminology Link Annotation Ontology Algorithms Link Construction (it includes the RESEARCH , DATA and CREATE options) Link Manipulation (it includes the MANIPULATE , and VALIDATION options) Link Export (it is about the EXPORT option) and Data Integration (it is about the EXTRACT option)","title":"1. Introduction"},{"location":"01.Introduction/#introduction","text":"Time and again, researchers are presented with problems for which they postulate and test hypotheses in order to provide us with robust explanations for research questions successfully investigated. Often enough, solid explanations for complex problems require exploring a multitude of datasources. This is the case, for example, in domains such as e-science (multiple scientific datasets), e-commerce (multiple product vendors), tourism (multiple data providers), e-social science, digital humanities, etc.","title":"INTRODUCTION"},{"location":"01.Introduction/#1-context","text":"DATA INTEGRATION. The use of various datasources come at the expense of heterogeneity which obfuscates the path to data integration and thereby hinders accurately addressing complex problems. Dealing with multiple datasources or data providers highlights the freedom at which providers document facets of the same entity. Indeed, this feature of oriented freedom for entity descriptions can explain, to a certain extent, the inherent difficulty to integrate heterogeneous datasources. In the Semantic Web, this problem is partially circumvented as any pair of resources can be linked regardless to the uniformity of data representation or vocabulary used, i.e. uniformizing data/schema is not a prerequisite for data integration provided that links between co-referent entities across heterogeneous datasets exist. RESULT QUALITY. The quality of supporting evidence for accepting or rejecting the hypothesis under investigation for a complex problem greatly depends on the correctness of the links integrating the underlying datasources. This begs for questions regarding the aboutness and correctness of the links, such as: How to create correct links? More specifically, are there reliable tools or macthing algorithms for linking co-referent descriptions of entity scattered across various heterogeneous datasets? Can different tools or algorithms be combined? How to judge the applicability of links? Can their quality be estimated? Can they be improved, manipulated, visualised for validation purposes, reproduced? More specifically, is there a platform that supports all of the aforementioned concerns? LINK CONSTRUCTION. Through the years, a number of entity matching tools have been developed and tested. However, some of theses tools have been developed for specific datasets, while others have limited applicability as they have mainly been tested in domain specific areas using synthetic or simplistic data, generally from at most two datasets. For example, as research in social sciences is increasingly based on multiple heterogeneous datasources, it becomes problematic to be limited to the integration of two datasets. Furthermore, in practice, the heterogeneity, messiness, incompleteness of data raise the bar higher in terms of entity matching complexity. In other words, most matching algorithms have been successfully applied in limited and controlled environments. This motivates the need for having the means to (re)use and combine generic matching approaches in order to solve specific problems. ENTITY DISAMBIGUATION PROPOSAL. In this document, we present a tool that supports disambiguation over multiple datasets: the Lenticular Lens . As a domain agnostic approach, the Lenticular Lens tool reuses existing matching approaches to allow for the user to reach their goals in ways that alleviates some of the main aforementioned issues: User-dependent and context-specific link discovery. User-based explicit concept mapping. Integration of more than two datasets. Combining entity matching algorithms and results. Structure-based evaluation of identity link networks. Enabling visualisation to support link/cluster validation. Metadata for documenting the link aboutness and enabling reproducibility. The context dependent link discovery idea developed and implemented in the Lenticular Lens [ Idrissou 2017 , 2018 , 2019 ] is an extension of the Linkset and Lens concepts introduced by the [ OpenPhacts ] project in the quests for building an infrastructure for integrating pharmacological data. Our extension and broadening of these concepts enabled us to design and build a flexible tool for undertaking entity disambiguation in a broader perspective.","title":"1. Context"},{"location":"01.Introduction/#2-gui-menus","text":"As a preview of what can be done with the Lenticular Lens tool, we list here the main menus composing the tool and provide a brief description of what can be done in each of the menu. CONTEXT This menu aims to specify the scope of the research by giving the researcher the opportunity to remind herself and other users the why of the research. This is done by providing a title, describing the goal and possibly linking the work done in this tool to a published result. DATA This menu provides means to: Select a GraphQL endpoint so that remote datasources can be located and made available to the user. The default selection is the Golden Agent\u2019s endpoint ; Select Datasources and Entity-types from the available list at the remote location so that information can be extracted and integrated in order to conduct an experiment; Define restrictions over selected Entity-types. Explore data based on pre-defined specifications (Datasource, Entity-type and Property-value Restrictions). LINKSET This menu provides means to: Specify the conditions in which to use a matching method or combined matching methods for the creation of a LINKSET, which is a set of links sharing the same specifications. Run the specification i.e create set of links and clusters. Get statistics on the result such as the total number of links found, how they cluster\u2026 Validate the resulting links by annotating them with flags such as accept or reject. Export the result in various format. LENS This menu provides means to: Specify the conditions in which to combine LINKSET(S) and/or LENS(ES) for the creation of a new LENS, specifically, the use of set like operations (Union, Intersection, Difference, Composition and In-Set) over linksets and lenses. Run the specification i.e combine Linkset(s) and/or Lens(es) and cluster the links. Get statistics on the result such as the total number of links found, how they cluster\u2026 Visualise and Validate the resulting links by annotating them with flags such as accept or reject. Export the result in various format. DATA INTEGRATION The menu here enables the user to materialise an entity-based integration of her selected datasources for the extraction of information vital to her analysis. The rest of the manual will first discuss Terminology Link Annotation Ontology Algorithms Link Construction (it includes the RESEARCH , DATA and CREATE options) Link Manipulation (it includes the MANIPULATE , and VALIDATION options) Link Export (it is about the EXPORT option) and Data Integration (it is about the EXTRACT option)","title":"2. GUI Menus"},{"location":"02.Terminology/","text":".katex img { display: block; position: absolute; width: 100%; height: inherit; } TERMINOLOGY \u00b6 Before diving into how to use the Lenticular Lens , we define a number of terms we believe to be important for a better comprehension of what is offered by the tool. For some of the concepts defined here, we opt for a broader scope which fits best problems encounter in every day life . RDF \u00b6 As described by the W3C , RDF is a graph-based data model for interchanging data on the Web and it stands for Resource Description Framework. In other words, Lexico , the Oxford supported dictionary, emphasises on the semantic aspect by defining it as a model for encoding semantic relationships between items of data so that these relationships can be interpreted computationally . Expressing a relationship between a pair of RDF resources is done as a sequence of three terms \u27e8 subject relation object . \u27e9 \\lang \\text{subject relation object .}\\rang \u27e8 subject relation object . \u27e9 . The sequence of terms is called a triple where each of its terms is separated by whitespace and the sequence is terminated by \u2019.\u2019 . The example below illustrates two simple triple syntax. The triples, not only do they provid Spiderman\u2019s mane and assert that Spiderman and Peter Parker are the same, but they also provid identification for Spiderman , Peter Parker and the vocabulary terms name and sameAs . In RDF, any triple is an RDF STATEMENT . There exist various syntaxes for representing triple statements. For further reading, see N-Triples , Notation3 , N-Quads , Turtle , RDF XML , RDFa , JSON-LD \u2026 Example 1 : Triples in N-TRIPLE syntax <http://example.org/hero#Spiderman> <http://xmlns.com/foaf/0.1/name> \"Peter-Parker\" . <http://example.org/hero#Spiderman> <http://www.w3.org/2002/07/owl#sameAs> <http://example.org/person#Peter-Parker> . Example 2 : Triples in Turtle syntax @prefix ex: <http://example.org/#> . @prefix rel: <http://www.perceive.net/schemas/relationship/> . ex: green-goblin rel: enemyOf ex: Spiderman . ex: spiderman foaf: name ex: Peter-Parker . Resource \u00b6 \u201cAnything can be a resource, including physical things, documents, abstract concepts, numbers and strings.\u201d RDF 1.1 Referents \u00b6 IRI - URI - URL - URN constitute ways in which things (resources) in the real world can be referred to in the digital world. \u201cThe resource denoted by an IRI is called its referent , and the resource denoted by a literal is called its literal value.\u201d RDF 1.1 . In the IRI example provided below, we illustrate six IRIs referents of resources of various types (hero, villain and vocabulary). Example 3 : IRIs A resource's REFERENT is an IRI. A resource's LITERAL VALUE is a LITERAL. http://example.org/villain#Green-Goblin http://example.org/villain#Thanos http://example.org/hero#Spiderman http://example.org/person#Peter-Parker http://www.perceive.net/schemas/relationship/enemyOf http://xmlns.com/foaf/0.1/name Fusion provides nice wording of all these terms as provided below. In short, URL, URN and URI are all specific types of an IRI. URI \u00b6 \u201cA Uniform Resource Identifier is a compact sequence of characters that identifies an abstract or physical resource. The set of characters is limited to US-ASCII excluding some reserved characters ( ; / ? : @ = & ). Characters outside the set of allowed characters can be represented using Percent-Encoding. A URI can be used as a locator , a name , or both. If a URI is a locator, it describes a resource\u2019s primary access mechanism. If a URI is a name, it identifies a resource by giving it a unique name. The exact specifications of syntax and semantics of a URI depend on the used Scheme that is defined by the characters before the first colon. [ RFC3986 ]\u201d URN \u00b6 \u201cA Uniform Resource Name is a URI in the scheme urn intended to serve as persistent, location-independent, resource identifier. Historically, the term also referred to any URI. [RFC3986] A URN consists of a Namespace Identifier (NID) and a Namespace Specific String (NSS): urn: : The syntax and semantics of the NSS is specific for each NID. Beside the registered NIDs, there exist several more NIDs, that did not go through the official registration process. [ RFC2141 ]\u201d URL \u00b6 \u201cA Uniform Resource Locator is a URI that, in addition to identifying a resource, provides a means of locating the resource by describing its primary access mechanism [RFC3986]. As there is no exact definition of URL by means of a set of Schemes, URL is a useful but informal concept, usually referring to a subset of URIs that do not contain URNs [ RFC3305 ].\u201d IRI \u00b6 \u201cAn Internationalized Resource Identifier is defined similarly to a URI, but the character set is extended to the Universal Coded Character Set. Therefore, it can contain any Latin and non Latin characters except the reserved characters. Instead of extending the definition of URI, the term IRI was introduced to allow for a clear distinction and avoid incompatibilities. IRIs are meant to replace URIs in identifying resources in situations where the Universal Coded Character Set is supported. By definition, every URI is an IRI. Furthermore, there is a defined surjective mapping of IRIs to URIs: Every IRI can be mapped to exactly one URI, but different IRIs might map to the same URI. Therefore, the conversion back from a URI to an IRI may not produce the original IRI. [ RFC3987 ]\u201d RDF Link \u00b6 It is also known as a correspondent triple [ Euzenat2013 ] or simply link in RDF and [ VoID ]. Links are triples in the form of \u27e8 subject relation object . \u27e9 \\lang \\text{subject relation object .}\\rang \u27e8 subject relation object . \u27e9 and are meant to exist only between two datasets. However, beside the incentive for providers to link their data to existing datasets, we do not see a good reason for a link not to exist within the same dataset. Thereby, in this document, an RDF link is a relation between two resources ( digital representations of entities presented as IRIs ) regardless of the datasource they stem from. This means that a link can involve a minimum of one dataset and a maximum of two. Identity Link \u00b6 An equality relation between two resources ( digital representations of the same real world entity presented as URIs ) regardless of the datasource they stem from. In this document we often use the term link to denote identity link unless otherwise stated. Mainly described using the predicate owl:sameAs , such encoded semantic relationship entails full equality between two resources. This semantic interpretation applies independently of context even though in real life problems, the equality between resources may depend not only on their intrinsic properties but also on the purpose or task for which they are used. In this regard, we present in the Export menu section the Lenticular Lens approach on the use and documentation of identity links in practice. Identity Link Network \u00b6 A set of co-referent entities regardless of the data they stem from. This can also be viewed as an Identity Cluster or Identity Network of co-referent entities. Link Validation \u00b6 The process of accepting or rejecting a link. This process is documented with the validation status (accepted or rejected) of the link and the supporting reasons. Named-graph \u00b6 According to Wikipedia , named graphs are a key concept of Semantic Web architecture in which a set of Resource Description Framework statements (a graph) are identified using a IRI, allowing descriptions to be made of that set of statements such as context, provenance information or other such metadata. Example 4 : Named-graph The example below illustrates a turtle named graph syntax of a linkset of three links using the owl:sameAs linktype. In the example, http://example.org/#linkset-1 is the IRI of the named graph. For more detail on Turtle RDF syntax, See https://www.w3.org/TR/turtle/#simple-triples . In this page, EXAMPLE 9 illustrates different ways of writing triples in Turtle. @base <http://example.org/> . @prefix ex: <http://example.org/#> . @prefix owl: <http://www.w3.org/2002/07/owl#> . @prefix foaf: <http://xmlns.com/foaf/0.1/> . @prefix sim: <http://purl.org/ontology/similarity/> . ex: linkset-1 { ex: Chiara owl: sameAs ex: Latronico . ex: Al owl: sameAs ex: Al_Idrissou . ex: Al owl: sameAs ex: Al_Koudous . } Default Graph \u00b6 In a triple-store jargon, any triple without a specific named-graph ends up in the default graph . In the example below, the triple at line 4 is located in the default graph while triples at line 8 and 9 are in an explicitly stated graph , in the named-graph: ex:linkset-1. Example 5 : Default Named-graph @prefix ex: <http://example.org/#> . @prefix owl: <http://www.w3.org/2002/07/owl#> . ex: Chiara owl: sameAs ex: Latronico . ex: graph-1 { ex: Al owl: sameAs ex: Al_Idrissou . ex: Al owl: sameAs ex: Al_Koudous . } Linkset \u00b6 In [ VoID ], a linkset is a collection of RDF links between two datasets where all subjects stem from one dataset and all objects from the other dataset. In here, we alleviate such strict restriction on the number of linked datasets to be one , two or more . Therefore, here a linkset is a collection of RDF links between dataset(s) , using the same link predicate (regardless of the link being an equality predicate or not). This predicate is called the linktype of the linkset. Lens \u00b6 Content-wise , a lens is a type of RDF linkset (in the sense that it is a collection of links sharing the same linktype) also involving one, two or more datasets. However, context-wise , it differs from a linkset as it is generated using different process (set-like link manipulation operators such as Union, Intersection, Difference or Transitivity) as compared to how a linkset comes about (matching algorithms). Linkset / Lens Specification \u00b6 In the Lenticular Lens , a Linkset / Lens specification can be viewed as a reproducibility metadata. It provides information on how set of links came to be. In other worlds, it explicitly defines the context in which a link hold and supports decisions making during the validation process (accepting or rejecting a link). Matching Algorithm \u00b6 A set of rules followed by a computer for finding pairs of matching resources. An algorithm can be further categorised as automated or semi-automated depending on whether it requires user assistance or not. Most matching algorithms employed in the Lenticular Lens are semi-automated. Triple Store \u00b6 OWL/DL \u00b6 Turtle Prefixes \u00b6 Example 6 : Prefixes used in this manual. Below are the prefixes used in this document @prefix A: <http://example.org/A#> . @prefix B: <http://example.org/B#> . @prefix C: <http://example.org/C#> . @prefix dataset: <http://example.org/dataset#> . @prefix dcterms: <http://purl.org/dc/terms/> . @prefix ex: <http://example.org/#> . @prefix foaf: <http://xmlns.com/foaf/0.1/> . @prefix format: <http://www.w3.org/ns/formats/> . @prefix grid: <http://www.grid.ac/ontology/> . @prefix gridC: <http://vivoweb.org/ontology/core#> . @prefix hero: <http://example.org/hero#> . @prefix institutes: <http://www.grid.ac/institutes/> . @prefix law: <http://www.opendatacommons.org/> @prefix owl: <http://www.w3.org/2002/07/owl#> . @prefix person: <http://example.org/person#> . @prefix prov: <http://www.w3.org/ns/prov#> . @prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> . @prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> @prefix rel: <http://www.perceive.net/schemas/relationship/> . @prefix sim: <http://purl.org/ontology/similarity/> . @prefix singleton: <http://lenticularlens.org/singleton#> @prefix void: <http://rdfs.org/ns/void#> . @prefix voidPlus: <http://lenticularlens.org/voidPlus#> . @prefix validation: <http://vocabulary/validation#> . @prefix wiki: <http://en.wikipedia.org/wiki/> @prefix wikidata: <http://www.wikidata.org/entity/> .","title":"2. Terminology"},{"location":"02.Terminology/#terminology","text":"Before diving into how to use the Lenticular Lens , we define a number of terms we believe to be important for a better comprehension of what is offered by the tool. For some of the concepts defined here, we opt for a broader scope which fits best problems encounter in every day life .","title":"TERMINOLOGY"},{"location":"02.Terminology/#rdf","text":"As described by the W3C , RDF is a graph-based data model for interchanging data on the Web and it stands for Resource Description Framework. In other words, Lexico , the Oxford supported dictionary, emphasises on the semantic aspect by defining it as a model for encoding semantic relationships between items of data so that these relationships can be interpreted computationally . Expressing a relationship between a pair of RDF resources is done as a sequence of three terms \u27e8 subject relation object . \u27e9 \\lang \\text{subject relation object .}\\rang \u27e8 subject relation object . \u27e9 . The sequence of terms is called a triple where each of its terms is separated by whitespace and the sequence is terminated by \u2019.\u2019 . The example below illustrates two simple triple syntax. The triples, not only do they provid Spiderman\u2019s mane and assert that Spiderman and Peter Parker are the same, but they also provid identification for Spiderman , Peter Parker and the vocabulary terms name and sameAs . In RDF, any triple is an RDF STATEMENT . There exist various syntaxes for representing triple statements. For further reading, see N-Triples , Notation3 , N-Quads , Turtle , RDF XML , RDFa , JSON-LD \u2026 Example 1 : Triples in N-TRIPLE syntax <http://example.org/hero#Spiderman> <http://xmlns.com/foaf/0.1/name> \"Peter-Parker\" . <http://example.org/hero#Spiderman> <http://www.w3.org/2002/07/owl#sameAs> <http://example.org/person#Peter-Parker> . Example 2 : Triples in Turtle syntax @prefix ex: <http://example.org/#> . @prefix rel: <http://www.perceive.net/schemas/relationship/> . ex: green-goblin rel: enemyOf ex: Spiderman . ex: spiderman foaf: name ex: Peter-Parker .","title":"RDF"},{"location":"02.Terminology/#resource","text":"\u201cAnything can be a resource, including physical things, documents, abstract concepts, numbers and strings.\u201d RDF 1.1","title":"Resource"},{"location":"02.Terminology/#referents","text":"IRI - URI - URL - URN constitute ways in which things (resources) in the real world can be referred to in the digital world. \u201cThe resource denoted by an IRI is called its referent , and the resource denoted by a literal is called its literal value.\u201d RDF 1.1 . In the IRI example provided below, we illustrate six IRIs referents of resources of various types (hero, villain and vocabulary). Example 3 : IRIs A resource's REFERENT is an IRI. A resource's LITERAL VALUE is a LITERAL. http://example.org/villain#Green-Goblin http://example.org/villain#Thanos http://example.org/hero#Spiderman http://example.org/person#Peter-Parker http://www.perceive.net/schemas/relationship/enemyOf http://xmlns.com/foaf/0.1/name Fusion provides nice wording of all these terms as provided below. In short, URL, URN and URI are all specific types of an IRI.","title":"Referents"},{"location":"02.Terminology/#uri","text":"\u201cA Uniform Resource Identifier is a compact sequence of characters that identifies an abstract or physical resource. The set of characters is limited to US-ASCII excluding some reserved characters ( ; / ? : @ = & ). Characters outside the set of allowed characters can be represented using Percent-Encoding. A URI can be used as a locator , a name , or both. If a URI is a locator, it describes a resource\u2019s primary access mechanism. If a URI is a name, it identifies a resource by giving it a unique name. The exact specifications of syntax and semantics of a URI depend on the used Scheme that is defined by the characters before the first colon. [ RFC3986 ]\u201d","title":"URI"},{"location":"02.Terminology/#urn","text":"\u201cA Uniform Resource Name is a URI in the scheme urn intended to serve as persistent, location-independent, resource identifier. Historically, the term also referred to any URI. [RFC3986] A URN consists of a Namespace Identifier (NID) and a Namespace Specific String (NSS): urn: : The syntax and semantics of the NSS is specific for each NID. Beside the registered NIDs, there exist several more NIDs, that did not go through the official registration process. [ RFC2141 ]\u201d","title":"URN"},{"location":"02.Terminology/#url","text":"\u201cA Uniform Resource Locator is a URI that, in addition to identifying a resource, provides a means of locating the resource by describing its primary access mechanism [RFC3986]. As there is no exact definition of URL by means of a set of Schemes, URL is a useful but informal concept, usually referring to a subset of URIs that do not contain URNs [ RFC3305 ].\u201d","title":"URL"},{"location":"02.Terminology/#iri","text":"\u201cAn Internationalized Resource Identifier is defined similarly to a URI, but the character set is extended to the Universal Coded Character Set. Therefore, it can contain any Latin and non Latin characters except the reserved characters. Instead of extending the definition of URI, the term IRI was introduced to allow for a clear distinction and avoid incompatibilities. IRIs are meant to replace URIs in identifying resources in situations where the Universal Coded Character Set is supported. By definition, every URI is an IRI. Furthermore, there is a defined surjective mapping of IRIs to URIs: Every IRI can be mapped to exactly one URI, but different IRIs might map to the same URI. Therefore, the conversion back from a URI to an IRI may not produce the original IRI. [ RFC3987 ]\u201d","title":"IRI"},{"location":"02.Terminology/#rdf-link","text":"It is also known as a correspondent triple [ Euzenat2013 ] or simply link in RDF and [ VoID ]. Links are triples in the form of \u27e8 subject relation object . \u27e9 \\lang \\text{subject relation object .}\\rang \u27e8 subject relation object . \u27e9 and are meant to exist only between two datasets. However, beside the incentive for providers to link their data to existing datasets, we do not see a good reason for a link not to exist within the same dataset. Thereby, in this document, an RDF link is a relation between two resources ( digital representations of entities presented as IRIs ) regardless of the datasource they stem from. This means that a link can involve a minimum of one dataset and a maximum of two.","title":"RDF Link"},{"location":"02.Terminology/#identity-link","text":"An equality relation between two resources ( digital representations of the same real world entity presented as URIs ) regardless of the datasource they stem from. In this document we often use the term link to denote identity link unless otherwise stated. Mainly described using the predicate owl:sameAs , such encoded semantic relationship entails full equality between two resources. This semantic interpretation applies independently of context even though in real life problems, the equality between resources may depend not only on their intrinsic properties but also on the purpose or task for which they are used. In this regard, we present in the Export menu section the Lenticular Lens approach on the use and documentation of identity links in practice.","title":"Identity Link"},{"location":"02.Terminology/#identity-link-network","text":"A set of co-referent entities regardless of the data they stem from. This can also be viewed as an Identity Cluster or Identity Network of co-referent entities.","title":"Identity Link Network"},{"location":"02.Terminology/#link-validation","text":"The process of accepting or rejecting a link. This process is documented with the validation status (accepted or rejected) of the link and the supporting reasons.","title":"Link Validation"},{"location":"02.Terminology/#named-graph","text":"According to Wikipedia , named graphs are a key concept of Semantic Web architecture in which a set of Resource Description Framework statements (a graph) are identified using a IRI, allowing descriptions to be made of that set of statements such as context, provenance information or other such metadata. Example 4 : Named-graph The example below illustrates a turtle named graph syntax of a linkset of three links using the owl:sameAs linktype. In the example, http://example.org/#linkset-1 is the IRI of the named graph. For more detail on Turtle RDF syntax, See https://www.w3.org/TR/turtle/#simple-triples . In this page, EXAMPLE 9 illustrates different ways of writing triples in Turtle. @base <http://example.org/> . @prefix ex: <http://example.org/#> . @prefix owl: <http://www.w3.org/2002/07/owl#> . @prefix foaf: <http://xmlns.com/foaf/0.1/> . @prefix sim: <http://purl.org/ontology/similarity/> . ex: linkset-1 { ex: Chiara owl: sameAs ex: Latronico . ex: Al owl: sameAs ex: Al_Idrissou . ex: Al owl: sameAs ex: Al_Koudous . }","title":"Named-graph"},{"location":"02.Terminology/#default-graph","text":"In a triple-store jargon, any triple without a specific named-graph ends up in the default graph . In the example below, the triple at line 4 is located in the default graph while triples at line 8 and 9 are in an explicitly stated graph , in the named-graph: ex:linkset-1. Example 5 : Default Named-graph @prefix ex: <http://example.org/#> . @prefix owl: <http://www.w3.org/2002/07/owl#> . ex: Chiara owl: sameAs ex: Latronico . ex: graph-1 { ex: Al owl: sameAs ex: Al_Idrissou . ex: Al owl: sameAs ex: Al_Koudous . }","title":"Default Graph"},{"location":"02.Terminology/#linkset","text":"In [ VoID ], a linkset is a collection of RDF links between two datasets where all subjects stem from one dataset and all objects from the other dataset. In here, we alleviate such strict restriction on the number of linked datasets to be one , two or more . Therefore, here a linkset is a collection of RDF links between dataset(s) , using the same link predicate (regardless of the link being an equality predicate or not). This predicate is called the linktype of the linkset.","title":"Linkset"},{"location":"02.Terminology/#lens","text":"Content-wise , a lens is a type of RDF linkset (in the sense that it is a collection of links sharing the same linktype) also involving one, two or more datasets. However, context-wise , it differs from a linkset as it is generated using different process (set-like link manipulation operators such as Union, Intersection, Difference or Transitivity) as compared to how a linkset comes about (matching algorithms).","title":"Lens"},{"location":"02.Terminology/#linkset-lens-specification","text":"In the Lenticular Lens , a Linkset / Lens specification can be viewed as a reproducibility metadata. It provides information on how set of links came to be. In other worlds, it explicitly defines the context in which a link hold and supports decisions making during the validation process (accepting or rejecting a link).","title":"Linkset / Lens Specification"},{"location":"02.Terminology/#matching-algorithm","text":"A set of rules followed by a computer for finding pairs of matching resources. An algorithm can be further categorised as automated or semi-automated depending on whether it requires user assistance or not. Most matching algorithms employed in the Lenticular Lens are semi-automated.","title":"Matching Algorithm"},{"location":"02.Terminology/#triple-store","text":"","title":"Triple Store"},{"location":"02.Terminology/#owldl","text":"","title":"OWL/DL"},{"location":"02.Terminology/#turtle-prefixes","text":"Example 6 : Prefixes used in this manual. Below are the prefixes used in this document @prefix A: <http://example.org/A#> . @prefix B: <http://example.org/B#> . @prefix C: <http://example.org/C#> . @prefix dataset: <http://example.org/dataset#> . @prefix dcterms: <http://purl.org/dc/terms/> . @prefix ex: <http://example.org/#> . @prefix foaf: <http://xmlns.com/foaf/0.1/> . @prefix format: <http://www.w3.org/ns/formats/> . @prefix grid: <http://www.grid.ac/ontology/> . @prefix gridC: <http://vivoweb.org/ontology/core#> . @prefix hero: <http://example.org/hero#> . @prefix institutes: <http://www.grid.ac/institutes/> . @prefix law: <http://www.opendatacommons.org/> @prefix owl: <http://www.w3.org/2002/07/owl#> . @prefix person: <http://example.org/person#> . @prefix prov: <http://www.w3.org/ns/prov#> . @prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> . @prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> @prefix rel: <http://www.perceive.net/schemas/relationship/> . @prefix sim: <http://purl.org/ontology/similarity/> . @prefix singleton: <http://lenticularlens.org/singleton#> @prefix void: <http://rdfs.org/ns/void#> . @prefix voidPlus: <http://lenticularlens.org/voidPlus#> . @prefix validation: <http://vocabulary/validation#> . @prefix wiki: <http://en.wikipedia.org/wiki/> @prefix wikidata: <http://www.wikidata.org/entity/> .","title":"Turtle Prefixes"},{"location":"03.Ontology%20copy%202/","text":"ONTOLOGY \u00b6 This section presents an Ontology meant for describing processes of generation and validation of links in detail, so that decisions made such as resource selections and matching options are made explicit. Those processes are implemented in the Lenticular Lens tool and result in the creation of Linksets or Lenses according to a specification. we call the proposed ontology VoID+ as it is proposed as an extension of the [ VoID ] vocabulary. The next section presents the motivation for such extension while Section 3.2 and Section 3.3 respectively present the main elements proposed as extension for VoID and the complete and detailed description of the VoID+ extension. 1. Motivation to extend VoID \u00b6 The model presented in Figure 1 is created based on the [ VoID ] documentation and owl-ontology description, where ellipses represent classes, thick arrows represent subclass or sub-property relations (hierarchy) and thin arrows represent properties. In this model, only classes and relations of interest are exhibit. The [ VoID ] vocabulary provides means to describe datasets and linksets, but with limitations. The first important limitation that motivates our proposal for extension is that void:Linkset is (1) too restrictive as it is directed and holds between exactly two non-identical datasets. Furthermore, (2) it also does not describe the details of how they were generated, nor it provides means to describe Lenses or Validations . The next limitation is (3) the ambiguate descriptions of subsets or partitions of a void:Dataset . This concept is in our theory very important and requires more clarity and expressivity. Those issues are further discussed in the next section. Fig 1: Excerpt of VoId Ontology regarding void:Dataset and void:Linkset. A description of the classes and properties exhibited in Fig 1 is available in the table below. Vocabulary Description void:Dataset A set of RDF triples that are published, maintained or aggregated by a single provider. void:Linkset A collection of RDF links between two void:Datasets. void:subset has subset. Domain : void:Dataset Range : void:Dataset void:classPartition A relation between a void:Dataset and its Partition, which is a subset of a void:Dataset that contains only entities of an explicitly defined rdfs:Class. Domain : void:Dataset Range : void:Dataset void:propertyPartition A relation between a void:Dataset and its Partition, which is a subset of a void:Dataset that contains only triples composed with an explicitly defined rdf:Property. Domain : void:Dataset Range : void:Dataset void:class A relation that assigns to a void:Dataset a rdfs:Class that is the rdf:type of all entities (subject) in a class-based partition. Domain : void:Dataset Range : rdfs:Class ( exactly 1 ) void:property A relation that assigns to a void:Dataset a rdf:Property that is the predicate of all triples in a property-based partition. Domain : void:Dataset Range : rdfs:Property ( exactly 1 ) void:target A relation that assigns one of the two datasets linked by the Linkset. Domain : void:Linkset Range : void:Dataset ( exactly 2 ) void:subjectsTarget A relation that assigns the dataset describing the subjects of triples contained in the Linkset. Domain : void:Linkset Range : void:Dataset ( exactly 1 ) void:objectsTarget A relation that assigns the dataset describing the objects of the triples contained in the Linkset. Domain : void:Linkset Range : void:Dataset ( exactly 1 ) 2. VoID+ Main Elements \u00b6 This section presents the main elements proposed as extension for VoID . It provides a simplified overview (Fig. 2) of VoID+ by (i) only describing the classes and properties that are of importance in this work and (ii) omitting hierarchical relations among classes. While the complete and detailed description of the VoID+ extension is provided in the next section, the complete ontology overview (figure) and the documentation extracted from the owl file are available in section 3.4. Fig 2: The Lenticular Lens Ontology The partial model of the simplified oberverview depicted in Fig. 2 highlights in yellow the use of [ VoID ] terms and in blue the new VoID+ terminology . In order to describe the proposed ontology, we dissect Fig 2 into four parts. First, a Resource Selection is elucidated. Second, we go about describing a Matching Formulation and show how it connects with a Resource Selection . The third step highlights that the description of a Linkset metadata involves specifying the Resource Selections used at the source and target positions of an entity matching process, the Matching Formulation , eventual validations plus statistics and authority information. The fourth and final step focuses on the annotation of a Lens by describing the combination of one or more Linksets and/or Lenses. 2.1 Resource Selection \u00b6 This step concerns the selection of the resources under scrutiny , that can potentially end up co-referent entities across or within datasources during an entity matching process. To therefore perform a matching, one first needs not only to select datasource(s) but also restrict which resources will undergo the matching. The first way of doing so is by applying a type (class) restriction. This is mandatory in the Lenticular Lens process as matching algorithms are not fully automated. Down this line, further restrictions can be applied by forcing the value of a number of properties to lie within a certain range. A Resource Selection is thereby, the annotation of such process. In the ontology excerpt depicted in Figure 3 we propose the entity type Resource Selection , which is also a void:Dataset that is a void:subset of one or more void:Dataset(s) . It can also have further restrictions defined as void:classPartion and/or void:propertyPartition . While a void:classPartion solely consists in specifying the type of entity under scrutiny, the void:propertyPartition entails a little more. It consists in specifying a property or property path and a restriction that the selected property should undergo for the selection of the right entities for the further down the road entity matching process. Those restrictions can be combined using a Formula Description given by ll:hasFormulaDescription . Fig 3: Selecting a matching resource Example 1 : Resource Selection In this example, the entity resource:ResourceSelection-2 is a ll:ResourceSelection (and a void:Dataset ) subset of resource:index_op_doopregister_raw_20190830 and also a collection (partition) of entities of type pnv:PersonName where each entity passed the filter test of (1) name in the English language which appears without trailing dots \"%...%\"@en and (2) birthdates within the interval [1600, 1699] . the entity resource:ResourceSelection-2 lists all three entities of type ll:PropertyConstraint and elaborates on the logic expression that binds all restrictions. For example, the property restriction described by resource:PropertyConstraint-PHce78383e3ff6e9dd73b6 documents that, applying the date function \"minimal_date\"@en over dates in the format the \"YYYY-MM-DD\"@en with the year restriction of 1600 makes sure that only persons born on 1600 onwards are admitted. Turtle Syntax When ever a literal in RDF syntax conatins quote or new line characters, the litreal should be in a three quote syntax ( \"...\"\"@en ). In the example below, we deliberately wrote the literal value of ll:hasFormulaDescription is in a single quote ( \"...\"\"@en ) instead of a triple quote ( \"\"\"%...%=\"\"\"@en ) as the syntax highliter is somewhat buggy. ### RESOURCE 2 resource: ResourceSelection-2 a void: dataset , ll: ResourceSelection ; rdfs: label \"Baptisms in the 17th Century\" @ en ; void: subset resource: index_op_doopregister_raw_20190830 ; void: classPartition [ void: class pnv: PersonName ] ; void: propertyPartition resource: PropertyConstraint-PHea6802ef02f99a848859 ; void: propertyPartition resource: PropertyConstraint-PHce78383e3ff6e9dd73b6 ; void: propertyPartition resource: PropertyConstraint-PH2580641bbdd572759cb9 ; ll: hasFormulaDescription \" resource: PropertyConstraint-PHce78383e3ff6e9dd73b6 AND resource: PropertyConstraint-PH2580641bbdd572759cb9 AND ( resource: PropertyConstraint-PHea6802ef02f99a848859 ) \"@en . resource: PropertyConstraint-PHea6802ef02f99a848859 a ll: PropertyConstraint ; void: property [ a rdfs: Sequence ; rdf : _ 1 pnv: literalName ] ; ll: hasFilterFunction \"not_ilike\" @ en ; ll: hasValueFunction \"%...%\" @ en . resource: PropertyConstraint-PHce78383e3ff6e9dd73b6 a ll: PropertyConstraint ; void: property [ a rdfs: Sequence ; rdf : _ 1 saa: isInRecord ; rdf : _ 2 saa: IndexOpDoopregisters ; rdf : _ 3 saa: birthDate ] ; ll: hasFilterFunction \"minimal_date\" @ en ; ll: hasValueFunction 1600 ; ll: hasFormatFunction \"YYYY-MM-DD\" @ en . resource: PropertyConstraint-PH2580641bbdd572759cb9 a ll: PropertyConstraint ; void: property [ a rdfs: Sequence ; rdf : _ 1 saa: isInRecord ; rdf : _ 2 saa: IndexOpDoopregisters ; rdf : _ 3 saa: birthDate ] ; ll: hasFilterFunction \"maximum_date\" @ en ; ll: hasValueFunction \"1699\" @ en ; ll: hasFormatFunction \"YYYY-MM-DD\" @ en . 2.2 Matching Formulation \u00b6 For simple matching problems, finding co-referents can be done using a single matching algorithm (matcher). However, time and again the data reality often imposes the use of more than one matcher instead. In this latter scenario, clearly reporting on how these matchers work together for detecting co-referents is essential. A Matching Formulation entity is a resource for just doing the aforementioned, as depicted in Figure 4. Once resources of type Resource Restriction are created, one can go ahead and used them for specifying the restricted collections to be used in a particular Matching Method , which also specifies the Matching Algorithm and its parameters such as threshold, range and operrator. In the end, all Matching Methods used in a matching process are documented in the Matching Formulation resource as well as how they bind together in a logic expression given by the predicate ll:hasFormulaDescription . Fig 4: Specifying the way in which methods are logically combined Example 2 : Linkset Logic Expression In Example 2.8, the resource:PHb99da2ecd91ad533af65 is a ll:MatchingFormulation listing eight ll:MatchingMethods used for creating a linkset. They their logic combination is described as ll:hasFormulaDescription . Among the ll:MatchingMethods , the resource:TIME_DELTA-PHfdc744f6bd0ced4e283a is the only method detailes in this example, documenting the four ll:ResourceSelections involved, as well as the chosen ll:MatchingAlgorithm , namely resource:TIME_DELTA , besides the threshold (20), threshold-unit (\u201cYear\u201d@en), threshold-operator (>=) and threshold-range \u201c\u2115\u201d of the matching method. Turtle Syntax When ever a literal in RDF syntax conatins quote or new line characters, the litreal should be in a three quote syntax ( \"...\"\"@en ). In the example below, we deliberately wrote the literal value of ll:hasFormulaDescription is in a single quote ( \"...\"\"@en ) instead of a triple quote ( \"\"\"%...%=\"\"\"@en ) as the syntax highliter is somewhat buggy. ###################################################### # LINKSET LOGIC EXPRESSION # ###################################################### resource: PHb99da2ecd91ad533af65 a ll: MatchingFormulation ; ll: hasMethod resource: TIME_DELTA-PHfdc744f6bd0ced4e283a ; ll: hasMethod resource: Exact-PH6491d1db6855098a70be ; ll: hasMethod resource: LL_SOUNDEX-PH0ad3ad579d7a29347753 ; ll: hasMethod resource: BLOOTHOOFT_REDUCT-PH10433274b57dafdd1335 ; ll: hasMethod resource: Exact-PH4d4187a08c3ba4c1cf0d ; ll: hasMethod resource: TIME_DELTA-PHe40547b9d3b6381347b4 ; ll: hasMethod resource: LEVENSHTEIN_APPROX-PH10f4c17bbf933cae647f ; ll: hasMethod resource: BLOOTHOOFT_REDUCT-PH98a9575087817b951447 ; ll: hasFormulaDescription \" resource: TIME_DELTA-PHe40547b9d3b6381347b4 AND resource: TIME_DELTA-PHfdc744f6bd0ced4e283a AND ( resource: Exact-PH4d4187a08c3ba4c1cf0d OR ( resource: BLOOTHOOFT_REDUCT-PH98a9575087817b951447 AND resource: BLOOTHOOFT_REDUCT-PH10433274b57dafdd1335 ) OR ( resource: Exact-PH6491d1db6855098a70be AND ( resource: LL_SOUNDEX-PH0ad3ad579d7a29347753 AND resource: LEVENSHTEIN_APPROX-PH10f4c17bbf933cae647f ) ) ) \"@en . ###################################################### # METHOD SIGNATURES # ###################################################### ### METHOD SPECIFICATIONS TIME_DELTA resource: TIME_DELTA-PHe40547b9d3b6381347b4 a ll: MatchingMethod ; ll: hasAlgorithm resource: TIME_DELTA ; ll: hasThresholdRange \"\u2115\" ; ### SOURCE PREDICATE CONFIGURATION ll: hasSubjResourceSelection resource: ResourceSelection-PHbe38976fdf884b6c4a8e ; ll: hasSubjResourceSelection resource: ResourceSelection-PHe8fa664d04ad00aaa697 ; ### TARGET PREDICATE CONFIGURATION ll: hasObjResourceSelection resource: ResourceSelection-PH71818c17d54a8fbec22b ; ll: hasObjResourceSelection resource: ResourceSelection-PHc8a3c6e494d230b79a6b . \u2022\u2022\u2022 2.3 Linkset \u00b6 This step documents a linkset metadata including WHAT - HOW - WHEN - WHO and other processes explaining the aboutness of links. The Matching Formulation specifies HOW entities are matched and Resource Selection specifies WHAT to match as subject and object targets. Also some statistic on the matching results can be reported such as the number of links found, the numbers of entities linked, WHO created the linkset and WHEN . Finally, a Validation entity can also be specified, comprising metadata with statitics and auhtority information on the validation process. Observe that when one or more validations are provided, statistics on this matter can be included in the linkset metadata, including eventual contradictions if one validation says a link is correct while another says it is not. As discussed earlier in this section, according to the [ VoID ] documentation, the void:Linkset definition expects as datasources exactly one source and one target, different from each other. This means it is more restrictive than the ll:Linkset here proposed, since the latter also expects a linkset to contain links within a datasource or across more than two. Therefore, we do not directly reuse that concept (and its correspoding properties void:subjects/objectsTarget). Naturally, one could still use void:Linkset for other purposes, but at the risk of abusing the VoID vocabulary if its instances do not really fit the required restrictions. Moreover, a void:Linkset (i.e. a resource representing a linkset\u2019s metadata) is also not an instance of ll:Linkset since the later requires the description of the processes underlying the creation of the links, which is not the case for the first. Fig 5: Specifying the linkset\u2019s context Example 3: A linkset annotation ### LINKSET 15 linkset : 15 a ll: Linkset ; void: feature format: Turtle ; cc: attributionName \"LenticularLens\" @ en ; cc: license <http://purl.org/NET/rdflicense/W3C1.0> ; dcterms: created \"2020-09-26T09:37:23.933624\" ^^ <http://www.w3.org/2001/XMLSchema#dateTime> ; dcterms: creator \"AL IDRISSOU\" ; dcterms: creator \"GoldenAgents\" ; void: linkPredicate owl: sameAs ; rdfs: label \"Linkset 9\" @ en ; dcterms: description \"LINSET-15-9: Test Baptism against Marriage and burial with several nested methods \" @ en ; ### VOID LINKSET STATS void: entities 12580 ; ### LENTICULAR LENS LINKSET STATS ### SOURCE ENTITY TYPE SELECTION(S) ll: subjectsTarget resource: ResourceSelection-2 ; ### TARGET ENTITY TYPE SELECTION(S) ll: objectsTarget resource: ResourceSelection-1 ; ll: objectsTarget resource: ResourceSelection-3 ; ### THE LOGIC FORMULA ll: hasLogicFormulation resource: PHb6e5e320dc08d7d9dd98 . 2.4 Lens \u00b6 Another process relevant to document is the creation of Lenses. In short, a lens is the result of a set-like operation over one or more Linkset and or Lens. Therefore, the entity Lens documents them as ll:hasTarget Fig 6: Specifying the linkset\u2019s context Example 4: A lens annotation 3. VoID+ Ontology \u00b6 This section discuses the complete and detailed description of the VoID+ extension in two parts. It first addresses the void+:Partition of void:Dataset. Second, it tackles the void+:LinkDataset which is considered a special sub-types of void:Dataset. The documentation extracted from the owl file is presented in the next section. 3.1 Partitions of void:Dataset \u00b6 The VoID vocabulary defines void:Dataset as a dataset superset but does make available a granularity of subsets for refined work. VoID+ extends the void:Dataset class by distinguishes between five subsets of void:Dataset. A void:Dataset that is defined as a subset of another one is called void+:Partition . Three types of void+:Partition are distinguished according to the type of partition that is used: (i) void+:ClassPartition : the dataset is the result of an rdfs:Class based-partition; (ii) void+:PropertyPartition : the dataset is the result of a rdf:Property or by a rdf:Seq \u2013 defining a sequence of two or more of properties \u2013 partition; (iii) void+:Language : the dataset is the result of a language partition given by a standardised ISO language code. Another special type of partition is the void+:ResourceSelection . It is defined by one or more partions of the type above described, Fig. 7 provides a straightforward understanding of how the class void:Dataset is extended. On its the left hand side, Fig. 7 presents a view on the classes, their hierarchy and how they are connected via object properties. On the one hand, the property void:subset and its sub-properties are extended such that they provide a directional non-ambiguous reading. On the other and, void:class and void:property are grouped into a superclass void+:partionedBy which also includes void:language to allow for one more type of partition. In particular, void:property is extended with a more generic relation void+:property that allows for describing a sequence of properties like in a property path. Fig 7: VoID+ Extension on the void:Dataset 3.2 VoID+ Link-datasets \u00b6 Figure 8 presents on the left hand side a view on the classes, their hierarchy and how they are connected via object properties. This provides a very straightforward understanding of how the class void:Linkset is extended. It is extended with superclasses that are less restrictive with respect with its targets. First, a void+:LinkDataset is a void:Dataset that contains links that may have been stabilished among one (deduplication), two or many datasets. When the creation of void+:LinkDataset is such that imposes that subjects always belong to the same datasets as well as objects, this is called void+:DirectedLinkDataset. This is the case for both void:Linkset but also for our definition of void+:Linkset. The former, however, requires excelty one dataset as target for its subjects and onther as target for its objects. In addition, our definition of void+:Linkset is also a void+:DocumentedLinkDataset, which requires more detailed documentation, including targets described as void+:ResourceSelection (all values from) and a void+:Formulation\u2026 A void+:Lens is also a void+:DocumentedLinkDataset which has one void:LensFormulation that specifies which void:LinkDatasets are combined and how. The right hand side of Figure 8 presents a hierarchy of properties in order to provide an undestanding of how void:target and its subproperties are extended. They actually are extended with superclasses having as range not only a void:Linkset but its superclass void+:LinkDataset. Fig 8: VoID+ Extension on the void:Linkset 4. VoID+ Documentation \u00b6 Markdown documentation created by pyLODE 2.8.3 4.1 Metadata \u00b6 URI http://lenticularlens.org/voidPlus Ontology RDF RDF ( voidPlus.ttl ) 4.2 Overview \u00b6 See Figure 7 and 8 above for an overview 4.3 Classes \u00b6 ClassPartition \u00b6 Property Value URI http://lenticularlens.org/voidPlus/ClassPartition Super-classes void+:Partition DirectedLinkDataset \u00b6 Property Value URI http://lenticularlens.org/voidPlus/DirectedLinkDataset Super-classes void+:LinkDataset Sub-classes void+:Linkset void:Linkset DocumentedLinkDataset \u00b6 Property Value URI http://lenticularlens.org/voidPlus/DocumentedLinkDataset Super-classes void+:LinkDataset Sub-classes void+:Lens void+:Linkset Formulation \u00b6 Property Value URI http://lenticularlens.org/voidPlus/Formulation Sub-classes void+:LensFormulation void+:LinksetFormulation In domain of void+:hasItem In range of void+:hasFormulation Language \u00b6 Property Value URI http://lenticularlens.org/voidPlus/Language In range of void+:language LanguagePartition \u00b6 Property Value URI http://lenticularlens.org/voidPlus/LanguagePartition Super-classes void+:Partition In domain of void+:language Lens \u00b6 Property Value URI http://lenticularlens.org/voidPlus/Lens Description Content-wise, a Lens is a type of RDF linkset (in the sense that it is a collection of links sharing the same linktype) also involving one, two or more datasets. However, context-wise, it differs from a linkset as it is generated using different process (set-like link manipulation operators such as Union, Intersection, Difference or Transitivity) as compared to how a linkset comes about (matching algorithms). Super-classes void+:DocumentedLinkDataset LensFormulation \u00b6 Property Value URI http://lenticularlens.org/voidPlus/LensFormulation Super-classes void+:Formulation LinkDataset \u00b6 Property Value URI http://lenticularlens.org/voidPlus/LinkDataset Super-classes void:Dataset Sub-classes void+:DocumentedLinkDataset void+:DirectedLinkDataset In domain of void+:hasTarget Linkset \u00b6 Property Value URI http://lenticularlens.org/voidPlus/Linkset Description In [VoID], a Linkset is a collection of RDF links between two datasets where all subjects stem from one dataset and all objects from the other dataset. In here, we alleviate such strict restriction on the number of linked datasets to be one, two or more. Therefore, here a linkset is a collection of RDF links between dataset(s), using the same link predicate (regardless of the link being an equality predicate or not). This predicate is called the linktype of the linkset. Super-classes void+:DirectedLinkDataset void+:DocumentedLinkDataset LinksetFormulation \u00b6 Property Value URI http://lenticularlens.org/voidPlus/LinksetFormulation Description A LinksetFormulation is a resource that makes explicit all matching-methods involved in the creation of a Linkset and how the methods logically work jointly. Super-classes void+:Formulation MatchingAlgorithm \u00b6 Property Value URI http://lenticularlens.org/voidPlus/MatchingAlgorithm In range of void+:hasAlgorithm MatchingMethod \u00b6 Property Value URI http://lenticularlens.org/voidPlus/MatchingMethod Description A MatchingMethod is a resource that makes explicit all pre-requisites of a matching algorithm including the conditions in which the algorithm is to accept a discovered link (threshold). In domain of void+:hasAlgorithm Partition \u00b6 Property Value URI http://lenticularlens.org/voidPlus/Partition Sub-classes void+:PropertyPartition void+:ClassPartition void+:LanguagePartition In domain of void+:partitionedBy In range of void+:hasSubset PropertyPartition \u00b6 Property Value URI http://lenticularlens.org/voidPlus/PropertyPartition Super-classes void+:Partition Restrictions void:property some ( rdf:Property or rdf:Seq ) PropertySequence \u00b6 Property Value URI http://lenticularlens.org/voidPlus/PropertySequence Super-classes rdf:Seq Sub-classes void+:TypedPropertySequence ResourceSelection \u00b6 Property Value URI http://lenticularlens.org/voidPlus/ResourceSelection Description A ResourceSelection is a collection of resources stemmed from the same dataset and partitioned on the basis of a given class and optionally a number of predicates having there respective predicate-value(s) enforced within a pre-defined range. Super-classes void:Dataset Restrictions void+:hasSubset some void+:Partition void:subset some void:Dataset In range of void+:hasResourceSelection TypedPropertySequence \u00b6 Property Value URI http://lenticularlens.org/voidPlus/TypedPropertySequence Super-classes void+:PropertySequence Validation \u00b6 Property Value URI http://lenticularlens.org/voidPlus/Validation In range of void+:hasValidation Dataset \u00b6 Property Value URI http://rdfs.org/ns/void#Dataset Sub-classes void+:LinkDataset void+:ResourceSelection In domain of void:subset void+:hasSubset In range of void:subset void:target void+:hasTarget Linkset \u00b6 Property Value URI http://rdfs.org/ns/void#Linkset Super-classes void+:DirectedLinkDataset In domain of void:target void:subjectsTarget void:objectsTarget 4.4 Object Properties \u00b6 hasAlgorithm \u00b6 Property Value URI http://lenticularlens.org/voidPlus/hasAlgorithm Domain(s) void+:MatchingMethod Range(s) void+:MatchingAlgorithm hasClassPartition \u00b6 Property Value URI http://lenticularlens.org/voidPlus/hasClassPartition Super-properties void:classPartition void+:hasSubset hasFormulation \u00b6 Property Value URI http://lenticularlens.org/voidPlus/hasFormulation Range(s) void+:Formulation hasItem \u00b6 Property Value URI http://lenticularlens.org/voidPlus/hasItem Domain(s) void+:Formulation hasLanguagePartition \u00b6 Property Value URI http://lenticularlens.org/voidPlus/hasLanguagePartition Super-properties void+:hasSubset hasObjectResourceSelection \u00b6 Property Value URI http://lenticularlens.org/voidPlus/hasObjectResourceSelection Super-properties void+:hasResourceSelection hasPropertyPartition \u00b6 Property Value URI http://lenticularlens.org/voidPlus/hasPropertyPartition Super-properties void:propertyPartition void+:hasSubset hasResourceSelection \u00b6 Property Value URI http://lenticularlens.org/voidPlus/hasResourceSelection Range(s) void+:ResourceSelection hasSubjectResourceSelection \u00b6 Property Value URI http://lenticularlens.org/voidPlus/hasSubjectResourceSelection Super-properties void+:hasResourceSelection hasSubset \u00b6 Property Value URI http://lenticularlens.org/voidPlus/hasSubset Super-properties void:subset Domain(s) void:Dataset Range(s) void+:Partition hasTarget \u00b6 Property Value URI http://lenticularlens.org/voidPlus/hasTarget Domain(s) void+:LinkDataset Range(s) void:Dataset hasValidation \u00b6 Property Value URI http://lenticularlens.org/voidPlus/hasValidation Range(s) void+:Validation language \u00b6 Property Value URI http://lenticularlens.org/voidPlus/language Super-properties void+:partitionedBy Domain(s) void+:LanguagePartition Range(s) void+:Language objectsTarget \u00b6 Property Value URI http://lenticularlens.org/voidPlus/objectsTarget Super-properties void+:hasTarget partitionedBy \u00b6 Property Value URI http://lenticularlens.org/voidPlus/partitionedBy Domain(s) void+:Partition property \u00b6 Property Value URI http://lenticularlens.org/voidPlus/property Super-properties void+:partitionedBy subjectsTarget \u00b6 Property Value URI http://lenticularlens.org/voidPlus/subjectsTarget Super-properties void+:hasTarget subsetOf \u00b6 Property Value URI http://lenticularlens.org/voidPlus/subsetOf class \u00b6 Property Value URI http://rdfs.org/ns/void#class Super-properties void+:partitionedBy Range(s) rdfs:Class classPartition \u00b6 Property Value URI http://rdfs.org/ns/void#classPartition Super-properties void:subset objectsTarget \u00b6 Property Value URI http://rdfs.org/ns/void#objectsTarget Super-properties void:target void+:objectsTarget Domain(s) void:Linkset property \u00b6 Property Value URI http://rdfs.org/ns/void#property Super-properties void+:property Range(s) rdf:Property rdf:Seq propertyPartition \u00b6 Property Value URI http://rdfs.org/ns/void#propertyPartition Super-properties void:subset subjectsTarget \u00b6 Property Value URI http://rdfs.org/ns/void#subjectsTarget Super-properties void+:subjectsTarget void:target Domain(s) void:Linkset subset \u00b6 Property Value URI http://rdfs.org/ns/void#subset Domain(s) void:Dataset Range(s) void:Dataset target \u00b6 Property Value URI http://rdfs.org/ns/void#target Super-properties void+:hasTarget Domain(s) void:Linkset Range(s) void:Dataset 4.5 Datatype Properties \u00b6 hasFormulaDescription \u00b6 Property Value URI http://lenticularlens.org/voidPlus/hasFormulaDescription Range(s) xsd:string 4.6 Namespaces \u00b6 owl : http://www.w3.org/2002/07/owl# prov : http://www.w3.org/ns/prov# rdf : http://www.w3.org/1999/02/22-rdf-syntax-ns# rdfs : http://www.w3.org/2000/01/rdf-schema# sdo : https://schema.org/ skos : http://www.w3.org/2004/02/skos/core# void : http://rdfs.org/ns/void# void+ : http://lenticularlens.org/voidPlus/ xsd : http://www.w3.org/2001/XMLSchema#","title":"ONTOLOGY :crayon:"},{"location":"03.Ontology%20copy%202/#ontology","text":"This section presents an Ontology meant for describing processes of generation and validation of links in detail, so that decisions made such as resource selections and matching options are made explicit. Those processes are implemented in the Lenticular Lens tool and result in the creation of Linksets or Lenses according to a specification. we call the proposed ontology VoID+ as it is proposed as an extension of the [ VoID ] vocabulary. The next section presents the motivation for such extension while Section 3.2 and Section 3.3 respectively present the main elements proposed as extension for VoID and the complete and detailed description of the VoID+ extension.","title":"ONTOLOGY"},{"location":"03.Ontology%20copy%202/#1-motivation-to-extend-void","text":"The model presented in Figure 1 is created based on the [ VoID ] documentation and owl-ontology description, where ellipses represent classes, thick arrows represent subclass or sub-property relations (hierarchy) and thin arrows represent properties. In this model, only classes and relations of interest are exhibit. The [ VoID ] vocabulary provides means to describe datasets and linksets, but with limitations. The first important limitation that motivates our proposal for extension is that void:Linkset is (1) too restrictive as it is directed and holds between exactly two non-identical datasets. Furthermore, (2) it also does not describe the details of how they were generated, nor it provides means to describe Lenses or Validations . The next limitation is (3) the ambiguate descriptions of subsets or partitions of a void:Dataset . This concept is in our theory very important and requires more clarity and expressivity. Those issues are further discussed in the next section. Fig 1: Excerpt of VoId Ontology regarding void:Dataset and void:Linkset. A description of the classes and properties exhibited in Fig 1 is available in the table below. Vocabulary Description void:Dataset A set of RDF triples that are published, maintained or aggregated by a single provider. void:Linkset A collection of RDF links between two void:Datasets. void:subset has subset. Domain : void:Dataset Range : void:Dataset void:classPartition A relation between a void:Dataset and its Partition, which is a subset of a void:Dataset that contains only entities of an explicitly defined rdfs:Class. Domain : void:Dataset Range : void:Dataset void:propertyPartition A relation between a void:Dataset and its Partition, which is a subset of a void:Dataset that contains only triples composed with an explicitly defined rdf:Property. Domain : void:Dataset Range : void:Dataset void:class A relation that assigns to a void:Dataset a rdfs:Class that is the rdf:type of all entities (subject) in a class-based partition. Domain : void:Dataset Range : rdfs:Class ( exactly 1 ) void:property A relation that assigns to a void:Dataset a rdf:Property that is the predicate of all triples in a property-based partition. Domain : void:Dataset Range : rdfs:Property ( exactly 1 ) void:target A relation that assigns one of the two datasets linked by the Linkset. Domain : void:Linkset Range : void:Dataset ( exactly 2 ) void:subjectsTarget A relation that assigns the dataset describing the subjects of triples contained in the Linkset. Domain : void:Linkset Range : void:Dataset ( exactly 1 ) void:objectsTarget A relation that assigns the dataset describing the objects of the triples contained in the Linkset. Domain : void:Linkset Range : void:Dataset ( exactly 1 )","title":"1. Motivation to extend VoID"},{"location":"03.Ontology%20copy%202/#2-void-main-elements","text":"This section presents the main elements proposed as extension for VoID . It provides a simplified overview (Fig. 2) of VoID+ by (i) only describing the classes and properties that are of importance in this work and (ii) omitting hierarchical relations among classes. While the complete and detailed description of the VoID+ extension is provided in the next section, the complete ontology overview (figure) and the documentation extracted from the owl file are available in section 3.4. Fig 2: The Lenticular Lens Ontology The partial model of the simplified oberverview depicted in Fig. 2 highlights in yellow the use of [ VoID ] terms and in blue the new VoID+ terminology . In order to describe the proposed ontology, we dissect Fig 2 into four parts. First, a Resource Selection is elucidated. Second, we go about describing a Matching Formulation and show how it connects with a Resource Selection . The third step highlights that the description of a Linkset metadata involves specifying the Resource Selections used at the source and target positions of an entity matching process, the Matching Formulation , eventual validations plus statistics and authority information. The fourth and final step focuses on the annotation of a Lens by describing the combination of one or more Linksets and/or Lenses.","title":"2. VoID+ Main Elements"},{"location":"03.Ontology%20copy%202/#21-resource-selection","text":"This step concerns the selection of the resources under scrutiny , that can potentially end up co-referent entities across or within datasources during an entity matching process. To therefore perform a matching, one first needs not only to select datasource(s) but also restrict which resources will undergo the matching. The first way of doing so is by applying a type (class) restriction. This is mandatory in the Lenticular Lens process as matching algorithms are not fully automated. Down this line, further restrictions can be applied by forcing the value of a number of properties to lie within a certain range. A Resource Selection is thereby, the annotation of such process. In the ontology excerpt depicted in Figure 3 we propose the entity type Resource Selection , which is also a void:Dataset that is a void:subset of one or more void:Dataset(s) . It can also have further restrictions defined as void:classPartion and/or void:propertyPartition . While a void:classPartion solely consists in specifying the type of entity under scrutiny, the void:propertyPartition entails a little more. It consists in specifying a property or property path and a restriction that the selected property should undergo for the selection of the right entities for the further down the road entity matching process. Those restrictions can be combined using a Formula Description given by ll:hasFormulaDescription . Fig 3: Selecting a matching resource Example 1 : Resource Selection In this example, the entity resource:ResourceSelection-2 is a ll:ResourceSelection (and a void:Dataset ) subset of resource:index_op_doopregister_raw_20190830 and also a collection (partition) of entities of type pnv:PersonName where each entity passed the filter test of (1) name in the English language which appears without trailing dots \"%...%\"@en and (2) birthdates within the interval [1600, 1699] . the entity resource:ResourceSelection-2 lists all three entities of type ll:PropertyConstraint and elaborates on the logic expression that binds all restrictions. For example, the property restriction described by resource:PropertyConstraint-PHce78383e3ff6e9dd73b6 documents that, applying the date function \"minimal_date\"@en over dates in the format the \"YYYY-MM-DD\"@en with the year restriction of 1600 makes sure that only persons born on 1600 onwards are admitted. Turtle Syntax When ever a literal in RDF syntax conatins quote or new line characters, the litreal should be in a three quote syntax ( \"...\"\"@en ). In the example below, we deliberately wrote the literal value of ll:hasFormulaDescription is in a single quote ( \"...\"\"@en ) instead of a triple quote ( \"\"\"%...%=\"\"\"@en ) as the syntax highliter is somewhat buggy. ### RESOURCE 2 resource: ResourceSelection-2 a void: dataset , ll: ResourceSelection ; rdfs: label \"Baptisms in the 17th Century\" @ en ; void: subset resource: index_op_doopregister_raw_20190830 ; void: classPartition [ void: class pnv: PersonName ] ; void: propertyPartition resource: PropertyConstraint-PHea6802ef02f99a848859 ; void: propertyPartition resource: PropertyConstraint-PHce78383e3ff6e9dd73b6 ; void: propertyPartition resource: PropertyConstraint-PH2580641bbdd572759cb9 ; ll: hasFormulaDescription \" resource: PropertyConstraint-PHce78383e3ff6e9dd73b6 AND resource: PropertyConstraint-PH2580641bbdd572759cb9 AND ( resource: PropertyConstraint-PHea6802ef02f99a848859 ) \"@en . resource: PropertyConstraint-PHea6802ef02f99a848859 a ll: PropertyConstraint ; void: property [ a rdfs: Sequence ; rdf : _ 1 pnv: literalName ] ; ll: hasFilterFunction \"not_ilike\" @ en ; ll: hasValueFunction \"%...%\" @ en . resource: PropertyConstraint-PHce78383e3ff6e9dd73b6 a ll: PropertyConstraint ; void: property [ a rdfs: Sequence ; rdf : _ 1 saa: isInRecord ; rdf : _ 2 saa: IndexOpDoopregisters ; rdf : _ 3 saa: birthDate ] ; ll: hasFilterFunction \"minimal_date\" @ en ; ll: hasValueFunction 1600 ; ll: hasFormatFunction \"YYYY-MM-DD\" @ en . resource: PropertyConstraint-PH2580641bbdd572759cb9 a ll: PropertyConstraint ; void: property [ a rdfs: Sequence ; rdf : _ 1 saa: isInRecord ; rdf : _ 2 saa: IndexOpDoopregisters ; rdf : _ 3 saa: birthDate ] ; ll: hasFilterFunction \"maximum_date\" @ en ; ll: hasValueFunction \"1699\" @ en ; ll: hasFormatFunction \"YYYY-MM-DD\" @ en .","title":"2.1 Resource Selection"},{"location":"03.Ontology%20copy%202/#22-matching-formulation","text":"For simple matching problems, finding co-referents can be done using a single matching algorithm (matcher). However, time and again the data reality often imposes the use of more than one matcher instead. In this latter scenario, clearly reporting on how these matchers work together for detecting co-referents is essential. A Matching Formulation entity is a resource for just doing the aforementioned, as depicted in Figure 4. Once resources of type Resource Restriction are created, one can go ahead and used them for specifying the restricted collections to be used in a particular Matching Method , which also specifies the Matching Algorithm and its parameters such as threshold, range and operrator. In the end, all Matching Methods used in a matching process are documented in the Matching Formulation resource as well as how they bind together in a logic expression given by the predicate ll:hasFormulaDescription . Fig 4: Specifying the way in which methods are logically combined Example 2 : Linkset Logic Expression In Example 2.8, the resource:PHb99da2ecd91ad533af65 is a ll:MatchingFormulation listing eight ll:MatchingMethods used for creating a linkset. They their logic combination is described as ll:hasFormulaDescription . Among the ll:MatchingMethods , the resource:TIME_DELTA-PHfdc744f6bd0ced4e283a is the only method detailes in this example, documenting the four ll:ResourceSelections involved, as well as the chosen ll:MatchingAlgorithm , namely resource:TIME_DELTA , besides the threshold (20), threshold-unit (\u201cYear\u201d@en), threshold-operator (>=) and threshold-range \u201c\u2115\u201d of the matching method. Turtle Syntax When ever a literal in RDF syntax conatins quote or new line characters, the litreal should be in a three quote syntax ( \"...\"\"@en ). In the example below, we deliberately wrote the literal value of ll:hasFormulaDescription is in a single quote ( \"...\"\"@en ) instead of a triple quote ( \"\"\"%...%=\"\"\"@en ) as the syntax highliter is somewhat buggy. ###################################################### # LINKSET LOGIC EXPRESSION # ###################################################### resource: PHb99da2ecd91ad533af65 a ll: MatchingFormulation ; ll: hasMethod resource: TIME_DELTA-PHfdc744f6bd0ced4e283a ; ll: hasMethod resource: Exact-PH6491d1db6855098a70be ; ll: hasMethod resource: LL_SOUNDEX-PH0ad3ad579d7a29347753 ; ll: hasMethod resource: BLOOTHOOFT_REDUCT-PH10433274b57dafdd1335 ; ll: hasMethod resource: Exact-PH4d4187a08c3ba4c1cf0d ; ll: hasMethod resource: TIME_DELTA-PHe40547b9d3b6381347b4 ; ll: hasMethod resource: LEVENSHTEIN_APPROX-PH10f4c17bbf933cae647f ; ll: hasMethod resource: BLOOTHOOFT_REDUCT-PH98a9575087817b951447 ; ll: hasFormulaDescription \" resource: TIME_DELTA-PHe40547b9d3b6381347b4 AND resource: TIME_DELTA-PHfdc744f6bd0ced4e283a AND ( resource: Exact-PH4d4187a08c3ba4c1cf0d OR ( resource: BLOOTHOOFT_REDUCT-PH98a9575087817b951447 AND resource: BLOOTHOOFT_REDUCT-PH10433274b57dafdd1335 ) OR ( resource: Exact-PH6491d1db6855098a70be AND ( resource: LL_SOUNDEX-PH0ad3ad579d7a29347753 AND resource: LEVENSHTEIN_APPROX-PH10f4c17bbf933cae647f ) ) ) \"@en . ###################################################### # METHOD SIGNATURES # ###################################################### ### METHOD SPECIFICATIONS TIME_DELTA resource: TIME_DELTA-PHe40547b9d3b6381347b4 a ll: MatchingMethod ; ll: hasAlgorithm resource: TIME_DELTA ; ll: hasThresholdRange \"\u2115\" ; ### SOURCE PREDICATE CONFIGURATION ll: hasSubjResourceSelection resource: ResourceSelection-PHbe38976fdf884b6c4a8e ; ll: hasSubjResourceSelection resource: ResourceSelection-PHe8fa664d04ad00aaa697 ; ### TARGET PREDICATE CONFIGURATION ll: hasObjResourceSelection resource: ResourceSelection-PH71818c17d54a8fbec22b ; ll: hasObjResourceSelection resource: ResourceSelection-PHc8a3c6e494d230b79a6b . \u2022\u2022\u2022","title":"2.2 Matching Formulation"},{"location":"03.Ontology%20copy%202/#23-linkset","text":"This step documents a linkset metadata including WHAT - HOW - WHEN - WHO and other processes explaining the aboutness of links. The Matching Formulation specifies HOW entities are matched and Resource Selection specifies WHAT to match as subject and object targets. Also some statistic on the matching results can be reported such as the number of links found, the numbers of entities linked, WHO created the linkset and WHEN . Finally, a Validation entity can also be specified, comprising metadata with statitics and auhtority information on the validation process. Observe that when one or more validations are provided, statistics on this matter can be included in the linkset metadata, including eventual contradictions if one validation says a link is correct while another says it is not. As discussed earlier in this section, according to the [ VoID ] documentation, the void:Linkset definition expects as datasources exactly one source and one target, different from each other. This means it is more restrictive than the ll:Linkset here proposed, since the latter also expects a linkset to contain links within a datasource or across more than two. Therefore, we do not directly reuse that concept (and its correspoding properties void:subjects/objectsTarget). Naturally, one could still use void:Linkset for other purposes, but at the risk of abusing the VoID vocabulary if its instances do not really fit the required restrictions. Moreover, a void:Linkset (i.e. a resource representing a linkset\u2019s metadata) is also not an instance of ll:Linkset since the later requires the description of the processes underlying the creation of the links, which is not the case for the first. Fig 5: Specifying the linkset\u2019s context Example 3: A linkset annotation ### LINKSET 15 linkset : 15 a ll: Linkset ; void: feature format: Turtle ; cc: attributionName \"LenticularLens\" @ en ; cc: license <http://purl.org/NET/rdflicense/W3C1.0> ; dcterms: created \"2020-09-26T09:37:23.933624\" ^^ <http://www.w3.org/2001/XMLSchema#dateTime> ; dcterms: creator \"AL IDRISSOU\" ; dcterms: creator \"GoldenAgents\" ; void: linkPredicate owl: sameAs ; rdfs: label \"Linkset 9\" @ en ; dcterms: description \"LINSET-15-9: Test Baptism against Marriage and burial with several nested methods \" @ en ; ### VOID LINKSET STATS void: entities 12580 ; ### LENTICULAR LENS LINKSET STATS ### SOURCE ENTITY TYPE SELECTION(S) ll: subjectsTarget resource: ResourceSelection-2 ; ### TARGET ENTITY TYPE SELECTION(S) ll: objectsTarget resource: ResourceSelection-1 ; ll: objectsTarget resource: ResourceSelection-3 ; ### THE LOGIC FORMULA ll: hasLogicFormulation resource: PHb6e5e320dc08d7d9dd98 .","title":"2.3 Linkset"},{"location":"03.Ontology%20copy%202/#24-lens","text":"Another process relevant to document is the creation of Lenses. In short, a lens is the result of a set-like operation over one or more Linkset and or Lens. Therefore, the entity Lens documents them as ll:hasTarget Fig 6: Specifying the linkset\u2019s context Example 4: A lens annotation","title":"2.4 Lens"},{"location":"03.Ontology%20copy%202/#3-void-ontology","text":"This section discuses the complete and detailed description of the VoID+ extension in two parts. It first addresses the void+:Partition of void:Dataset. Second, it tackles the void+:LinkDataset which is considered a special sub-types of void:Dataset. The documentation extracted from the owl file is presented in the next section.","title":"3. VoID+ Ontology"},{"location":"03.Ontology%20copy%202/#31-partitions-of-voiddataset","text":"The VoID vocabulary defines void:Dataset as a dataset superset but does make available a granularity of subsets for refined work. VoID+ extends the void:Dataset class by distinguishes between five subsets of void:Dataset. A void:Dataset that is defined as a subset of another one is called void+:Partition . Three types of void+:Partition are distinguished according to the type of partition that is used: (i) void+:ClassPartition : the dataset is the result of an rdfs:Class based-partition; (ii) void+:PropertyPartition : the dataset is the result of a rdf:Property or by a rdf:Seq \u2013 defining a sequence of two or more of properties \u2013 partition; (iii) void+:Language : the dataset is the result of a language partition given by a standardised ISO language code. Another special type of partition is the void+:ResourceSelection . It is defined by one or more partions of the type above described, Fig. 7 provides a straightforward understanding of how the class void:Dataset is extended. On its the left hand side, Fig. 7 presents a view on the classes, their hierarchy and how they are connected via object properties. On the one hand, the property void:subset and its sub-properties are extended such that they provide a directional non-ambiguous reading. On the other and, void:class and void:property are grouped into a superclass void+:partionedBy which also includes void:language to allow for one more type of partition. In particular, void:property is extended with a more generic relation void+:property that allows for describing a sequence of properties like in a property path. Fig 7: VoID+ Extension on the void:Dataset","title":"3.1 Partitions of void:Dataset"},{"location":"03.Ontology%20copy%202/#32-void-link-datasets","text":"Figure 8 presents on the left hand side a view on the classes, their hierarchy and how they are connected via object properties. This provides a very straightforward understanding of how the class void:Linkset is extended. It is extended with superclasses that are less restrictive with respect with its targets. First, a void+:LinkDataset is a void:Dataset that contains links that may have been stabilished among one (deduplication), two or many datasets. When the creation of void+:LinkDataset is such that imposes that subjects always belong to the same datasets as well as objects, this is called void+:DirectedLinkDataset. This is the case for both void:Linkset but also for our definition of void+:Linkset. The former, however, requires excelty one dataset as target for its subjects and onther as target for its objects. In addition, our definition of void+:Linkset is also a void+:DocumentedLinkDataset, which requires more detailed documentation, including targets described as void+:ResourceSelection (all values from) and a void+:Formulation\u2026 A void+:Lens is also a void+:DocumentedLinkDataset which has one void:LensFormulation that specifies which void:LinkDatasets are combined and how. The right hand side of Figure 8 presents a hierarchy of properties in order to provide an undestanding of how void:target and its subproperties are extended. They actually are extended with superclasses having as range not only a void:Linkset but its superclass void+:LinkDataset. Fig 8: VoID+ Extension on the void:Linkset","title":"3.2 VoID+ Link-datasets"},{"location":"03.Ontology%20copy%202/#4-void-documentation","text":"Markdown documentation created by pyLODE 2.8.3","title":"4. VoID+ Documentation"},{"location":"03.Ontology%20copy%202/#41-metadata","text":"URI http://lenticularlens.org/voidPlus Ontology RDF RDF ( voidPlus.ttl )","title":"4.1 Metadata"},{"location":"03.Ontology%20copy%202/#42-overview","text":"See Figure 7 and 8 above for an overview","title":"4.2 Overview"},{"location":"03.Ontology%20copy%202/#43-classes","text":"","title":"4.3 Classes"},{"location":"03.Ontology%20copy%202/#classpartition","text":"Property Value URI http://lenticularlens.org/voidPlus/ClassPartition Super-classes void+:Partition","title":"ClassPartition"},{"location":"03.Ontology%20copy%202/#directedlinkdataset","text":"Property Value URI http://lenticularlens.org/voidPlus/DirectedLinkDataset Super-classes void+:LinkDataset Sub-classes void+:Linkset void:Linkset","title":"DirectedLinkDataset"},{"location":"03.Ontology%20copy%202/#documentedlinkdataset","text":"Property Value URI http://lenticularlens.org/voidPlus/DocumentedLinkDataset Super-classes void+:LinkDataset Sub-classes void+:Lens void+:Linkset","title":"DocumentedLinkDataset"},{"location":"03.Ontology%20copy%202/#formulation","text":"Property Value URI http://lenticularlens.org/voidPlus/Formulation Sub-classes void+:LensFormulation void+:LinksetFormulation In domain of void+:hasItem In range of void+:hasFormulation","title":"Formulation"},{"location":"03.Ontology%20copy%202/#language","text":"Property Value URI http://lenticularlens.org/voidPlus/Language In range of void+:language","title":"Language"},{"location":"03.Ontology%20copy%202/#languagepartition","text":"Property Value URI http://lenticularlens.org/voidPlus/LanguagePartition Super-classes void+:Partition In domain of void+:language","title":"LanguagePartition"},{"location":"03.Ontology%20copy%202/#lens","text":"Property Value URI http://lenticularlens.org/voidPlus/Lens Description Content-wise, a Lens is a type of RDF linkset (in the sense that it is a collection of links sharing the same linktype) also involving one, two or more datasets. However, context-wise, it differs from a linkset as it is generated using different process (set-like link manipulation operators such as Union, Intersection, Difference or Transitivity) as compared to how a linkset comes about (matching algorithms). Super-classes void+:DocumentedLinkDataset","title":"Lens"},{"location":"03.Ontology%20copy%202/#lensformulation","text":"Property Value URI http://lenticularlens.org/voidPlus/LensFormulation Super-classes void+:Formulation","title":"LensFormulation"},{"location":"03.Ontology%20copy%202/#linkdataset","text":"Property Value URI http://lenticularlens.org/voidPlus/LinkDataset Super-classes void:Dataset Sub-classes void+:DocumentedLinkDataset void+:DirectedLinkDataset In domain of void+:hasTarget","title":"LinkDataset"},{"location":"03.Ontology%20copy%202/#linkset","text":"Property Value URI http://lenticularlens.org/voidPlus/Linkset Description In [VoID], a Linkset is a collection of RDF links between two datasets where all subjects stem from one dataset and all objects from the other dataset. In here, we alleviate such strict restriction on the number of linked datasets to be one, two or more. Therefore, here a linkset is a collection of RDF links between dataset(s), using the same link predicate (regardless of the link being an equality predicate or not). This predicate is called the linktype of the linkset. Super-classes void+:DirectedLinkDataset void+:DocumentedLinkDataset","title":"Linkset"},{"location":"03.Ontology%20copy%202/#linksetformulation","text":"Property Value URI http://lenticularlens.org/voidPlus/LinksetFormulation Description A LinksetFormulation is a resource that makes explicit all matching-methods involved in the creation of a Linkset and how the methods logically work jointly. Super-classes void+:Formulation","title":"LinksetFormulation"},{"location":"03.Ontology%20copy%202/#matchingalgorithm","text":"Property Value URI http://lenticularlens.org/voidPlus/MatchingAlgorithm In range of void+:hasAlgorithm","title":"MatchingAlgorithm"},{"location":"03.Ontology%20copy%202/#matchingmethod","text":"Property Value URI http://lenticularlens.org/voidPlus/MatchingMethod Description A MatchingMethod is a resource that makes explicit all pre-requisites of a matching algorithm including the conditions in which the algorithm is to accept a discovered link (threshold). In domain of void+:hasAlgorithm","title":"MatchingMethod"},{"location":"03.Ontology%20copy%202/#partition","text":"Property Value URI http://lenticularlens.org/voidPlus/Partition Sub-classes void+:PropertyPartition void+:ClassPartition void+:LanguagePartition In domain of void+:partitionedBy In range of void+:hasSubset","title":"Partition"},{"location":"03.Ontology%20copy%202/#propertypartition","text":"Property Value URI http://lenticularlens.org/voidPlus/PropertyPartition Super-classes void+:Partition Restrictions void:property some ( rdf:Property or rdf:Seq )","title":"PropertyPartition"},{"location":"03.Ontology%20copy%202/#propertysequence","text":"Property Value URI http://lenticularlens.org/voidPlus/PropertySequence Super-classes rdf:Seq Sub-classes void+:TypedPropertySequence","title":"PropertySequence"},{"location":"03.Ontology%20copy%202/#resourceselection","text":"Property Value URI http://lenticularlens.org/voidPlus/ResourceSelection Description A ResourceSelection is a collection of resources stemmed from the same dataset and partitioned on the basis of a given class and optionally a number of predicates having there respective predicate-value(s) enforced within a pre-defined range. Super-classes void:Dataset Restrictions void+:hasSubset some void+:Partition void:subset some void:Dataset In range of void+:hasResourceSelection","title":"ResourceSelection"},{"location":"03.Ontology%20copy%202/#typedpropertysequence","text":"Property Value URI http://lenticularlens.org/voidPlus/TypedPropertySequence Super-classes void+:PropertySequence","title":"TypedPropertySequence"},{"location":"03.Ontology%20copy%202/#validation","text":"Property Value URI http://lenticularlens.org/voidPlus/Validation In range of void+:hasValidation","title":"Validation"},{"location":"03.Ontology%20copy%202/#dataset","text":"Property Value URI http://rdfs.org/ns/void#Dataset Sub-classes void+:LinkDataset void+:ResourceSelection In domain of void:subset void+:hasSubset In range of void:subset void:target void+:hasTarget","title":"Dataset"},{"location":"03.Ontology%20copy%202/#linkset_1","text":"Property Value URI http://rdfs.org/ns/void#Linkset Super-classes void+:DirectedLinkDataset In domain of void:target void:subjectsTarget void:objectsTarget","title":"Linkset"},{"location":"03.Ontology%20copy%202/#44-object-properties","text":"","title":"4.4 Object Properties"},{"location":"03.Ontology%20copy%202/#hasalgorithm","text":"Property Value URI http://lenticularlens.org/voidPlus/hasAlgorithm Domain(s) void+:MatchingMethod Range(s) void+:MatchingAlgorithm","title":"hasAlgorithm"},{"location":"03.Ontology%20copy%202/#hasclasspartition","text":"Property Value URI http://lenticularlens.org/voidPlus/hasClassPartition Super-properties void:classPartition void+:hasSubset","title":"hasClassPartition"},{"location":"03.Ontology%20copy%202/#hasformulation","text":"Property Value URI http://lenticularlens.org/voidPlus/hasFormulation Range(s) void+:Formulation","title":"hasFormulation"},{"location":"03.Ontology%20copy%202/#hasitem","text":"Property Value URI http://lenticularlens.org/voidPlus/hasItem Domain(s) void+:Formulation","title":"hasItem"},{"location":"03.Ontology%20copy%202/#haslanguagepartition","text":"Property Value URI http://lenticularlens.org/voidPlus/hasLanguagePartition Super-properties void+:hasSubset","title":"hasLanguagePartition"},{"location":"03.Ontology%20copy%202/#hasobjectresourceselection","text":"Property Value URI http://lenticularlens.org/voidPlus/hasObjectResourceSelection Super-properties void+:hasResourceSelection","title":"hasObjectResourceSelection"},{"location":"03.Ontology%20copy%202/#haspropertypartition","text":"Property Value URI http://lenticularlens.org/voidPlus/hasPropertyPartition Super-properties void:propertyPartition void+:hasSubset","title":"hasPropertyPartition"},{"location":"03.Ontology%20copy%202/#hasresourceselection","text":"Property Value URI http://lenticularlens.org/voidPlus/hasResourceSelection Range(s) void+:ResourceSelection","title":"hasResourceSelection"},{"location":"03.Ontology%20copy%202/#hassubjectresourceselection","text":"Property Value URI http://lenticularlens.org/voidPlus/hasSubjectResourceSelection Super-properties void+:hasResourceSelection","title":"hasSubjectResourceSelection"},{"location":"03.Ontology%20copy%202/#hassubset","text":"Property Value URI http://lenticularlens.org/voidPlus/hasSubset Super-properties void:subset Domain(s) void:Dataset Range(s) void+:Partition","title":"hasSubset"},{"location":"03.Ontology%20copy%202/#hastarget","text":"Property Value URI http://lenticularlens.org/voidPlus/hasTarget Domain(s) void+:LinkDataset Range(s) void:Dataset","title":"hasTarget"},{"location":"03.Ontology%20copy%202/#hasvalidation","text":"Property Value URI http://lenticularlens.org/voidPlus/hasValidation Range(s) void+:Validation","title":"hasValidation"},{"location":"03.Ontology%20copy%202/#language_1","text":"Property Value URI http://lenticularlens.org/voidPlus/language Super-properties void+:partitionedBy Domain(s) void+:LanguagePartition Range(s) void+:Language","title":"language"},{"location":"03.Ontology%20copy%202/#objectstarget","text":"Property Value URI http://lenticularlens.org/voidPlus/objectsTarget Super-properties void+:hasTarget","title":"objectsTarget"},{"location":"03.Ontology%20copy%202/#partitionedby","text":"Property Value URI http://lenticularlens.org/voidPlus/partitionedBy Domain(s) void+:Partition","title":"partitionedBy"},{"location":"03.Ontology%20copy%202/#property","text":"Property Value URI http://lenticularlens.org/voidPlus/property Super-properties void+:partitionedBy","title":"property"},{"location":"03.Ontology%20copy%202/#subjectstarget","text":"Property Value URI http://lenticularlens.org/voidPlus/subjectsTarget Super-properties void+:hasTarget","title":"subjectsTarget"},{"location":"03.Ontology%20copy%202/#subsetof","text":"Property Value URI http://lenticularlens.org/voidPlus/subsetOf","title":"subsetOf"},{"location":"03.Ontology%20copy%202/#class","text":"Property Value URI http://rdfs.org/ns/void#class Super-properties void+:partitionedBy Range(s) rdfs:Class","title":"class"},{"location":"03.Ontology%20copy%202/#classpartition_1","text":"Property Value URI http://rdfs.org/ns/void#classPartition Super-properties void:subset","title":"classPartition"},{"location":"03.Ontology%20copy%202/#objectstarget_1","text":"Property Value URI http://rdfs.org/ns/void#objectsTarget Super-properties void:target void+:objectsTarget Domain(s) void:Linkset","title":"objectsTarget"},{"location":"03.Ontology%20copy%202/#property_1","text":"Property Value URI http://rdfs.org/ns/void#property Super-properties void+:property Range(s) rdf:Property rdf:Seq","title":"property"},{"location":"03.Ontology%20copy%202/#propertypartition_1","text":"Property Value URI http://rdfs.org/ns/void#propertyPartition Super-properties void:subset","title":"propertyPartition"},{"location":"03.Ontology%20copy%202/#subjectstarget_1","text":"Property Value URI http://rdfs.org/ns/void#subjectsTarget Super-properties void+:subjectsTarget void:target Domain(s) void:Linkset","title":"subjectsTarget"},{"location":"03.Ontology%20copy%202/#subset","text":"Property Value URI http://rdfs.org/ns/void#subset Domain(s) void:Dataset Range(s) void:Dataset","title":"subset"},{"location":"03.Ontology%20copy%202/#target","text":"Property Value URI http://rdfs.org/ns/void#target Super-properties void+:hasTarget Domain(s) void:Linkset Range(s) void:Dataset","title":"target"},{"location":"03.Ontology%20copy%202/#45-datatype-properties","text":"","title":"4.5 Datatype Properties"},{"location":"03.Ontology%20copy%202/#hasformuladescription","text":"Property Value URI http://lenticularlens.org/voidPlus/hasFormulaDescription Range(s) xsd:string","title":"hasFormulaDescription"},{"location":"03.Ontology%20copy%202/#46-namespaces","text":"owl : http://www.w3.org/2002/07/owl# prov : http://www.w3.org/ns/prov# rdf : http://www.w3.org/1999/02/22-rdf-syntax-ns# rdfs : http://www.w3.org/2000/01/rdf-schema# sdo : https://schema.org/ skos : http://www.w3.org/2004/02/skos/core# void : http://rdfs.org/ns/void# void+ : http://lenticularlens.org/voidPlus/ xsd : http://www.w3.org/2001/XMLSchema#","title":"4.6 Namespaces"},{"location":"03.Ontology%20copy/","text":".katex img { display: block; position: absolute; width: 100%; height: inherit; } 3. ONTOLOGY \u00b6 This section presents an Ontology meant for describing processes of generation and validation of links in detail, so that decisions made such as resource selections and matching options are made explicit. Those processes are implemented in the Lenticular Lens tool and result in the creation of Linksets or Lenses according to a specification. we call the proposed ontology VoID+ as it is proposed as an extension of the [ VoID ] vocabulary. The next section presents the motivation for such extension while Section 3.2 and Section 3.3 respectively present the main elements proposed as extension for VoID and the complete and detailed description of the VoID+ extension. 3.1 Motivation to extend VoID \u00b6 The model presented in Figure 1 is created based on the [ VoID ] documentation, and owl-ontology description , where ellipses represent classes, thick arrows represent subclass or subproperty relations (hierarchy) and thin arrows represent properties. Fig 1: The Lenticular Lens Ontology The presented model only contains classes and relations of interest, namely: Vocabulary Description void:Dataset A set of RDF triples that are published, maintained or aggregated by a single provider. void:Linkset A collection of RDF links between two void:Datasets. void:subset has subset. Domain : void:Dataset Range : void:Dataset void:classPartition A relation between a void:Dataset and its Partition, which is a subset of a void:Dataset that contains only entities of an explicitly defined rdfs:Class. Domain : void:Dataset Range : void:Dataset void:propertyPartition A relation between a void:Dataset and its Partition, which is a subset of a void:Dataset that contains only triples composed with an explicitly defined rdf:Property. Domain : void:Dataset Range : void:Dataset void:class A relation that assigns to a void:Dataset a rdfs:Class that is the rdf:type of all entities in a class-based partition. Domain : void:Dataset Range : rdfs:Class ( exactly 1 ) void:property A relation that assigns to a void:Dataset a rdf:Property that is the predicate of all triples in a property-based partition. Domain : void:Dataset Range : rdfs:Property ( exactly 1 ) void:target A relation that assigns one of the two datasets linked by the Linkset. Domain : void:Linkset Range : void:Dataset ( exactly 2 ) void:subjectsTarget A relation that assigns the dataset describing the subjects of triples contained in the Linkset. Domain : void:Linkset Range : void:Dataset ( exactly 1 ) void:objectsTarget A relation that assigns the dataset describing the objects of the triples contained in the Linkset. Domain : void:Linkset Range : void:Dataset ( exactly 1 ) The [ VoID ] vocabulary provides means to describe datasets and linksets, but with limitations. The first important limitation that motivates our proposal for extenstion is that a void:Linkset is too restrictive, since it is necessarily directed and holds between exact two (different) datasets. It also does not describe the details of how they were generated, nor it provides means to describe Lenses or Validations . The next limitation is the vague descriptions of subsets or partitions of a void:Dataset . This concept is in our theory very important and requires more clarity and expressivity. Those issues are further discussed in the next section. 3.2 Main Elements for VoID+ \u00b6 This section presents the main elements proposed as extension for VoID . It provides a simplified take of VoID+ describing all the classes and proporties that are of importance in this work in this part the hierarchical relations among the classes are ommited. The complete and detailed description of the VoID+ extension is provided in the next section, including a visualisation and the documention extracted from the owl file. The partial model depicted in Fig. 2 highlights in yellow the use of [ VoID ] terms and in blue the new terminology VoID+. In order to describe the proposed ontology, we dissect Fig 2 into four parts. First, a Resource Selection is elucidated. Second, we go about describing a Matching Formulation and show how it connects with a Resource Selection . The third step highlights that the description of a Linkset metadata involves specifying the Resource Selections used at the source and target positions of an entity matching process, the Matching Formulation , eventual validations plus statistics and authority information. The fourth and final step focuses on the annotation of a Lens by describing the combination of one or more Linksets and/or Lenses. Fig 2: The Lenticular Lens Ontology 3.2.1 Resource Selection \u00b6 This step concerns the selection of the resources under scrutiny , that can potentially end up co-referent entities across or within datasources during an entity matching process. To therefore perform a matching, one first needs not only to select datasource(s) but also restrict which resources will undergo the matching. The first way of doing so is by applying a type (class) restriction. This is mandatory in the Lenticular Lens process as matching algorithms are not fully automated. Down this line, further restrictions can be applied by forcing the value of a number of properties to lie within a certain range. A Resource Selection is thereby, the annotation of such process. In the ontology excerpt depicted in Figure 3 we propose the entity type Resource Selection , which is also a void:Dataset that is a void:subset of one or more void:Dataset(s) . It can also have further restrictions defined as void:classPartion and/or void:propertyPartition . While a void:classPartion solely consists in specifying the type of entity under scrutiny, the void:propertyPartition entails a little more. It consists in specifying a property or property path and a restriction that the selected property should undergo for the selection of the right entities for the further down the road entity matching process. Those restrictions can be combined using a Formula Description given by ll:hasFormulaDescription . Fig 3: Selecting a matching resource Example 1 : Resource Selection In this example, the entity resource:ResourceSelection-2 is a ll:ResourceSelection (and a void:Dataset ) subset of resource:index_op_doopregister_raw_20190830 and also a collection (partition) of entities of type pnv:PersonName where each entity passed the filter test of (1) name in the English language which appears without trailing dots \"%...%\"@en and (2) birthdates within the interval [1600, 1699] . the entity resource:ResourceSelection-2 lists all three entities of type ll:PropertyConstraint and elaborates on the logic expression that binds all restrictions. For example, the property restriction described by resource:PropertyConstraint-PHce78383e3ff6e9dd73b6 documents that, applying the date function \"minimal_date\"@en over dates in the format the \"YYYY-MM-DD\"@en with the year restriction of 1600 makes sure that only persons born on 1600 onwards are admitted. Turtle Syntax When ever a literal in RDF syntax conatins quote or new line characters, the litreal should be in a three quote syntax ( \"...\"\"@en ). In the example below, we deliberately wrote the literal value of ll:hasFormulaDescription is in a single quote ( \"...\"\"@en ) instead of a triple quote ( \"\"\"%...%=\"\"\"@en ) as the syntax highliter is somewhat buggy. ### RESOURCE 2 resource: ResourceSelection-2 a void: dataset , ll: ResourceSelection ; rdfs: label \"Baptisms in the 17th Century\" @ en ; void: subset resource: index_op_doopregister_raw_20190830 ; void: classPartition [ void: class pnv: PersonName ] ; void: propertyPartition resource: PropertyConstraint-PHea6802ef02f99a848859 ; void: propertyPartition resource: PropertyConstraint-PHce78383e3ff6e9dd73b6 ; void: propertyPartition resource: PropertyConstraint-PH2580641bbdd572759cb9 ; ll: hasFormulaDescription \" resource: PropertyConstraint-PHce78383e3ff6e9dd73b6 AND resource: PropertyConstraint-PH2580641bbdd572759cb9 AND ( resource: PropertyConstraint-PHea6802ef02f99a848859 ) \"@en . resource: PropertyConstraint-PHea6802ef02f99a848859 a ll: PropertyConstraint ; void: property [ a rdfs: Sequence ; rdf : _ 1 pnv: literalName ] ; ll: hasFilterFunction \"not_ilike\" @ en ; ll: hasValueFunction \"%...%\" @ en . resource: PropertyConstraint-PHce78383e3ff6e9dd73b6 a ll: PropertyConstraint ; void: property [ a rdfs: Sequence ; rdf : _ 1 saa: isInRecord ; rdf : _ 2 saa: IndexOpDoopregisters ; rdf : _ 3 saa: birthDate ] ; ll: hasFilterFunction \"minimal_date\" @ en ; ll: hasValueFunction 1600 ; ll: hasFormatFunction \"YYYY-MM-DD\" @ en . resource: PropertyConstraint-PH2580641bbdd572759cb9 a ll: PropertyConstraint ; void: property [ a rdfs: Sequence ; rdf : _ 1 saa: isInRecord ; rdf : _ 2 saa: IndexOpDoopregisters ; rdf : _ 3 saa: birthDate ] ; ll: hasFilterFunction \"maximum_date\" @ en ; ll: hasValueFunction \"1699\" @ en ; ll: hasFormatFunction \"YYYY-MM-DD\" @ en . 3.1.2 Matching Formulation \u00b6 For simple matching problems, finding co-referents can be done using a single matching algorithm (matcher). However, time and again the data reality often imposes the use of more than one matcher instead. In this latter scenario, clearly reporting on how these matchers work together for detecting co-referents is essential. A Matching Formulation entity is a resource for just doing the aforementioned, as depicted in Figure 4. Once resources of type Resource Restriction are created, one can go ahead and used them for specifying the restricted collections to be used in a particular Matching Method , which also specifies the Matching Algorithm and its parameters such as threshold, range and operrator. In the end, all Matching Methods used in a matching process are documented in the Matching Formulation resource as well as how they bind together in a logic expression given by the predicate ll:hasFormulaDescription . Fig 4: Specifying the way in which methods are logically combined Example 2 : Linkset Logic Expression In Example 2.8, the resource:PHb99da2ecd91ad533af65 is a ll:MatchingFormulation listing eight ll:MatchingMethods used for creating a linkset. They their logic combination is described as ll:hasFormulaDescription . Among the ll:MatchingMethods , the resource:TIME_DELTA-PHfdc744f6bd0ced4e283a is the only method detailes in this example, documenting the four ll:ResourceSelections involved, as well as the chosen ll:MatchingAlgorithm , namely resource:TIME_DELTA , besides the threshold (20), threshold-unit (\u201cYear\u201d@en), threshold-operator (>=) and threshold-range \u201c\u2115\u201d of the matching method. Turtle Syntax When ever a literal in RDF syntax conatins quote or new line characters, the litreal should be in a three quote syntax ( \"...\"\"@en ). In the example below, we deliberately wrote the literal value of ll:hasFormulaDescription is in a single quote ( \"...\"\"@en ) instead of a triple quote ( \"\"\"%...%=\"\"\"@en ) as the syntax highliter is somewhat buggy. ################################################################################ # LINKSET LOGIC EXPRESSION # ################################################################################ resource: PHb99da2ecd91ad533af65 a ll: MatchingFormulation ; ll: hasMethod resource: TIME_DELTA-PHfdc744f6bd0ced4e283a ; ll: hasMethod resource: Exact-PH6491d1db6855098a70be ; ll: hasMethod resource: LL_SOUNDEX-PH0ad3ad579d7a29347753 ; ll: hasMethod resource: BLOOTHOOFT_REDUCT-PH10433274b57dafdd1335 ; ll: hasMethod resource: Exact-PH4d4187a08c3ba4c1cf0d ; ll: hasMethod resource: TIME_DELTA-PHe40547b9d3b6381347b4 ; ll: hasMethod resource: LEVENSHTEIN_APPROX-PH10f4c17bbf933cae647f ; ll: hasMethod resource: BLOOTHOOFT_REDUCT-PH98a9575087817b951447 ; ll: hasFormulaDescription \" resource: TIME_DELTA-PHe40547b9d3b6381347b4 AND resource: TIME_DELTA-PHfdc744f6bd0ced4e283a AND ( resource: Exact-PH4d4187a08c3ba4c1cf0d OR ( resource: BLOOTHOOFT_REDUCT-PH98a9575087817b951447 AND resource: BLOOTHOOFT_REDUCT-PH10433274b57dafdd1335 ) OR ( resource: Exact-PH6491d1db6855098a70be AND ( resource: LL_SOUNDEX-PH0ad3ad579d7a29347753 AND resource: LEVENSHTEIN_APPROX-PH10f4c17bbf933cae647f ) ) ) \"@en . ################################################################################ # METHOD SIGNATURES # ################################################################################ ### METHOD SPECIFICATIONS TIME_DELTA resource: TIME_DELTA-PHe40547b9d3b6381347b4 a ll: MatchingMethod ; ll: hasAlgorithm resource: TIME_DELTA ; ll: hasThresholdRange \"\u2115\" ; ### SOURCE PREDICATE CONFIGURATION ll: hasSubjResourceSelection resource: ResourceSelection-PHbe38976fdf884b6c4a8e ; ll: hasSubjResourceSelection resource: ResourceSelection-PHe8fa664d04ad00aaa697 ; ### TARGET PREDICATE CONFIGURATION ll: hasObjResourceSelection resource: ResourceSelection-PH71818c17d54a8fbec22b ; ll: hasObjResourceSelection resource: ResourceSelection-PHc8a3c6e494d230b79a6b . \u2022\u2022\u2022 3.1.3 Linkset \u00b6 This step documents a linkset metadata including WHAT - HOW - WHEN - WHO and other processes explaining the aboutness of links. The Matching Formulation specifies HOW entities are matched and Resource Selection specifies WHAT to match as subject and object targets. Also some statistic on the matching results can be reported such as the number of links found, the numbers of entities linked, WHO created the linkset and WHEN . Finally, a Validation entity can also be specified, comprising metadata with statitics and auhtority information on the validation process. Observe that when one or more validations are provided, statistics on this matter can be included in the linkset metadata, including eventual contradictions if one validation says a link is correct while another says it is not. As discussed earlier in this section, according to the [ VoID ] documentation, the void:Linkset definition expects as datasources exactly one source and one target, different from each other. This means it is more restrictive than the ll:Linkset here proposed, since the latter also expects a linkset to contain links within a datasource or across more than two. Therefore, we do not directly reuse that concept (and its correspoding properties void:subjects/objectsTarget). Naturally, one could still use void:Linkset for other purposes, but at the risk of abusing the VoID vocabulary if its instances do not really fit the required restrictions. Moreover, a void:Linkset (i.e. a resource representing a linkset\u2019s metadata) is also not an instance of ll:Linkset since the later requires the description of the processes underlying the creation of the links, which is not the case for the first. Fig 5: Specifying the linkset\u2019s context Example 3: A linkset annotation ### LINKSET 15 linkset : 15 a ll: Linkset ; void: feature format: Turtle ; cc: attributionName \"LenticularLens\" @ en ; cc: license <http://purl.org/NET/rdflicense/W3C1.0> ; dcterms: created \"2020-09-26T09:37:23.933624\" ^^ <http://www.w3.org/2001/XMLSchema#dateTime> ; dcterms: creator \"AL IDRISSOU\" ; dcterms: creator \"GoldenAgents\" ; void: linkPredicate owl: sameAs ; rdfs: label \"Linkset 9\" @ en ; dcterms: description \"LINSET-15-9: Test Baptism against Marriage and burial with several nested methods \" @ en ; ### VOID LINKSET STATS void: entities 12580 ; ### LENTICULAR LENS LINKSET STATS ### SOURCE ENTITY TYPE SELECTION(S) ll: subjectsTarget resource: ResourceSelection-2 ; ### TARGET ENTITY TYPE SELECTION(S) ll: objectsTarget resource: ResourceSelection-1 ; ll: objectsTarget resource: ResourceSelection-3 ; ### THE LOGIC FORMULA ll: hasLogicFormulation resource: PHb6e5e320dc08d7d9dd98 . 3.1.4 Lens \u00b6 Another process relevant to document is the creation of Lenses. In short, a lens is the result of a set-like operation over one or more Linkset and or Lens. Therefore, the entity Lens documents them as ll:hasTarget Fig 6: Specifying the linkset\u2019s context Example 4: A lens annotation 3.3 VoID+ Ontology \u00b6 This section provides a complete and detailed description of the VoID+ extension. First the model is presented in two parts: partitions of void:Dataset and the link-datasets as special sub-types of void:Dataset. In the sequel the documention extracted from the owl file is presented. Partitions of void:Dataset \u00b6 Figure 7 presents on the left hand side a view on the classes, their hierarchy and how they are connected via object properties. This provides a very straightforward undestanding of how the class void:Dataset is extended. A void:Dataset that is defined as a subset of another one is called void+:Partition. Three types of void+:Partition are distinguished according to the type of partition that is used: (i) a void+:ClassPartition is partioned by a rdfs:Class; (ii) a void+:PropertyPartition is partioned by a rdf:Property or by a rdf:Seq defining a sequence of two or more of them; and (iii) a void+:Language partition is partioned by a language given by a standardized ISO langague code. Another special type of partition is a void+:ResourceSelection which is defined by one or more partions of the type above described. The right hand side of Figure 7 presents a hierarchy of properties in order to provide an undestanding of how some of the VoID properties are extended. On the one hand, the propery void:subset and its subproperties are extended more to provide a directional/non-ambiguos reading. On the other and, void:class and void:property are grouped into a superclass void+:partionedBy which also includes void:language to allow for one more type of partition. In particular, void:property is extended with a more generic relation void+:property that allows for describing a seequence of properties like in a property path. Fig 7: VoID+ Extension on the void:Dataset Link-datasets as special sub-types of void:Dataset \u00b6 Figure 8 presents on the left hand side a view on the classes, their hierarchy and how they are connected via object properties. This provides a very straightforward undestanding of how the class void:Linkset is extended. It is extended with superclasses that are less restrictive with respect with its targets. First, a void+:LinkDataset is a void:Dataset that contains links that may have been stabilished among one (deduplication), two or many datasets. When the creation of void+:LinkDataset is such that imposes that subjects always belong to the same datasets as well as objects, this is called void+:DirectedLinkDataset. This is the case for both void:Linkset but also for our definition of void+:Linkset. The former, however, requires excelty one dataset as target for its subjects and onther as target for its objects. In addition, our definition of void+:Linkset is also a void+:DocumentedLinkDataset, which requires more detailed documentation, including targets described as void+:ResourceSelection (all values from) and a void+:Formulation\u2026 A void+:Lens is also a void+:DocumentedLinkDataset which has one void:LensFormulation that specifies which void:LinkDatasets are combined and how. The right hand side of Figure 8 presents a hierarchy of properties in order to provide an undestanding of how void:target and its subproperties are extended. They actually are extended with superclasses having as range not only a void:Linkset but its superclass void+:LinkDataset. Fig 8: \u2026 3.3.1 OWL Ontology Documentation \u00b6 Classes \u00b6 Class Purpose ll:ResourceSelection A ResourceSelection is a collection of resources stemmed from the same dataset and partitioned on the basis of a given class and optionally a number of predicates having there respective predicate-value(s) enforced within a pre-defined range. ll:PropertyConstraint A PropertyConstraint is a resource that maps an explicitly defined property-path to a value-range constraint . In this way, resources that are described with the mapped property-path are to pass the value-range constraint test to be selected for further processing. Such a property-path can be (i) a sequence of properties only or (ii) a more precise path where a class is associated to a property in the following pattern: <:property>/<:class>/<:property>/../<:class>/<:property> \\text{<:property>/<:class>/<:property>/../<:class>/<:property>} <:property>/<:class>/<:property>/../<:class>/<:property> . ll:MatchingMethod A MatchingMethod is a resource that makes explicit all pre-requisites of a matching algorithm including the conditions in which the algorithm is to accept a discovered link (threshold). ll:MatchingFormulation A MatchingFormulation is a resource that makes explicit all matching-methods involved in the creation of a Linkset and how the methods logically work jointly. ll:Linkset In [ VoID ], a Linkset is a collection of RDF links between two datasets where all subjects stem from one dataset and all objects from the other dataset. In here, we alleviate such strict restriction on the number of linked datasets to be one, two or more. Therefore, here a linkset is a collection of RDF links between dataset(s), using the same link predicate (regardless of the link being an equality predicate or not). This predicate is called the linktype of the linkset. ll:Lens Content-wise , a Lens is a type of RDF linkset (in the sense that it is a collection of links sharing the same linktype) also involving one, two or more datasets. However, context-wise , it differs from a linkset as it is generated using different process (set-like link manipulation operators such as Union, Intersection, Difference or Transitivity) as compared to how a linkset comes about (matching algorithms). Properties \u00b6 ResourceSelection Property Purpose rdfs:label void:subset void:classPartition void:propertyPartition ll:hasFormulaDescription MatchingMethod Property Purpose ll:hasAlgorithm ll:hasThresholdRange ll:hasSubjResourceSelection ll:hasObjResourceSelection PropertyConstraint Property Purpose void:property ll:hasFilterFunction ll:hasValueFunction ll:hasFormatFunction MatchingFormulation Property Purpose ll:hasMethod ll:hasFormulaDescription Linkset Property Purpose cc:attributionName cc:license dcterms:created dcterms:creator dcterms:description ll:subjectsTarget ll:objectsTarget ll:hasLogicFormulation Lens Property Purpose cc:attributionName cc:license dcterms:created dcterms:creator dcterms:description ll:subjectsTarget ll:objectsTarget ll:target ll:hasLogicFormulation","title":"3. ONTOLOGY"},{"location":"03.Ontology%20copy/#3-ontology","text":"This section presents an Ontology meant for describing processes of generation and validation of links in detail, so that decisions made such as resource selections and matching options are made explicit. Those processes are implemented in the Lenticular Lens tool and result in the creation of Linksets or Lenses according to a specification. we call the proposed ontology VoID+ as it is proposed as an extension of the [ VoID ] vocabulary. The next section presents the motivation for such extension while Section 3.2 and Section 3.3 respectively present the main elements proposed as extension for VoID and the complete and detailed description of the VoID+ extension.","title":"3. ONTOLOGY"},{"location":"03.Ontology%20copy/#31-motivation-to-extend-void","text":"The model presented in Figure 1 is created based on the [ VoID ] documentation, and owl-ontology description , where ellipses represent classes, thick arrows represent subclass or subproperty relations (hierarchy) and thin arrows represent properties. Fig 1: The Lenticular Lens Ontology The presented model only contains classes and relations of interest, namely: Vocabulary Description void:Dataset A set of RDF triples that are published, maintained or aggregated by a single provider. void:Linkset A collection of RDF links between two void:Datasets. void:subset has subset. Domain : void:Dataset Range : void:Dataset void:classPartition A relation between a void:Dataset and its Partition, which is a subset of a void:Dataset that contains only entities of an explicitly defined rdfs:Class. Domain : void:Dataset Range : void:Dataset void:propertyPartition A relation between a void:Dataset and its Partition, which is a subset of a void:Dataset that contains only triples composed with an explicitly defined rdf:Property. Domain : void:Dataset Range : void:Dataset void:class A relation that assigns to a void:Dataset a rdfs:Class that is the rdf:type of all entities in a class-based partition. Domain : void:Dataset Range : rdfs:Class ( exactly 1 ) void:property A relation that assigns to a void:Dataset a rdf:Property that is the predicate of all triples in a property-based partition. Domain : void:Dataset Range : rdfs:Property ( exactly 1 ) void:target A relation that assigns one of the two datasets linked by the Linkset. Domain : void:Linkset Range : void:Dataset ( exactly 2 ) void:subjectsTarget A relation that assigns the dataset describing the subjects of triples contained in the Linkset. Domain : void:Linkset Range : void:Dataset ( exactly 1 ) void:objectsTarget A relation that assigns the dataset describing the objects of the triples contained in the Linkset. Domain : void:Linkset Range : void:Dataset ( exactly 1 ) The [ VoID ] vocabulary provides means to describe datasets and linksets, but with limitations. The first important limitation that motivates our proposal for extenstion is that a void:Linkset is too restrictive, since it is necessarily directed and holds between exact two (different) datasets. It also does not describe the details of how they were generated, nor it provides means to describe Lenses or Validations . The next limitation is the vague descriptions of subsets or partitions of a void:Dataset . This concept is in our theory very important and requires more clarity and expressivity. Those issues are further discussed in the next section.","title":"3.1 Motivation to extend VoID"},{"location":"03.Ontology%20copy/#32-main-elements-for-void","text":"This section presents the main elements proposed as extension for VoID . It provides a simplified take of VoID+ describing all the classes and proporties that are of importance in this work in this part the hierarchical relations among the classes are ommited. The complete and detailed description of the VoID+ extension is provided in the next section, including a visualisation and the documention extracted from the owl file. The partial model depicted in Fig. 2 highlights in yellow the use of [ VoID ] terms and in blue the new terminology VoID+. In order to describe the proposed ontology, we dissect Fig 2 into four parts. First, a Resource Selection is elucidated. Second, we go about describing a Matching Formulation and show how it connects with a Resource Selection . The third step highlights that the description of a Linkset metadata involves specifying the Resource Selections used at the source and target positions of an entity matching process, the Matching Formulation , eventual validations plus statistics and authority information. The fourth and final step focuses on the annotation of a Lens by describing the combination of one or more Linksets and/or Lenses. Fig 2: The Lenticular Lens Ontology","title":"3.2 Main Elements for VoID+"},{"location":"03.Ontology%20copy/#321-resource-selection","text":"This step concerns the selection of the resources under scrutiny , that can potentially end up co-referent entities across or within datasources during an entity matching process. To therefore perform a matching, one first needs not only to select datasource(s) but also restrict which resources will undergo the matching. The first way of doing so is by applying a type (class) restriction. This is mandatory in the Lenticular Lens process as matching algorithms are not fully automated. Down this line, further restrictions can be applied by forcing the value of a number of properties to lie within a certain range. A Resource Selection is thereby, the annotation of such process. In the ontology excerpt depicted in Figure 3 we propose the entity type Resource Selection , which is also a void:Dataset that is a void:subset of one or more void:Dataset(s) . It can also have further restrictions defined as void:classPartion and/or void:propertyPartition . While a void:classPartion solely consists in specifying the type of entity under scrutiny, the void:propertyPartition entails a little more. It consists in specifying a property or property path and a restriction that the selected property should undergo for the selection of the right entities for the further down the road entity matching process. Those restrictions can be combined using a Formula Description given by ll:hasFormulaDescription . Fig 3: Selecting a matching resource Example 1 : Resource Selection In this example, the entity resource:ResourceSelection-2 is a ll:ResourceSelection (and a void:Dataset ) subset of resource:index_op_doopregister_raw_20190830 and also a collection (partition) of entities of type pnv:PersonName where each entity passed the filter test of (1) name in the English language which appears without trailing dots \"%...%\"@en and (2) birthdates within the interval [1600, 1699] . the entity resource:ResourceSelection-2 lists all three entities of type ll:PropertyConstraint and elaborates on the logic expression that binds all restrictions. For example, the property restriction described by resource:PropertyConstraint-PHce78383e3ff6e9dd73b6 documents that, applying the date function \"minimal_date\"@en over dates in the format the \"YYYY-MM-DD\"@en with the year restriction of 1600 makes sure that only persons born on 1600 onwards are admitted. Turtle Syntax When ever a literal in RDF syntax conatins quote or new line characters, the litreal should be in a three quote syntax ( \"...\"\"@en ). In the example below, we deliberately wrote the literal value of ll:hasFormulaDescription is in a single quote ( \"...\"\"@en ) instead of a triple quote ( \"\"\"%...%=\"\"\"@en ) as the syntax highliter is somewhat buggy. ### RESOURCE 2 resource: ResourceSelection-2 a void: dataset , ll: ResourceSelection ; rdfs: label \"Baptisms in the 17th Century\" @ en ; void: subset resource: index_op_doopregister_raw_20190830 ; void: classPartition [ void: class pnv: PersonName ] ; void: propertyPartition resource: PropertyConstraint-PHea6802ef02f99a848859 ; void: propertyPartition resource: PropertyConstraint-PHce78383e3ff6e9dd73b6 ; void: propertyPartition resource: PropertyConstraint-PH2580641bbdd572759cb9 ; ll: hasFormulaDescription \" resource: PropertyConstraint-PHce78383e3ff6e9dd73b6 AND resource: PropertyConstraint-PH2580641bbdd572759cb9 AND ( resource: PropertyConstraint-PHea6802ef02f99a848859 ) \"@en . resource: PropertyConstraint-PHea6802ef02f99a848859 a ll: PropertyConstraint ; void: property [ a rdfs: Sequence ; rdf : _ 1 pnv: literalName ] ; ll: hasFilterFunction \"not_ilike\" @ en ; ll: hasValueFunction \"%...%\" @ en . resource: PropertyConstraint-PHce78383e3ff6e9dd73b6 a ll: PropertyConstraint ; void: property [ a rdfs: Sequence ; rdf : _ 1 saa: isInRecord ; rdf : _ 2 saa: IndexOpDoopregisters ; rdf : _ 3 saa: birthDate ] ; ll: hasFilterFunction \"minimal_date\" @ en ; ll: hasValueFunction 1600 ; ll: hasFormatFunction \"YYYY-MM-DD\" @ en . resource: PropertyConstraint-PH2580641bbdd572759cb9 a ll: PropertyConstraint ; void: property [ a rdfs: Sequence ; rdf : _ 1 saa: isInRecord ; rdf : _ 2 saa: IndexOpDoopregisters ; rdf : _ 3 saa: birthDate ] ; ll: hasFilterFunction \"maximum_date\" @ en ; ll: hasValueFunction \"1699\" @ en ; ll: hasFormatFunction \"YYYY-MM-DD\" @ en .","title":"3.2.1 Resource Selection"},{"location":"03.Ontology%20copy/#312-matching-formulation","text":"For simple matching problems, finding co-referents can be done using a single matching algorithm (matcher). However, time and again the data reality often imposes the use of more than one matcher instead. In this latter scenario, clearly reporting on how these matchers work together for detecting co-referents is essential. A Matching Formulation entity is a resource for just doing the aforementioned, as depicted in Figure 4. Once resources of type Resource Restriction are created, one can go ahead and used them for specifying the restricted collections to be used in a particular Matching Method , which also specifies the Matching Algorithm and its parameters such as threshold, range and operrator. In the end, all Matching Methods used in a matching process are documented in the Matching Formulation resource as well as how they bind together in a logic expression given by the predicate ll:hasFormulaDescription . Fig 4: Specifying the way in which methods are logically combined Example 2 : Linkset Logic Expression In Example 2.8, the resource:PHb99da2ecd91ad533af65 is a ll:MatchingFormulation listing eight ll:MatchingMethods used for creating a linkset. They their logic combination is described as ll:hasFormulaDescription . Among the ll:MatchingMethods , the resource:TIME_DELTA-PHfdc744f6bd0ced4e283a is the only method detailes in this example, documenting the four ll:ResourceSelections involved, as well as the chosen ll:MatchingAlgorithm , namely resource:TIME_DELTA , besides the threshold (20), threshold-unit (\u201cYear\u201d@en), threshold-operator (>=) and threshold-range \u201c\u2115\u201d of the matching method. Turtle Syntax When ever a literal in RDF syntax conatins quote or new line characters, the litreal should be in a three quote syntax ( \"...\"\"@en ). In the example below, we deliberately wrote the literal value of ll:hasFormulaDescription is in a single quote ( \"...\"\"@en ) instead of a triple quote ( \"\"\"%...%=\"\"\"@en ) as the syntax highliter is somewhat buggy. ################################################################################ # LINKSET LOGIC EXPRESSION # ################################################################################ resource: PHb99da2ecd91ad533af65 a ll: MatchingFormulation ; ll: hasMethod resource: TIME_DELTA-PHfdc744f6bd0ced4e283a ; ll: hasMethod resource: Exact-PH6491d1db6855098a70be ; ll: hasMethod resource: LL_SOUNDEX-PH0ad3ad579d7a29347753 ; ll: hasMethod resource: BLOOTHOOFT_REDUCT-PH10433274b57dafdd1335 ; ll: hasMethod resource: Exact-PH4d4187a08c3ba4c1cf0d ; ll: hasMethod resource: TIME_DELTA-PHe40547b9d3b6381347b4 ; ll: hasMethod resource: LEVENSHTEIN_APPROX-PH10f4c17bbf933cae647f ; ll: hasMethod resource: BLOOTHOOFT_REDUCT-PH98a9575087817b951447 ; ll: hasFormulaDescription \" resource: TIME_DELTA-PHe40547b9d3b6381347b4 AND resource: TIME_DELTA-PHfdc744f6bd0ced4e283a AND ( resource: Exact-PH4d4187a08c3ba4c1cf0d OR ( resource: BLOOTHOOFT_REDUCT-PH98a9575087817b951447 AND resource: BLOOTHOOFT_REDUCT-PH10433274b57dafdd1335 ) OR ( resource: Exact-PH6491d1db6855098a70be AND ( resource: LL_SOUNDEX-PH0ad3ad579d7a29347753 AND resource: LEVENSHTEIN_APPROX-PH10f4c17bbf933cae647f ) ) ) \"@en . ################################################################################ # METHOD SIGNATURES # ################################################################################ ### METHOD SPECIFICATIONS TIME_DELTA resource: TIME_DELTA-PHe40547b9d3b6381347b4 a ll: MatchingMethod ; ll: hasAlgorithm resource: TIME_DELTA ; ll: hasThresholdRange \"\u2115\" ; ### SOURCE PREDICATE CONFIGURATION ll: hasSubjResourceSelection resource: ResourceSelection-PHbe38976fdf884b6c4a8e ; ll: hasSubjResourceSelection resource: ResourceSelection-PHe8fa664d04ad00aaa697 ; ### TARGET PREDICATE CONFIGURATION ll: hasObjResourceSelection resource: ResourceSelection-PH71818c17d54a8fbec22b ; ll: hasObjResourceSelection resource: ResourceSelection-PHc8a3c6e494d230b79a6b . \u2022\u2022\u2022","title":"3.1.2 Matching Formulation"},{"location":"03.Ontology%20copy/#313-linkset","text":"This step documents a linkset metadata including WHAT - HOW - WHEN - WHO and other processes explaining the aboutness of links. The Matching Formulation specifies HOW entities are matched and Resource Selection specifies WHAT to match as subject and object targets. Also some statistic on the matching results can be reported such as the number of links found, the numbers of entities linked, WHO created the linkset and WHEN . Finally, a Validation entity can also be specified, comprising metadata with statitics and auhtority information on the validation process. Observe that when one or more validations are provided, statistics on this matter can be included in the linkset metadata, including eventual contradictions if one validation says a link is correct while another says it is not. As discussed earlier in this section, according to the [ VoID ] documentation, the void:Linkset definition expects as datasources exactly one source and one target, different from each other. This means it is more restrictive than the ll:Linkset here proposed, since the latter also expects a linkset to contain links within a datasource or across more than two. Therefore, we do not directly reuse that concept (and its correspoding properties void:subjects/objectsTarget). Naturally, one could still use void:Linkset for other purposes, but at the risk of abusing the VoID vocabulary if its instances do not really fit the required restrictions. Moreover, a void:Linkset (i.e. a resource representing a linkset\u2019s metadata) is also not an instance of ll:Linkset since the later requires the description of the processes underlying the creation of the links, which is not the case for the first. Fig 5: Specifying the linkset\u2019s context Example 3: A linkset annotation ### LINKSET 15 linkset : 15 a ll: Linkset ; void: feature format: Turtle ; cc: attributionName \"LenticularLens\" @ en ; cc: license <http://purl.org/NET/rdflicense/W3C1.0> ; dcterms: created \"2020-09-26T09:37:23.933624\" ^^ <http://www.w3.org/2001/XMLSchema#dateTime> ; dcterms: creator \"AL IDRISSOU\" ; dcterms: creator \"GoldenAgents\" ; void: linkPredicate owl: sameAs ; rdfs: label \"Linkset 9\" @ en ; dcterms: description \"LINSET-15-9: Test Baptism against Marriage and burial with several nested methods \" @ en ; ### VOID LINKSET STATS void: entities 12580 ; ### LENTICULAR LENS LINKSET STATS ### SOURCE ENTITY TYPE SELECTION(S) ll: subjectsTarget resource: ResourceSelection-2 ; ### TARGET ENTITY TYPE SELECTION(S) ll: objectsTarget resource: ResourceSelection-1 ; ll: objectsTarget resource: ResourceSelection-3 ; ### THE LOGIC FORMULA ll: hasLogicFormulation resource: PHb6e5e320dc08d7d9dd98 .","title":"3.1.3 Linkset"},{"location":"03.Ontology%20copy/#314-lens","text":"Another process relevant to document is the creation of Lenses. In short, a lens is the result of a set-like operation over one or more Linkset and or Lens. Therefore, the entity Lens documents them as ll:hasTarget Fig 6: Specifying the linkset\u2019s context Example 4: A lens annotation","title":"3.1.4 Lens"},{"location":"03.Ontology%20copy/#33-void-ontology","text":"This section provides a complete and detailed description of the VoID+ extension. First the model is presented in two parts: partitions of void:Dataset and the link-datasets as special sub-types of void:Dataset. In the sequel the documention extracted from the owl file is presented.","title":"3.3 VoID+ Ontology"},{"location":"03.Ontology%20copy/#partitions-of-voiddataset","text":"Figure 7 presents on the left hand side a view on the classes, their hierarchy and how they are connected via object properties. This provides a very straightforward undestanding of how the class void:Dataset is extended. A void:Dataset that is defined as a subset of another one is called void+:Partition. Three types of void+:Partition are distinguished according to the type of partition that is used: (i) a void+:ClassPartition is partioned by a rdfs:Class; (ii) a void+:PropertyPartition is partioned by a rdf:Property or by a rdf:Seq defining a sequence of two or more of them; and (iii) a void+:Language partition is partioned by a language given by a standardized ISO langague code. Another special type of partition is a void+:ResourceSelection which is defined by one or more partions of the type above described. The right hand side of Figure 7 presents a hierarchy of properties in order to provide an undestanding of how some of the VoID properties are extended. On the one hand, the propery void:subset and its subproperties are extended more to provide a directional/non-ambiguos reading. On the other and, void:class and void:property are grouped into a superclass void+:partionedBy which also includes void:language to allow for one more type of partition. In particular, void:property is extended with a more generic relation void+:property that allows for describing a seequence of properties like in a property path. Fig 7: VoID+ Extension on the void:Dataset","title":"Partitions of void:Dataset"},{"location":"03.Ontology%20copy/#link-datasets-as-special-sub-types-of-voiddataset","text":"Figure 8 presents on the left hand side a view on the classes, their hierarchy and how they are connected via object properties. This provides a very straightforward undestanding of how the class void:Linkset is extended. It is extended with superclasses that are less restrictive with respect with its targets. First, a void+:LinkDataset is a void:Dataset that contains links that may have been stabilished among one (deduplication), two or many datasets. When the creation of void+:LinkDataset is such that imposes that subjects always belong to the same datasets as well as objects, this is called void+:DirectedLinkDataset. This is the case for both void:Linkset but also for our definition of void+:Linkset. The former, however, requires excelty one dataset as target for its subjects and onther as target for its objects. In addition, our definition of void+:Linkset is also a void+:DocumentedLinkDataset, which requires more detailed documentation, including targets described as void+:ResourceSelection (all values from) and a void+:Formulation\u2026 A void+:Lens is also a void+:DocumentedLinkDataset which has one void:LensFormulation that specifies which void:LinkDatasets are combined and how. The right hand side of Figure 8 presents a hierarchy of properties in order to provide an undestanding of how void:target and its subproperties are extended. They actually are extended with superclasses having as range not only a void:Linkset but its superclass void+:LinkDataset. Fig 8: \u2026","title":"Link-datasets as special sub-types of void:Dataset"},{"location":"03.Ontology%20copy/#331-owl-ontology-documentation","text":"","title":"3.3.1 OWL Ontology Documentation"},{"location":"03.Ontology%20copy/#classes","text":"Class Purpose ll:ResourceSelection A ResourceSelection is a collection of resources stemmed from the same dataset and partitioned on the basis of a given class and optionally a number of predicates having there respective predicate-value(s) enforced within a pre-defined range. ll:PropertyConstraint A PropertyConstraint is a resource that maps an explicitly defined property-path to a value-range constraint . In this way, resources that are described with the mapped property-path are to pass the value-range constraint test to be selected for further processing. Such a property-path can be (i) a sequence of properties only or (ii) a more precise path where a class is associated to a property in the following pattern: <:property>/<:class>/<:property>/../<:class>/<:property> \\text{<:property>/<:class>/<:property>/../<:class>/<:property>} <:property>/<:class>/<:property>/../<:class>/<:property> . ll:MatchingMethod A MatchingMethod is a resource that makes explicit all pre-requisites of a matching algorithm including the conditions in which the algorithm is to accept a discovered link (threshold). ll:MatchingFormulation A MatchingFormulation is a resource that makes explicit all matching-methods involved in the creation of a Linkset and how the methods logically work jointly. ll:Linkset In [ VoID ], a Linkset is a collection of RDF links between two datasets where all subjects stem from one dataset and all objects from the other dataset. In here, we alleviate such strict restriction on the number of linked datasets to be one, two or more. Therefore, here a linkset is a collection of RDF links between dataset(s), using the same link predicate (regardless of the link being an equality predicate or not). This predicate is called the linktype of the linkset. ll:Lens Content-wise , a Lens is a type of RDF linkset (in the sense that it is a collection of links sharing the same linktype) also involving one, two or more datasets. However, context-wise , it differs from a linkset as it is generated using different process (set-like link manipulation operators such as Union, Intersection, Difference or Transitivity) as compared to how a linkset comes about (matching algorithms).","title":"Classes"},{"location":"03.Ontology%20copy/#properties","text":"ResourceSelection Property Purpose rdfs:label void:subset void:classPartition void:propertyPartition ll:hasFormulaDescription MatchingMethod Property Purpose ll:hasAlgorithm ll:hasThresholdRange ll:hasSubjResourceSelection ll:hasObjResourceSelection PropertyConstraint Property Purpose void:property ll:hasFilterFunction ll:hasValueFunction ll:hasFormatFunction MatchingFormulation Property Purpose ll:hasMethod ll:hasFormulaDescription Linkset Property Purpose cc:attributionName cc:license dcterms:created dcterms:creator dcterms:description ll:subjectsTarget ll:objectsTarget ll:hasLogicFormulation Lens Property Purpose cc:attributionName cc:license dcterms:created dcterms:creator dcterms:description ll:subjectsTarget ll:objectsTarget ll:target ll:hasLogicFormulation","title":"Properties"},{"location":"03.Ontology/","text":"ONTOLOGY \u00b6 This section presents an Ontology meant for describing processes of generation and validation of links in detail, so that decisions made such as resource selections and matching options are made explicit. Those processes are implemented in the Lenticular Lens tool and result in the creation of Linksets or Lenses according to a specification. we call the proposed ontology VoID+ as it is proposed as an extension of the [ VoID ] vocabulary. The next section presents the motivation for such extension while Section 3.2 and Section 3.3 respectively present the main elements proposed as extension for VoID and the complete and detailed description of the VoID+ extension. 1. Motivation to extend VoID \u00b6 The model presented in Figure 1 is created based on the [ VoID ] documentation and owl-ontology description, where ellipses represent classes, thick arrows represent subclass or sub-property relations (hierarchy) and thin arrows represent properties. In this model, only classes and relations of interest are exhibit. The [ VoID ] vocabulary provides means to describe datasets and linksets, but with limitations. The first important limitation that motivates our proposal for extension is that void:Linkset is (1) too restrictive as it is directed and holds between exactly two non-identical datasets. Furthermore, (2) it also does not describe the details of how they were generated, nor it provides means to describe Lenses or Validations . The next limitation is (3) the ambiguate descriptions of subsets or partitions of a void:Dataset . This concept is in our theory very important and requires more clarity and expressivity. Those issues are further discussed in the next section. Fig 1: Excerpt of VoId Ontology regarding void:Dataset and void:Linkset. A description of the classes and properties exhibited in Fig 1 is available in the table below. Vocabulary Description void:Dataset A set of RDF triples that are published, maintained or aggregated by a single provider. void:Linkset A collection of RDF links between two void:Datasets. void:subset has subset. Domain : void:Dataset Range : void:Dataset void:classPartition A relation between a void:Dataset and its Partition, which is a subset of a void:Dataset that contains only entities of an explicitly defined rdfs:Class. Domain : void:Dataset Range : void:Dataset void:propertyPartition A relation between a void:Dataset and its Partition, which is a subset of a void:Dataset that contains only triples composed with an explicitly defined rdf:Property. Domain : void:Dataset Range : void:Dataset void:class A relation that assigns to a void:Dataset a rdfs:Class that is the rdf:type of all entities (subject) in a class-based partition. Domain : void:Dataset Range : rdfs:Class ( exactly 1 ) void:property A relation that assigns to a void:Dataset a rdf:Property that is the predicate of all triples in a property-based partition. Domain : void:Dataset Range : rdfs:Property ( exactly 1 ) void:target A relation that assigns one of the two datasets linked by the Linkset. Domain : void:Linkset Range : void:Dataset ( exactly 2 ) void:subjectsTarget A relation that assigns the dataset describing the subjects of triples contained in the Linkset. Domain : void:Linkset Range : void:Dataset ( exactly 1 ) void:objectsTarget A relation that assigns the dataset describing the objects of the triples contained in the Linkset. Domain : void:Linkset Range : void:Dataset ( exactly 1 ) 2. VoID+ Main Elements \u00b6 This section presents the main elements proposed as extension for VoID . It provides a simplified overview (Fig. 2) of VoID+ by (i) only describing the classes and properties that are of importance in this work and (ii) omitting hierarchical relations among classes. While the complete and detailed description of the VoID+ extension is provided in the next section, the complete ontology overview (figure) and the documentation extracted from the owl file are available in section 3.4. Fig 2: The Lenticular Lens Ontology The partial model of the simplified oberverview depicted in Fig. 2 highlights in yellow the use of [ VoID ] terms and in blue the new VoID+ terminology . In order to describe the proposed ontology, we dissect Fig 2 into four parts. First, a Resource Selection is elucidated. Second, we go about describing a Matching Formulation and show how it connects with a Resource Selection . The third step highlights that the description of a Linkset metadata involves specifying the Resource Selections used at the source and target positions of an entity matching process, the Matching Formulation , eventual validations plus statistics and authority information. The fourth and final step focuses on the annotation of a Lens by describing the combination of one or more Linksets and/or Lenses. 2.1 Resource Selection \u00b6 This step concerns the selection of the resources under scrutiny , that can potentially end up co-referent entities across or within datasources during an entity matching process. To therefore perform a matching, one first needs not only to select datasource(s) but also restrict which resources will undergo the matching. The first way of doing so is by applying a type (class) restriction. This is mandatory in the Lenticular Lens process as matching algorithms are not fully automated. Down this line, further restrictions can be applied by forcing the value of a number of properties to lie within a certain range. A Resource Selection is thereby, the annotation of such process. In the ontology excerpt depicted in Figure 3 we propose the entity type Resource Selection , which is also a void:Dataset that is a void:subset of one or more void:Dataset(s) . It can also have further restrictions defined as void:classPartion and/or void:propertyPartition . While a void:classPartion solely consists in specifying the type of entity under scrutiny, the void:propertyPartition entails a little more. It consists in specifying a property or property path and a restriction that the selected property should undergo for the selection of the right entities for the further down the road entity matching process. Those restrictions can be combined using a Formula Description given by ll:hasFormulaDescription . Fig 3: Selecting a matching resource Example 1 : Resource Selection In this example, the entity resource:ResourceSelection-2 is a ll:ResourceSelection (and a void:Dataset ) subset of resource:index_op_doopregister_raw_20190830 and also a collection (partition) of entities of type pnv:PersonName where each entity passed the filter test of (1) name in the English language which appears without trailing dots \"%...%\"@en and (2) birthdates within the interval [1600, 1699] . the entity resource:ResourceSelection-2 lists all three entities of type ll:PropertyConstraint and elaborates on the logic expression that binds all restrictions. For example, the property restriction described by resource:PropertyConstraint-PHce78383e3ff6e9dd73b6 documents that, applying the date function \"minimal_date\"@en over dates in the format the \"YYYY-MM-DD\"@en with the year restriction of 1600 makes sure that only persons born on 1600 onwards are admitted. Turtle Syntax When ever a literal in RDF syntax conatins quote or new line characters, the litreal should be in a three quote syntax ( \"...\"\"@en ). In the example below, we deliberately wrote the literal value of ll:hasFormulaDescription is in a single quote ( \"...\"\"@en ) instead of a triple quote ( \"\"\"%...%=\"\"\"@en ) as the syntax highliter is somewhat buggy. ### RESOURCE 2 resource: ResourceSelection-2 a void: dataset , ll: ResourceSelection ; rdfs: label \"Baptisms in the 17th Century\" @ en ; void: subset resource: index_op_doopregister_raw_20190830 ; void: classPartition [ void: class pnv: PersonName ] ; void: propertyPartition resource: PropertyConstraint-PHea6802ef02f99a848859 ; void: propertyPartition resource: PropertyConstraint-PHce78383e3ff6e9dd73b6 ; void: propertyPartition resource: PropertyConstraint-PH2580641bbdd572759cb9 ; ll: hasFormulaDescription \" resource: PropertyConstraint-PHce78383e3ff6e9dd73b6 AND resource: PropertyConstraint-PH2580641bbdd572759cb9 AND ( resource: PropertyConstraint-PHea6802ef02f99a848859 ) \"@en . resource: PropertyConstraint-PHea6802ef02f99a848859 a ll: PropertyConstraint ; void: property [ a rdfs: Sequence ; rdf : _ 1 pnv: literalName ] ; ll: hasFilterFunction \"not_ilike\" @ en ; ll: hasValueFunction \"%...%\" @ en . resource: PropertyConstraint-PHce78383e3ff6e9dd73b6 a ll: PropertyConstraint ; void: property [ a rdfs: Sequence ; rdf : _ 1 saa: isInRecord ; rdf : _ 2 saa: IndexOpDoopregisters ; rdf : _ 3 saa: birthDate ] ; ll: hasFilterFunction \"minimal_date\" @ en ; ll: hasValueFunction 1600 ; ll: hasFormatFunction \"YYYY-MM-DD\" @ en . resource: PropertyConstraint-PH2580641bbdd572759cb9 a ll: PropertyConstraint ; void: property [ a rdfs: Sequence ; rdf : _ 1 saa: isInRecord ; rdf : _ 2 saa: IndexOpDoopregisters ; rdf : _ 3 saa: birthDate ] ; ll: hasFilterFunction \"maximum_date\" @ en ; ll: hasValueFunction \"1699\" @ en ; ll: hasFormatFunction \"YYYY-MM-DD\" @ en . 2.2 Matching Formulation \u00b6 For simple matching problems, finding co-referents can be done using a single matching algorithm (matcher). However, time and again the data reality often imposes the use of more than one matcher instead. In this latter scenario, clearly reporting on how these matchers work together for detecting co-referents is essential. A Matching Formulation entity is a resource for just doing the aforementioned, as depicted in Figure 4. Once resources of type Resource Restriction are created, one can go ahead and used them for specifying the restricted collections to be used in a particular Matching Method , which also specifies the Matching Algorithm and its parameters such as threshold, range and operrator. In the end, all Matching Methods used in a matching process are documented in the Matching Formulation resource as well as how they bind together in a logic expression given by the predicate ll:hasFormulaDescription . Fig 4: Specifying the way in which methods are logically combined Example 2 : Linkset Logic Expression In Example 2.8, the resource:PHb99da2ecd91ad533af65 is a ll:MatchingFormulation listing eight ll:MatchingMethods used for creating a linkset. They their logic combination is described as ll:hasFormulaDescription . Among the ll:MatchingMethods , the resource:TIME_DELTA-PHfdc744f6bd0ced4e283a is the only method detailes in this example, documenting the four ll:ResourceSelections involved, as well as the chosen ll:MatchingAlgorithm , namely resource:TIME_DELTA , besides the threshold (20), threshold-unit (\u201cYear\u201d@en), threshold-operator (>=) and threshold-range \u201c\u2115\u201d of the matching method. Turtle Syntax When ever a literal in RDF syntax conatins quote or new line characters, the litreal should be in a three quote syntax ( \"...\"\"@en ). In the example below, we deliberately wrote the literal value of ll:hasFormulaDescription is in a single quote ( \"...\"\"@en ) instead of a triple quote ( \"\"\"%...%=\"\"\"@en ) as the syntax highliter is somewhat buggy. ###################################################### # LINKSET LOGIC EXPRESSION # ###################################################### resource: PHb99da2ecd91ad533af65 a ll: MatchingFormulation ; ll: hasMethod resource: TIME_DELTA-PHfdc744f6bd0ced4e283a ; ll: hasMethod resource: Exact-PH6491d1db6855098a70be ; ll: hasMethod resource: LL_SOUNDEX-PH0ad3ad579d7a29347753 ; ll: hasMethod resource: BLOOTHOOFT_REDUCT-PH10433274b57dafdd1335 ; ll: hasMethod resource: Exact-PH4d4187a08c3ba4c1cf0d ; ll: hasMethod resource: TIME_DELTA-PHe40547b9d3b6381347b4 ; ll: hasMethod resource: LEVENSHTEIN_APPROX-PH10f4c17bbf933cae647f ; ll: hasMethod resource: BLOOTHOOFT_REDUCT-PH98a9575087817b951447 ; ll: hasFormulaDescription \" resource: TIME_DELTA-PHe40547b9d3b6381347b4 AND resource: TIME_DELTA-PHfdc744f6bd0ced4e283a AND ( resource: Exact-PH4d4187a08c3ba4c1cf0d OR ( resource: BLOOTHOOFT_REDUCT-PH98a9575087817b951447 AND resource: BLOOTHOOFT_REDUCT-PH10433274b57dafdd1335 ) OR ( resource: Exact-PH6491d1db6855098a70be AND ( resource: LL_SOUNDEX-PH0ad3ad579d7a29347753 AND resource: LEVENSHTEIN_APPROX-PH10f4c17bbf933cae647f ) ) ) \"@en . ###################################################### # METHOD SIGNATURES # ###################################################### ### METHOD SPECIFICATIONS TIME_DELTA resource: TIME_DELTA-PHe40547b9d3b6381347b4 a ll: MatchingMethod ; ll: hasAlgorithm resource: TIME_DELTA ; ll: hasThresholdRange \"\u2115\" ; ### SOURCE PREDICATE CONFIGURATION ll: hasSubjResourceSelection resource: ResourceSelection-PHbe38976fdf884b6c4a8e ; ll: hasSubjResourceSelection resource: ResourceSelection-PHe8fa664d04ad00aaa697 ; ### TARGET PREDICATE CONFIGURATION ll: hasObjResourceSelection resource: ResourceSelection-PH71818c17d54a8fbec22b ; ll: hasObjResourceSelection resource: ResourceSelection-PHc8a3c6e494d230b79a6b . \u2022\u2022\u2022 2.3 Linkset \u00b6 This step documents a linkset metadata including WHAT - HOW - WHEN - WHO and other processes explaining the aboutness of links. The Matching Formulation specifies HOW entities are matched and Resource Selection specifies WHAT to match as subject and object targets. Also some statistic on the matching results can be reported such as the number of links found, the numbers of entities linked, WHO created the linkset and WHEN . Finally, a Validation entity can also be specified, comprising metadata with statitics and auhtority information on the validation process. Observe that when one or more validations are provided, statistics on this matter can be included in the linkset metadata, including eventual contradictions if one validation says a link is correct while another says it is not. As discussed earlier in this section, according to the [ VoID ] documentation, the void:Linkset definition expects as datasources exactly one source and one target, different from each other. This means it is more restrictive than the ll:Linkset here proposed, since the latter also expects a linkset to contain links within a datasource or across more than two. Therefore, we do not directly reuse that concept (and its correspoding properties void:subjects/objectsTarget). Naturally, one could still use void:Linkset for other purposes, but at the risk of abusing the VoID vocabulary if its instances do not really fit the required restrictions. Moreover, a void:Linkset (i.e. a resource representing a linkset\u2019s metadata) is also not an instance of ll:Linkset since the later requires the description of the processes underlying the creation of the links, which is not the case for the first. Fig 5: Specifying the linkset\u2019s context Example 3: A linkset annotation ### LINKSET 15 linkset : 15 a ll: Linkset ; void: feature format: Turtle ; cc: attributionName \"LenticularLens\" @ en ; cc: license <http://purl.org/NET/rdflicense/W3C1.0> ; dcterms: created \"2020-09-26T09:37:23.933624\" ^^ <http://www.w3.org/2001/XMLSchema#dateTime> ; dcterms: creator \"AL IDRISSOU\" ; dcterms: creator \"GoldenAgents\" ; void: linkPredicate owl: sameAs ; rdfs: label \"Linkset 9\" @ en ; dcterms: description \"LINSET-15-9: Test Baptism against Marriage and burial with several nested methods \" @ en ; ### VOID LINKSET STATS void: entities 12580 ; ### LENTICULAR LENS LINKSET STATS ### SOURCE ENTITY TYPE SELECTION(S) ll: subjectsTarget resource: ResourceSelection-2 ; ### TARGET ENTITY TYPE SELECTION(S) ll: objectsTarget resource: ResourceSelection-1 ; ll: objectsTarget resource: ResourceSelection-3 ; ### THE LOGIC FORMULA ll: hasLogicFormulation resource: PHb6e5e320dc08d7d9dd98 . 2.4 Lens \u00b6 Another process relevant to document is the creation of Lenses. In short, a lens is the result of a set-like operation over one or more Linkset and or Lens. Therefore, the entity Lens documents them as ll:hasTarget Fig 6: Specifying the linkset\u2019s context Example 4: A lens annotation 3. VoID+ Ontology \u00b6 This section discuses the complete and detailed description of the VoID+ extension in two parts. It first addresses the void+:Partition of void:Dataset. Second, it tackles the void+:LinkDataset which is considered a special sub-types of void:Dataset. The documentation extracted from the owl file is presented in the next section. 3.1 Partitions of void:Dataset \u00b6 The VoID vocabulary defines void:Dataset as a dataset superset but does make available a granularity of subsets for refined work. VoID+ extends the void:Dataset class by distinguishes between five subsets of void:Dataset. A void:Dataset that is defined as a subset of another one is called void+:Partition . Three types of void+:Partition are distinguished according to the type of partition that is used: (i) void+:ClassPartition : the dataset is the result of an rdfs:Class based-partition; (ii) void+:PropertyPartition : the dataset is the result of a rdf:Property or by a rdf:Seq \u2013 defining a sequence of two or more of properties \u2013 partition; (iii) void+:Language : the dataset is the result of a language partition given by a standardised ISO language code. Another special type of partition is the void+:ResourceSelection . It is defined by one or more partions of the type above described, Fig. 7 provides a straightforward understanding of how the class void:Dataset is extended. On its the left hand side, Fig. 7 presents a view on the classes, their hierarchy and how they are connected via object properties. On the one hand, the property void:subset and its sub-properties are extended such that they provide a directional non-ambiguous reading. On the other and, void:class and void:property are grouped into a superclass void+:partionedBy which also includes void:language to allow for one more type of partition. In particular, void:property is extended with a more generic relation void+:property that allows for describing a sequence of properties like in a property path. Fig 7: VoID+ Extension on the void:Dataset 3.2 VoID+ Link-datasets \u00b6 Figure 8 presents on the left hand side a view on the classes, their hierarchy and how they are connected via object properties. This provides a very straightforward understanding of how the class void:Linkset is extended. It is extended with superclasses that are less restrictive with respect with its targets. First, a void+:LinkDataset is a void:Dataset that contains links that may have been stabilished among one (deduplication), two or many datasets. When the creation of void+:LinkDataset is such that imposes that subjects always belong to the same datasets as well as objects, this is called void+:DirectedLinkDataset. This is the case for both void:Linkset but also for our definition of void+:Linkset. The former, however, requires excelty one dataset as target for its subjects and onther as target for its objects. In addition, our definition of void+:Linkset is also a void+:DocumentedLinkDataset, which requires more detailed documentation, including targets described as void+:ResourceSelection (all values from) and a void+:Formulation\u2026 A void+:Lens is also a void+:DocumentedLinkDataset which has one void:LensFormulation that specifies which void:LinkDatasets are combined and how. The right hand side of Figure 8 presents a hierarchy of properties in order to provide an undestanding of how void:target and its subproperties are extended. They actually are extended with superclasses having as range not only a void:Linkset but its superclass void+:LinkDataset. Fig 8: VoID+ Extension on the void:Linkset 3.3 VoID+ OWL \u00b6 Here, we provide a turtle description of the ontology. VoID+ @prefix : <http://lenticularlens.org/voidPlus#> . @prefix owl: <http://www.w3.org/2002/07/owl#> . @prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> . @prefix xml: <http://www.w3.org/XML/1998/namespace> . @prefix xsd: <http://www.w3.org/2001/XMLSchema#> . @prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> . @prefix void: <http://rdfs.org/ns/void#> . @prefix voidPlus: <http://lenticularlens.org/voidPlus/> . @base <http://lenticularlens.org/voidPlus> . <http://lenticularlens.org/voidPlus> rdf: type owl: Ontology . ################################################################# # Object Properties ################################################################# ### http://lenticularlens.org/voidPlus/hasAlgorithm voidPlus: hasAlgorithm rdf: type owl: ObjectProperty , owl: FunctionalProperty ; rdfs: domain voidPlus: MatchingMethod ; rdfs: range voidPlus: MatchingAlgorithm ; rdfs: comment \"relates a void+:MatchingMethod to its void+:MatchingAlgorithm.\" @ en . ### http://lenticularlens.org/voidPlus/hasClassPartition voidPlus: hasClassPartition rdf: type owl: ObjectProperty ; rdfs: subPropertyOf voidPlus: hasSubset , void: classPartition ; rdfs: comment \"relates a void:Dataset to its subset void+:ClassPartition. In practice, the main difference wrt void:classPartition is the name meant to avoid missusage as it can be read as \\\"is classPartition of\\\" as well.\" @ en . ### http://lenticularlens.org/voidPlus/hasFormulation voidPlus: hasFormulation rdf: type owl: ObjectProperty ; rdfs: domain voidPlus: LinkDataset ; rdfs: range voidPlus: Formulation ; rdfs: comment \"relates a void+:LinkDataset to its void+:Formulation.\" @ en . ### http://lenticularlens.org/voidPlus/hasItem voidPlus: hasItem rdf: type owl: ObjectProperty ; rdfs: domain voidPlus: Formulation ; rdfs: comment \"relates a void+:Formulation to its items.\" @ en . ### http://lenticularlens.org/voidPlus/hasLanguagePartition voidPlus: hasLanguagePartition rdf: type owl: ObjectProperty ; rdfs: subPropertyOf voidPlus: hasSubset ; rdfs: comment \"relates a void:Dataset to its subset void+:LanguagePartition.\" @ en . ### http://lenticularlens.org/voidPlus/hasObjectResourceSelection voidPlus: hasObjectResourceSelection rdf: type owl: ObjectProperty ; rdfs: subPropertyOf voidPlus: hasResourceSelection ; rdfs: comment \"a relation to assing a void+:ResourceSelection as the source for the subjects of triples under scrutiny.\" @ en . ### http://lenticularlens.org/voidPlus/hasPropertyPartition voidPlus: hasPropertyPartition rdf: type owl: ObjectProperty ; rdfs: subPropertyOf voidPlus: hasSubset , void: propertyPartition ; rdfs: comment \"relates a void:Dataset to its subset void+:PropertyPartition. In practice, the main difference wrt void:propertyPartition is the name meant to avoid missusage as it can be read as \\\"is propertyPartition of\\\" as well.\" @ en . ### http://lenticularlens.org/voidPlus/hasResourceSelection voidPlus: hasResourceSelection rdf: type owl: ObjectProperty ; rdfs: range voidPlus: ResourceSelection ; rdfs: comment \"a relation to assing a void+:ResourceSelection as the source for entities under scrutiny, for example, in a void+:MatchingMethos\" @ en . ### http://lenticularlens.org/voidPlus/hasSubjectResourceSelection voidPlus: hasSubjectResourceSelection rdf: type owl: ObjectProperty ; rdfs: subPropertyOf voidPlus: hasResourceSelection ; rdfs: comment \"a relation to assing a void+:ResourceSelection as the source for the objects of triples under scrutiny.\" @ en . ### http://lenticularlens.org/voidPlus/hasSubset voidPlus: hasSubset rdf: type owl: ObjectProperty ; rdfs: subPropertyOf void: subset ; owl: inverseOf voidPlus: subsetOf ; rdfs: domain void: Dataset ; rdfs: range voidPlus: Partition ; rdfs: comment \"relates a void:Dataset that has subset another void+:Partition. In practice, the main difference wrt void:subset is the name meant to avoid missusage as it can be read as \\\"is subset of\\\" as well. For a similar puporse, an inverse relation void+:subsetOf is also defined.\" @ en . ### http://lenticularlens.org/voidPlus/hasTarget voidPlus: hasTarget rdf: type owl: ObjectProperty ; rdfs: domain voidPlus: LinkDataset ; rdfs: range void: Dataset ; rdfs: comment \"A relation that assigns one or more void:Datasets linked by the void+:LinkDataset.\" @ en . ### http://lenticularlens.org/voidPlus/hasValidation voidPlus: hasValidation rdf: type owl: ObjectProperty ; rdfs: domain voidPlus: LinkDataset ; rdfs: range voidPlus: Validation ; rdfs: comment \"A relation that assigns a void+:LinkDataset to one or more void+:Validations.\" @ en . ### http://lenticularlens.org/voidPlus/language voidPlus: language rdf: type owl: ObjectProperty ; rdfs: subPropertyOf voidPlus: partitionedBy ; rdfs: range voidPlus: Language ; rdfs: comment \"A relation that assigns to a void:Dataset a void+:Language (for ISO standard language codes) that is the rdf:language of all literals (objects) qualifiying entities (subject) in a language-based partition.\" @ en . ### http://lenticularlens.org/voidPlus/objectsTarget voidPlus: objectsTarget rdf: type owl: ObjectProperty ; rdfs: subPropertyOf voidPlus: hasTarget ; rdfs: domain voidPlus: DirectedLinkDataset ; rdfs: range void: Dataset ; rdfs: comment \"A relation that assigns void:Datasets describing the subjects of triples contained in the void+:DirectedLinkDataset.\" @ en . ### http://lenticularlens.org/voidPlus/partitionedBy voidPlus: partitionedBy rdf: type owl: ObjectProperty ; rdfs: domain void: Dataset ; rdfs: comment \"A relation that assigns to a void:Dataset to the conditions under which it is partitioned.\" @ en . ### http://lenticularlens.org/voidPlus/property voidPlus: property rdf: type owl: ObjectProperty ; rdfs: subPropertyOf voidPlus: partitionedBy ; rdfs: range [ rdf: type owl: Class ; owl: unionOf ( rdf: Property rdf: Seq ) ] ; rdfs: comment \"A relation that assigns to a void:Dataset a rdf:Property or a rdf:Seq of properties that expresses the pattern of all triples in a property-based partition.\" @ en . ### http://lenticularlens.org/voidPlus/subjectsTarget voidPlus: subjectsTarget rdf: type owl: ObjectProperty ; rdfs: subPropertyOf voidPlus: hasTarget ; rdfs: domain voidPlus: DirectedLinkDataset ; rdfs: range void: Dataset ; rdfs: comment \"A relation that assigns void:Datasets describing the objects of triples contained in the void+:DirectedLinkDataset.\" @ en . ### http://lenticularlens.org/voidPlus/subsetOf voidPlus: subsetOf rdf: type owl: ObjectProperty ; rdfs: comment \"relates a void+:Partition to its void:Dataset superset. Define as the inverse relation of void+:hasSubset.\" @ en . ### http://rdfs.org/ns/void#class void: class rdf: type owl: ObjectProperty ; rdfs: subPropertyOf voidPlus: partitionedBy ; rdfs: range rdfs: Class ; rdfs: comment \"A relation that assigns to a void:Dataset a rdfs:Class that is the rdf:type of all entities (subject) in a class-based partition.\" @ en . ### http://rdfs.org/ns/void#classPartition void: classPartition rdf: type owl: ObjectProperty ; rdfs: subPropertyOf void: subset ; rdfs: comment \"A relation between a void:Dataset and its Partition, which is a subset of a void:Dataset that contains only entities of an explicitly defined rdfs:Class.\" @ en . ### http://rdfs.org/ns/void#objectsTarget void: objectsTarget rdf: type owl: ObjectProperty ; rdfs: subPropertyOf voidPlus: objectsTarget , void: target ; rdfs: domain void: Linkset ; rdfs: comment \"A relation that assigns the void:Dataset describing the objects of triples contained in the void:Linkset.\" @ en . ### http://rdfs.org/ns/void#property void: property rdf: type owl: ObjectProperty ; rdfs: subPropertyOf voidPlus: property ; rdfs: domain void: Dataset ; rdfs: range rdf: Property ; rdfs: comment \"A relation that assigns to a void:Dataset a rdf:Property that is the predicate of all triples in a property-based partition.\" @ en . ### http://rdfs.org/ns/void#propertyPartition void: propertyPartition rdf: type owl: ObjectProperty ; rdfs: subPropertyOf void: subset ; rdfs: comment \"A relation between a void:Dataset and its Partition, which is a subset of a void:Dataset that contains only triples composed with an explicitly defined rdf:Property.\" @ en . ### http://rdfs.org/ns/void#subjectsTarget void: subjectsTarget rdf: type owl: ObjectProperty ; rdfs: subPropertyOf voidPlus: subjectsTarget , void: target ; rdfs: domain void: Linkset ; rdfs: comment \"A relation that assigns the void:Dataset describing the subjects of triples contained in the void:Linkset.\" @ en . ### http://rdfs.org/ns/void#subset void: subset rdf: type owl: ObjectProperty ; rdfs: domain void: Dataset ; rdfs: range void: Dataset ; rdfs: comment \"relates a void:Dataset that has subset another void:Dataset.\" @ en . ### http://rdfs.org/ns/void#target void: target rdf: type owl: ObjectProperty ; rdfs: subPropertyOf voidPlus: hasTarget ; rdfs: domain void: Linkset ; rdfs: range void: Dataset ; rdfs: comment \"A relation that assigns one of the two void:Datasets linked by the void:Linkset.\" @ en . ### http://www.w3.org/2000/01/rdf-schema#member rdfs: member rdf: type owl: ObjectProperty ; rdfs: comment \"rdfs:member is an instance of rdf:Property that is a super-property of all the container membership properties. In particular, properties called rdf:_1, rdf:_2, rdf:_3... etc., used for rdf:Seq are sub-properties of rdfs:member.\" @ en . ################################################################# # Data properties ################################################################# ### http://lenticularlens.org/voidPlus/hasFormulaDescription voidPlus: hasFormulaDescription rdf: type owl: DatatypeProperty ; rdfs: range xsd: string . ################################################################# # Classes ################################################################# ### http://lenticularlens.org/voidPlus/ClassPartition voidPlus: ClassPartition rdf: type owl: Class ; owl: equivalentClass [ rdf: type owl: Restriction ; owl: onProperty [ owl: inverseOf voidPlus: hasClassPartition ] ; owl: someValuesFrom void: Dataset ] , [ rdf: type owl: Restriction ; owl: onProperty void: class ; owl: qualifiedCardinality \"1\" ^^ xsd:nonNegativeInteger ; owl: onClass rdfs: Class ] ; rdfs: subClassOf voidPlus: Partition ; rdfs: comment \"A void+:Partition that is partioned by a rdfs:Class.\" @ en . ### http://lenticularlens.org/voidPlus/DirectedLinkDataset voidPlus: DirectedLinkDataset rdf: type owl: Class ; rdfs: subClassOf voidPlus: LinkDataset ; rdfs: comment \"A void+:LinkDataset that imposes that subjects always belong to the same datasets as well as objects.\" @ en . ### http://lenticularlens.org/voidPlus/DocumentedLinkDataset voidPlus: DocumentedLinkDataset rdf: type owl: Class ; owl: equivalentClass [ owl: intersectionOf ( [ rdf: type owl: Restriction ; owl: onProperty voidPlus: hasTarget ; owl: someValuesFrom voidPlus: ResourceSelection ] [ rdf: type owl: Restriction ; owl: onProperty voidPlus: hasTarget ; owl: allValuesFrom voidPlus: ResourceSelection ] ) ; rdf: type owl: Class ] ; rdfs: subClassOf voidPlus: LinkDataset ; rdfs: comment \"A void+:LinkDataset that requires detailed documentation, including targets described as void+:ResourceSelection (all values from) and a void+:Formulation.\" @ en . ### http://lenticularlens.org/voidPlus/Formulation voidPlus: Formulation rdf: type owl: Class ; rdfs: comment \"A (reusable) formulation that lists a number of items (e.g. matching methods or linksets) and describes how they are meant to be combined (e.g. using logic or set operators).\" @ en . ### http://lenticularlens.org/voidPlus/Language voidPlus: Language rdf: type owl: Class ; rdfs: comment \"A set of standardized ISO langague codes.\" @ en . ### http://lenticularlens.org/voidPlus/LanguagePartition voidPlus: LanguagePartition rdf: type owl: Class ; owl: equivalentClass [ rdf: type owl: Restriction ; owl: onProperty voidPlus: language ; owl: someValuesFrom voidPlus: Language ] , [ rdf: type owl: Restriction ; owl: onProperty [ owl: inverseOf voidPlus: hasLanguagePartition ] ; owl: someValuesFrom void: Dataset ] ; rdfs: subClassOf voidPlus: Partition ; rdfs: comment \"A void+:Partition that is partioned by a void+:Language, i.e. an ISO standard language code.\" @ en . ### http://lenticularlens.org/voidPlus/Lens voidPlus: Lens rdf: type owl: Class ; rdfs: subClassOf voidPlus: DocumentedLinkDataset ; rdfs: comment \"Similar to a void+:Linkset (in the sense that it is a collection of links sharing the same linktype) also involving one, two or more datasets, but not necessarilly directed. Moreover, context-wise, it differs from a linkset as it is generated using different processes (set-like link manipulation operators such as Union, Intersection, Difference or Transitivity) as compared to how a linkset comes about (matching algorithms).\" @ en . ### http://lenticularlens.org/voidPlus/LensFormulation voidPlus: LensFormulation rdf: type owl: Class ; rdfs: subClassOf voidPlus: Formulation ; rdfs: comment \"A resource that makes explicit all void+:LinkDatasets involved in the creation of a void+:Lens and how the they are combined.\" @ en . ### http://lenticularlens.org/voidPlus/LinkDataset voidPlus: LinkDataset rdf: type owl: Class ; owl: equivalentClass [ rdf: type owl: Restriction ; owl: onProperty voidPlus: hasTarget ; owl: someValuesFrom void: Dataset ] ; rdfs: subClassOf void: Dataset ; rdfs: comment \"A collection of RDF links between dataset(s), using the same link predicate (regardless of the link being an equality predicate or not). This predicate is called the linktype of the linkset. The links may have been stabilished among one (deduplication), two or many datasets.\" @ en . ### http://lenticularlens.org/voidPlus/Linkset voidPlus: Linkset rdf: type owl: Class ; rdfs: subClassOf voidPlus: DirectedLinkDataset , voidPlus: DocumentedLinkDataset ; rdfs: comment \"A void+DirrectedLinkDataset that is also a void+:DocumentedLinkDataset.\" @ en . ### http://lenticularlens.org/voidPlus/LinksetFormulation voidPlus: LinksetFormulation rdf: type owl: Class ; rdfs: subClassOf voidPlus: Formulation ; rdfs: comment \"A resource that makes explicit all void+:MatchingMethods involved in the creation of a void+:Linkset and how the methods are logically joint.\" @ en . ### http://lenticularlens.org/voidPlus/MatchingAlgorithm voidPlus: MatchingAlgorithm rdf: type owl: Class ; rdfs: comment \"A set of rules followed by a computer for finding pairs of matching resources. An algorithm can be further categorised as automated or semi-automated depending on whether it requires user assistance or not. Most matching algorithms employed in the Lenticular Lens are semi-automated.\" @ en . ### http://lenticularlens.org/voidPlus/MatchingMethod voidPlus: MatchingMethod rdf: type owl: Class ; rdfs: comment \"A resource that makes explicit all parameters/pre-requisites of a matching algorithm including the conditions in which the algorithm is to accept a discovered link (threshold).\" @ en . ### http://lenticularlens.org/voidPlus/Partition voidPlus: Partition rdf: type owl: Class ; owl: equivalentClass [ rdf: type owl: Restriction ; owl: onProperty void: subset ; owl: someValuesFrom void: Dataset ] ; rdfs: comment \"A void:Daset that is subset of another one.\" @ en . ### http://lenticularlens.org/voidPlus/PropertyPartition voidPlus: PropertyPartition rdf: type owl: Class ; owl: equivalentClass [ rdf: type owl: Restriction ; owl: onProperty [ owl: inverseOf voidPlus: hasPropertyPartition ] ; owl: someValuesFrom void: Dataset ] , [ rdf: type owl: Restriction ; owl: onProperty voidPlus: property ; owl: qualifiedCardinality \"1\" ^^ xsd:nonNegativeInteger ; owl: onClass [ rdf: type owl: Class ; owl: unionOf ( rdf: Property rdf: Seq ) ] ] ; rdfs: subClassOf voidPlus: Partition ; rdfs: comment \"A void+:Partition that is partioned by a rdf:Property.\" @ en . ### http://lenticularlens.org/voidPlus/PropertySequence voidPlus: PropertySequence rdf: type owl: Class ; owl: equivalentClass [ rdf: type owl: Restriction ; owl: onProperty rdfs: member ; owl: allValuesFrom rdf: Property ] , [ rdf: type owl: Restriction ; owl: onProperty rdfs: member ; owl: minQualifiedCardinality \"2\" ^^ xsd:nonNegativeInteger ; owl: onClass rdf: Property ] ; rdfs: subClassOf rdf: Seq ; rdfs: comment \"Represents a sequence of properties, analogously to a property path.\" @ en . ### http://lenticularlens.org/voidPlus/ResourceSelection voidPlus: ResourceSelection rdf: type owl: Class ; rdfs: subClassOf void: Dataset , [ rdf: type owl: Restriction ; owl: onProperty voidPlus: hasSubset ; owl: someValuesFrom voidPlus: Partition ] , [ rdf: type owl: Restriction ; owl: onProperty void: subset ; owl: someValuesFrom void: Dataset ] ; rdfs: comment \"A collection of resources stemmed from the same void:Dataset. It is expected to have as partition, directly or indirectly (i.e. as a subset), a void+:ClassPartition. It can also have void+:PropertyPartitions, where property-value(s) can be restricted, as well as void+:LanguagePartitions, where the language of the property-value(s) can be reestricted.\" @ en . ### http://lenticularlens.org/voidPlus/TypedPropertySequence voidPlus: TypedPropertySequence rdf: type owl: Class ; owl: equivalentClass [ rdf: type owl: Restriction ; owl: onProperty rdfs: member ; owl: allValuesFrom [ rdf: type owl: Class ; owl: unionOf ( rdf: Property rdfs: Class ) ] ] , [ rdf: type owl: Restriction ; owl: onProperty rdfs: member ; owl: minQualifiedCardinality \"1\" ^^ xsd:nonNegativeInteger ; owl: onClass rdfs: Class ] , [ rdf: type owl: Restriction ; owl: onProperty rdfs: member ; owl: minQualifiedCardinality \"2\" ^^ xsd:nonNegativeInteger ; owl: onClass rdf: Property ] ; rdfs: subClassOf rdf: Seq ; rdfs: comment \"\"\"Represents a sequence of properties and classes, as in a different type property path with class restriction in between: property -> class -> property -> class\"\"\"@en . ### http://lenticularlens.org/voidPlus/Validation voidPlus:Validation rdf:type owl:Class ; rdfs:subClassOf void:Dataset ; rdfs:comment \"A void:Dataset that contains triples regarding the validation of links from a void+:LinkDataset.\"@en . ### http://rdfs.org/ns/void#Dataset void:Dataset rdf:type owl:Class ; rdfs:comment \"A set of RDF triples that are published, maintained or aggregated by a single provider\"@en . ### http://rdfs.org/ns/void#Linkset void:Linkset rdf:type owl:Class ; rdfs:subClassOf voidPlus:DirectedLinkDataset ; rdfs:comment \"A collection of RDF links between *two* void:Datasets.\"@en . ### http://www.w3.org/1999/02/22-rdf-syntax-ns#Property rdf:Property rdf:type owl:Class ; rdfs:comment \"rdf:Property is the class of RDF properties.\"@en . ### http://www.w3.org/1999/02/22-rdf-syntax-ns#Seq rdf:Seq rdf:type owl:Class ; rdfs:comment \"The rdf:Seq class is the class of RDF 'Sequence' containers.\"@en . ### http://www.w3.org/2000/01/rdf-schema#Class rdfs:Class rdf:type owl:Class ; rdfs:comment \"This is the class of resources that are RDF classes.\"@en . ### Generated by the OWL API (version 4.5.9.2019-02-01T07:24:44Z) https://github.com/owlcs/owlapi 4. VoID+ Documentation \u00b6 Markdown documentation created by pyLODE 2.8.3 URI : http://lenticularlens.org/voidPlus Ontology RDF : download voidPlus.owl 4.1 Overview \u00b6 See Figure 7 and 8 above for an overview. 4.2 Classes \u00b6 ClassPartition \u00b6 Property Value URI http://lenticularlens.org/voidPlus/ClassPartition Description A void+:Partition that is partioned by a rdfs:Class. Super-classes void+:Partition DirectedLinkDataset \u00b6 Property Value URI http://lenticularlens.org/voidPlus/DirectedLinkDataset Description A void+:LinkDataset that imposes that subjects always belong to the same datasets as well as objects. Super-classes void+:LinkDataset Sub-classes void+:Linkset void:Linkset In domain of void+:subjectsTarget void+:objectsTarget DocumentedLinkDataset \u00b6 Property Value URI http://lenticularlens.org/voidPlus/DocumentedLinkDataset Description A void+:LinkDataset that requires detailed documentation, including targets described as void+:ResourceSelection (all values from) and a void+:Formulation. Super-classes void+:LinkDataset Sub-classes void+:Linkset void+:Lens Formulation \u00b6 Property Value URI http://lenticularlens.org/voidPlus/Formulation Description A (reusable) formulation that lists a number of items (e.g. matching methods or linksets) and describes how they are meant to be combined (e.g. using logic or set operators). Sub-classes void+:LensFormulation void+:LinksetFormulation In domain of void+:hasItem In range of void+:hasFormulation Language \u00b6 Property Value URI http://lenticularlens.org/voidPlus/Language Description A set of standardized ISO langague codes. In range of void+:language LanguagePartition \u00b6 Property Value URI http://lenticularlens.org/voidPlus/LanguagePartition Description A void+:Partition that is partioned by a void+:Language, i.e. an ISO standard language code. Super-classes void+:Partition Lens \u00b6 Property Value URI http://lenticularlens.org/voidPlus/Lens Description Similar to a void+:Linkset (in the sense that it is a collection of links sharing the same linktype) also involving one, two or more datasets, but not necessarilly directed. Moreover, context-wise, it differs from a linkset as it is generated using different processes (set-like link manipulation operators such as Union, Intersection, Difference or Transitivity) as compared to how a linkset comes about (matching algorithms). Super-classes void+:DocumentedLinkDataset LensFormulation \u00b6 Property Value URI http://lenticularlens.org/voidPlus/LensFormulation Description A resource that makes explicit all void+:LinkDatasets involved in the creation of a void+:Lens and how the they are combined. Super-classes void+:Formulation LinkDataset \u00b6 Property Value URI http://lenticularlens.org/voidPlus/LinkDataset Description A collection of RDF links between dataset(s), using the same link predicate (regardless of the link being an equality predicate or not). This predicate is called the linktype of the linkset. The links may have been stabilished among one (deduplication), two or many datasets. Super-classes void:Dataset Sub-classes void+:DirectedLinkDataset void+:DocumentedLinkDataset In domain of void+:hasValidation void+:hasFormulation void+:hasTarget Linkset \u00b6 Property Value URI http://lenticularlens.org/voidPlus/Linkset Description A void+DirrectedLinkDataset that is also a void+:DocumentedLinkDataset. Super-classes void+:DocumentedLinkDataset void+:DirectedLinkDataset LinksetFormulation \u00b6 Property Value URI http://lenticularlens.org/voidPlus/LinksetFormulation Description A resource that makes explicit all void+:MatchingMethods involved in the creation of a void+:Linkset and how the methods are logically joint. Super-classes void+:Formulation MatchingAlgorithm \u00b6 Property Value URI http://lenticularlens.org/voidPlus/MatchingAlgorithm Description A set of rules followed by a computer for finding pairs of matching resources. An algorithm can be further categorised as automated or semi-automated depending on whether it requires user assistance or not. Most matching algorithms employed in the Lenticular Lens are semi-automated. In range of void+:hasAlgorithm MatchingMethod \u00b6 Property Value URI http://lenticularlens.org/voidPlus/MatchingMethod Description A resource that makes explicit all parameters/pre-requisites of a matching algorithm including the conditions in which the algorithm is to accept a discovered link (threshold). In domain of void+:hasAlgorithm Partition \u00b6 Property Value URI http://lenticularlens.org/voidPlus/Partition Description A void:Daset that is subset of another one. Sub-classes void+:ClassPartition void+:LanguagePartition void+:PropertyPartition In range of void+:hasSubset PropertyPartition \u00b6 Property Value URI http://lenticularlens.org/voidPlus/PropertyPartition Description A void+:Partition that is partioned by a rdf:Property. Super-classes void+:Partition PropertySequence \u00b6 Property Value URI http://lenticularlens.org/voidPlus/PropertySequence Description Represents a sequence of properties, analogously to a property path. Super-classes rdf:Seq ResourceSelection \u00b6 Property Value URI http://lenticularlens.org/voidPlus/ResourceSelection Description A collection of resources stemmed from the same void:Dataset. It is expected to have as partition, directly or indirectly (i.e. as a subset), a void+:ClassPartition. It can also have void+:PropertyPartitions, where property-value(s) can be restricted, as well as void+:LanguagePartitions, where the language of the property-value(s) can be reestricted. Super-classes void:Dataset Restrictions void:subset some void:Dataset void+:hasSubset some void+:Partition In range of void+:hasResourceSelection TypedPropertySequence \u00b6 Property Value URI http://lenticularlens.org/voidPlus/TypedPropertySequence Description Represents a sequence of properties and classes, as in a different type property path with class restriction in between: property -> class -> property -> class Super-classes rdf:Seq Validation \u00b6 Property Value URI http://lenticularlens.org/voidPlus/Validation Description A void:Dataset that contains triples regarding the validation of links from a void+:LinkDataset. Super-classes void:Dataset In range of void+:hasValidation Dataset \u00b6 Property Value URI http://rdfs.org/ns/void#Dataset Description A set of RDF triples that are published, maintained or aggregated by a single provider Sub-classes void+:Validation void+:LinkDataset void+:ResourceSelection In domain of void:property void+:partitionedBy void+:hasSubset void:subset In range of void+:hasTarget void:subset void+:objectsTarget void:target void+:subjectsTarget Linkset \u00b6 Property Value URI http://rdfs.org/ns/void#Linkset Description A collection of RDF links between two void:Datasets. Super-classes void+:DirectedLinkDataset In domain of void:objectsTarget void:target void:subjectsTarget Property \u00b6 Property Value URI http://www.w3.org/1999/02/22-rdf-syntax-ns#Property Description rdf:Property is the class of RDF properties. In range of void:property Seq \u00b6 Property Value URI http://www.w3.org/1999/02/22-rdf-syntax-ns#Seq Description The rdf:Seq class is the class of RDF \u2018Sequence\u2019 containers. Sub-classes void+:PropertySequence void+:TypedPropertySequence Class \u00b6 Property Value URI http://www.w3.org/2000/01/rdf-schema#Class Description This is the class of resources that are RDF classes. In range of void:class 4.3 Object Properties \u00b6 hasAlgorithm \u00b6 Property Value URI http://lenticularlens.org/voidPlus/hasAlgorithm Description relates a void+:MatchingMethod to its void+:MatchingAlgorithm. Domain(s) void+:MatchingMethod Range(s) void+:MatchingAlgorithm hasClassPartition \u00b6 Property Value URI http://lenticularlens.org/voidPlus/hasClassPartition Description relates a void:Dataset to its subset void+:ClassPartition. In practice, the main difference wrt void:classPartition is the name meant to avoid missusage as it can be read as \u201cis classPartition of\u201d as well. Super-properties void+:hasSubset void:classPartition hasFormulation \u00b6 Property Value URI http://lenticularlens.org/voidPlus/hasFormulation Description relates a void+:LinkDataset to its void+:Formulation. Domain(s) void+:LinkDataset Range(s) void+:Formulation hasItem \u00b6 Property Value URI http://lenticularlens.org/voidPlus/hasItem Description relates a void+:Formulation to its items. Domain(s) void+:Formulation hasLanguagePartition \u00b6 Property Value URI http://lenticularlens.org/voidPlus/hasLanguagePartition Description relates a void:Dataset to its subset void+:LanguagePartition. Super-properties void+:hasSubset hasObjectResourceSelection \u00b6 Property Value URI http://lenticularlens.org/voidPlus/hasObjectResourceSelection Description a relation to assing a void+:ResourceSelection as the source for the subjects of triples under scrutiny. Super-properties void+:hasResourceSelection hasPropertyPartition \u00b6 Property Value URI http://lenticularlens.org/voidPlus/hasPropertyPartition Description relates a void:Dataset to its subset void+:PropertyPartition. In practice, the main difference wrt void:propertyPartition is the name meant to avoid missusage as it can be read as \u201cis propertyPartition of\u201d as well. Super-properties void+:hasSubset void:propertyPartition hasResourceSelection \u00b6 Property Value URI http://lenticularlens.org/voidPlus/hasResourceSelection Description a relation to assing a void+:ResourceSelection as the source for entities under scrutiny, for example, in a void+:MatchingMethos Range(s) void+:ResourceSelection hasSubjectResourceSelection \u00b6 Property Value URI http://lenticularlens.org/voidPlus/hasSubjectResourceSelection Description a relation to assing a void+:ResourceSelection as the source for the objects of triples under scrutiny. Super-properties void+:hasResourceSelection hasSubset \u00b6 Property Value URI http://lenticularlens.org/voidPlus/hasSubset Description relates a void:Dataset that has subset another void+:Partition. In practice, the main difference wrt void:subset is the name meant to avoid missusage as it can be read as \u201cis subset of\u201d as well. For a similar puporse, an inverse relation void+:subsetOf is also defined. Super-properties void:subset Domain(s) void:Dataset Range(s) void+:Partition hasTarget \u00b6 Property Value URI http://lenticularlens.org/voidPlus/hasTarget Description A relation that assigns one or more void:Datasets linked by the void+:LinkDataset. Domain(s) void+:LinkDataset Range(s) void:Dataset hasValidation \u00b6 Property Value URI http://lenticularlens.org/voidPlus/hasValidation Description A relation that assigns a void+:LinkDataset to one or more void+:Validations. Domain(s) void+:LinkDataset Range(s) void+:Validation language \u00b6 Property Value URI http://lenticularlens.org/voidPlus/language Description A relation that assigns to a void:Dataset a void+:Language (for ISO standard language codes) that is the rdf:language of all literals (objects) qualifiying entities (subject) in a language-based partition. Super-properties void+:partitionedBy Range(s) void+:Language objectsTarget \u00b6 Property Value URI http://lenticularlens.org/voidPlus/objectsTarget Description A relation that assigns void:Datasets describing the subjects of triples contained in the void+:DirectedLinkDataset. Super-properties void+:hasTarget Domain(s) void+:DirectedLinkDataset Range(s) void:Dataset partitionedBy \u00b6 Property Value URI http://lenticularlens.org/voidPlus/partitionedBy Description A relation that assigns to a void:Dataset to the conditions under which it is partitioned. Domain(s) void:Dataset property \u00b6 Property Value URI http://lenticularlens.org/voidPlus/property Description A relation that assigns to a void:Dataset a rdf:Property or a rdf:Seq of properties that expresses the pattern of all triples in a property-based partition. Super-properties void+:partitionedBy Range(s) rdf:Property rdf:Seq subjectsTarget \u00b6 Property Value URI http://lenticularlens.org/voidPlus/subjectsTarget Description A relation that assigns void:Datasets describing the objects of triples contained in the void+:DirectedLinkDataset. Super-properties void+:hasTarget Domain(s) void+:DirectedLinkDataset Range(s) void:Dataset subsetOf \u00b6 Property Value URI http://lenticularlens.org/voidPlus/subsetOf Description relates a void+:Partition to its void:Dataset superset. Define as the inverse relation of void+:hasSubset. class \u00b6 Property Value URI http://rdfs.org/ns/void#class Description A relation that assigns to a void:Dataset a rdfs:Class that is the rdf:type of all entities (subject) in a class-based partition. Super-properties void+:partitionedBy Range(s) rdfs:Class classPartition \u00b6 Property Value URI http://rdfs.org/ns/void#classPartition Description A relation between a void:Dataset and its Partition, which is a subset of a void:Dataset that contains only entities of an explicitly defined rdfs:Class. Super-properties void:subset objectsTarget \u00b6 Property Value URI http://rdfs.org/ns/void#objectsTarget Description A relation that assigns the void:Dataset describing the objects of triples contained in the void:Linkset. Super-properties void+:objectsTarget void:target Domain(s) void:Linkset property \u00b6 Property Value URI http://rdfs.org/ns/void#property Description A relation that assigns to a void:Dataset a rdf:Property that is the predicate of all triples in a property-based partition. Super-properties void+:property Domain(s) void:Dataset Range(s) rdf:Property propertyPartition \u00b6 Property Value URI http://rdfs.org/ns/void#propertyPartition Description A relation between a void:Dataset and its Partition, which is a subset of a void:Dataset that contains only triples composed with an explicitly defined rdf:Property. Super-properties void:subset subjectsTarget \u00b6 Property Value URI http://rdfs.org/ns/void#subjectsTarget Description A relation that assigns the void:Dataset describing the subjects of triples contained in the void:Linkset. Super-properties void+:subjectsTarget void:target Domain(s) void:Linkset subset \u00b6 Property Value URI http://rdfs.org/ns/void#subset Description relates a void:Dataset that has subset another void:Dataset. Domain(s) void:Dataset Range(s) void:Dataset target \u00b6 Property Value URI http://rdfs.org/ns/void#target Description A relation that assigns one of the two void:Datasets linked by the void:Linkset. Super-properties void+:hasTarget Domain(s) void:Linkset Range(s) void:Dataset member \u00b6 Property Value URI http://www.w3.org/2000/01/rdf-schema#member Description rdfs:member is an instance of rdf:Property that is a super-property of all the container membership properties. In particular, properties called rdf:_1, rdf:_2, rdf:_3\u2026 etc., used for rdf:Seq are sub-properties of rdfs:member. 4.4 Datatype Properties \u00b6 hasFormulaDescription \u00b6 Property Value URI http://lenticularlens.org/voidPlus/hasFormulaDescription Range(s) xsd:string 4.5 Namespaces \u00b6 owl : http://www.w3.org/2002/07/owl# prov : http://www.w3.org/ns/prov# rdf : http://www.w3.org/1999/02/22-rdf-syntax-ns# rdfs : http://www.w3.org/2000/01/rdf-schema# sdo : https://schema.org/ skos : http://www.w3.org/2004/02/skos/core# void : http://rdfs.org/ns/void# void+ : http://lenticularlens.org/voidPlus/ xsd : http://www.w3.org/2001/XMLSchema#","title":"3. Link Annotation Ontology"},{"location":"03.Ontology/#ontology","text":"This section presents an Ontology meant for describing processes of generation and validation of links in detail, so that decisions made such as resource selections and matching options are made explicit. Those processes are implemented in the Lenticular Lens tool and result in the creation of Linksets or Lenses according to a specification. we call the proposed ontology VoID+ as it is proposed as an extension of the [ VoID ] vocabulary. The next section presents the motivation for such extension while Section 3.2 and Section 3.3 respectively present the main elements proposed as extension for VoID and the complete and detailed description of the VoID+ extension.","title":"ONTOLOGY"},{"location":"03.Ontology/#1-motivation-to-extend-void","text":"The model presented in Figure 1 is created based on the [ VoID ] documentation and owl-ontology description, where ellipses represent classes, thick arrows represent subclass or sub-property relations (hierarchy) and thin arrows represent properties. In this model, only classes and relations of interest are exhibit. The [ VoID ] vocabulary provides means to describe datasets and linksets, but with limitations. The first important limitation that motivates our proposal for extension is that void:Linkset is (1) too restrictive as it is directed and holds between exactly two non-identical datasets. Furthermore, (2) it also does not describe the details of how they were generated, nor it provides means to describe Lenses or Validations . The next limitation is (3) the ambiguate descriptions of subsets or partitions of a void:Dataset . This concept is in our theory very important and requires more clarity and expressivity. Those issues are further discussed in the next section. Fig 1: Excerpt of VoId Ontology regarding void:Dataset and void:Linkset. A description of the classes and properties exhibited in Fig 1 is available in the table below. Vocabulary Description void:Dataset A set of RDF triples that are published, maintained or aggregated by a single provider. void:Linkset A collection of RDF links between two void:Datasets. void:subset has subset. Domain : void:Dataset Range : void:Dataset void:classPartition A relation between a void:Dataset and its Partition, which is a subset of a void:Dataset that contains only entities of an explicitly defined rdfs:Class. Domain : void:Dataset Range : void:Dataset void:propertyPartition A relation between a void:Dataset and its Partition, which is a subset of a void:Dataset that contains only triples composed with an explicitly defined rdf:Property. Domain : void:Dataset Range : void:Dataset void:class A relation that assigns to a void:Dataset a rdfs:Class that is the rdf:type of all entities (subject) in a class-based partition. Domain : void:Dataset Range : rdfs:Class ( exactly 1 ) void:property A relation that assigns to a void:Dataset a rdf:Property that is the predicate of all triples in a property-based partition. Domain : void:Dataset Range : rdfs:Property ( exactly 1 ) void:target A relation that assigns one of the two datasets linked by the Linkset. Domain : void:Linkset Range : void:Dataset ( exactly 2 ) void:subjectsTarget A relation that assigns the dataset describing the subjects of triples contained in the Linkset. Domain : void:Linkset Range : void:Dataset ( exactly 1 ) void:objectsTarget A relation that assigns the dataset describing the objects of the triples contained in the Linkset. Domain : void:Linkset Range : void:Dataset ( exactly 1 )","title":"1. Motivation to extend VoID"},{"location":"03.Ontology/#2-void-main-elements","text":"This section presents the main elements proposed as extension for VoID . It provides a simplified overview (Fig. 2) of VoID+ by (i) only describing the classes and properties that are of importance in this work and (ii) omitting hierarchical relations among classes. While the complete and detailed description of the VoID+ extension is provided in the next section, the complete ontology overview (figure) and the documentation extracted from the owl file are available in section 3.4. Fig 2: The Lenticular Lens Ontology The partial model of the simplified oberverview depicted in Fig. 2 highlights in yellow the use of [ VoID ] terms and in blue the new VoID+ terminology . In order to describe the proposed ontology, we dissect Fig 2 into four parts. First, a Resource Selection is elucidated. Second, we go about describing a Matching Formulation and show how it connects with a Resource Selection . The third step highlights that the description of a Linkset metadata involves specifying the Resource Selections used at the source and target positions of an entity matching process, the Matching Formulation , eventual validations plus statistics and authority information. The fourth and final step focuses on the annotation of a Lens by describing the combination of one or more Linksets and/or Lenses.","title":"2. VoID+ Main Elements"},{"location":"03.Ontology/#21-resource-selection","text":"This step concerns the selection of the resources under scrutiny , that can potentially end up co-referent entities across or within datasources during an entity matching process. To therefore perform a matching, one first needs not only to select datasource(s) but also restrict which resources will undergo the matching. The first way of doing so is by applying a type (class) restriction. This is mandatory in the Lenticular Lens process as matching algorithms are not fully automated. Down this line, further restrictions can be applied by forcing the value of a number of properties to lie within a certain range. A Resource Selection is thereby, the annotation of such process. In the ontology excerpt depicted in Figure 3 we propose the entity type Resource Selection , which is also a void:Dataset that is a void:subset of one or more void:Dataset(s) . It can also have further restrictions defined as void:classPartion and/or void:propertyPartition . While a void:classPartion solely consists in specifying the type of entity under scrutiny, the void:propertyPartition entails a little more. It consists in specifying a property or property path and a restriction that the selected property should undergo for the selection of the right entities for the further down the road entity matching process. Those restrictions can be combined using a Formula Description given by ll:hasFormulaDescription . Fig 3: Selecting a matching resource Example 1 : Resource Selection In this example, the entity resource:ResourceSelection-2 is a ll:ResourceSelection (and a void:Dataset ) subset of resource:index_op_doopregister_raw_20190830 and also a collection (partition) of entities of type pnv:PersonName where each entity passed the filter test of (1) name in the English language which appears without trailing dots \"%...%\"@en and (2) birthdates within the interval [1600, 1699] . the entity resource:ResourceSelection-2 lists all three entities of type ll:PropertyConstraint and elaborates on the logic expression that binds all restrictions. For example, the property restriction described by resource:PropertyConstraint-PHce78383e3ff6e9dd73b6 documents that, applying the date function \"minimal_date\"@en over dates in the format the \"YYYY-MM-DD\"@en with the year restriction of 1600 makes sure that only persons born on 1600 onwards are admitted. Turtle Syntax When ever a literal in RDF syntax conatins quote or new line characters, the litreal should be in a three quote syntax ( \"...\"\"@en ). In the example below, we deliberately wrote the literal value of ll:hasFormulaDescription is in a single quote ( \"...\"\"@en ) instead of a triple quote ( \"\"\"%...%=\"\"\"@en ) as the syntax highliter is somewhat buggy. ### RESOURCE 2 resource: ResourceSelection-2 a void: dataset , ll: ResourceSelection ; rdfs: label \"Baptisms in the 17th Century\" @ en ; void: subset resource: index_op_doopregister_raw_20190830 ; void: classPartition [ void: class pnv: PersonName ] ; void: propertyPartition resource: PropertyConstraint-PHea6802ef02f99a848859 ; void: propertyPartition resource: PropertyConstraint-PHce78383e3ff6e9dd73b6 ; void: propertyPartition resource: PropertyConstraint-PH2580641bbdd572759cb9 ; ll: hasFormulaDescription \" resource: PropertyConstraint-PHce78383e3ff6e9dd73b6 AND resource: PropertyConstraint-PH2580641bbdd572759cb9 AND ( resource: PropertyConstraint-PHea6802ef02f99a848859 ) \"@en . resource: PropertyConstraint-PHea6802ef02f99a848859 a ll: PropertyConstraint ; void: property [ a rdfs: Sequence ; rdf : _ 1 pnv: literalName ] ; ll: hasFilterFunction \"not_ilike\" @ en ; ll: hasValueFunction \"%...%\" @ en . resource: PropertyConstraint-PHce78383e3ff6e9dd73b6 a ll: PropertyConstraint ; void: property [ a rdfs: Sequence ; rdf : _ 1 saa: isInRecord ; rdf : _ 2 saa: IndexOpDoopregisters ; rdf : _ 3 saa: birthDate ] ; ll: hasFilterFunction \"minimal_date\" @ en ; ll: hasValueFunction 1600 ; ll: hasFormatFunction \"YYYY-MM-DD\" @ en . resource: PropertyConstraint-PH2580641bbdd572759cb9 a ll: PropertyConstraint ; void: property [ a rdfs: Sequence ; rdf : _ 1 saa: isInRecord ; rdf : _ 2 saa: IndexOpDoopregisters ; rdf : _ 3 saa: birthDate ] ; ll: hasFilterFunction \"maximum_date\" @ en ; ll: hasValueFunction \"1699\" @ en ; ll: hasFormatFunction \"YYYY-MM-DD\" @ en .","title":"2.1 Resource Selection"},{"location":"03.Ontology/#22-matching-formulation","text":"For simple matching problems, finding co-referents can be done using a single matching algorithm (matcher). However, time and again the data reality often imposes the use of more than one matcher instead. In this latter scenario, clearly reporting on how these matchers work together for detecting co-referents is essential. A Matching Formulation entity is a resource for just doing the aforementioned, as depicted in Figure 4. Once resources of type Resource Restriction are created, one can go ahead and used them for specifying the restricted collections to be used in a particular Matching Method , which also specifies the Matching Algorithm and its parameters such as threshold, range and operrator. In the end, all Matching Methods used in a matching process are documented in the Matching Formulation resource as well as how they bind together in a logic expression given by the predicate ll:hasFormulaDescription . Fig 4: Specifying the way in which methods are logically combined Example 2 : Linkset Logic Expression In Example 2.8, the resource:PHb99da2ecd91ad533af65 is a ll:MatchingFormulation listing eight ll:MatchingMethods used for creating a linkset. They their logic combination is described as ll:hasFormulaDescription . Among the ll:MatchingMethods , the resource:TIME_DELTA-PHfdc744f6bd0ced4e283a is the only method detailes in this example, documenting the four ll:ResourceSelections involved, as well as the chosen ll:MatchingAlgorithm , namely resource:TIME_DELTA , besides the threshold (20), threshold-unit (\u201cYear\u201d@en), threshold-operator (>=) and threshold-range \u201c\u2115\u201d of the matching method. Turtle Syntax When ever a literal in RDF syntax conatins quote or new line characters, the litreal should be in a three quote syntax ( \"...\"\"@en ). In the example below, we deliberately wrote the literal value of ll:hasFormulaDescription is in a single quote ( \"...\"\"@en ) instead of a triple quote ( \"\"\"%...%=\"\"\"@en ) as the syntax highliter is somewhat buggy. ###################################################### # LINKSET LOGIC EXPRESSION # ###################################################### resource: PHb99da2ecd91ad533af65 a ll: MatchingFormulation ; ll: hasMethod resource: TIME_DELTA-PHfdc744f6bd0ced4e283a ; ll: hasMethod resource: Exact-PH6491d1db6855098a70be ; ll: hasMethod resource: LL_SOUNDEX-PH0ad3ad579d7a29347753 ; ll: hasMethod resource: BLOOTHOOFT_REDUCT-PH10433274b57dafdd1335 ; ll: hasMethod resource: Exact-PH4d4187a08c3ba4c1cf0d ; ll: hasMethod resource: TIME_DELTA-PHe40547b9d3b6381347b4 ; ll: hasMethod resource: LEVENSHTEIN_APPROX-PH10f4c17bbf933cae647f ; ll: hasMethod resource: BLOOTHOOFT_REDUCT-PH98a9575087817b951447 ; ll: hasFormulaDescription \" resource: TIME_DELTA-PHe40547b9d3b6381347b4 AND resource: TIME_DELTA-PHfdc744f6bd0ced4e283a AND ( resource: Exact-PH4d4187a08c3ba4c1cf0d OR ( resource: BLOOTHOOFT_REDUCT-PH98a9575087817b951447 AND resource: BLOOTHOOFT_REDUCT-PH10433274b57dafdd1335 ) OR ( resource: Exact-PH6491d1db6855098a70be AND ( resource: LL_SOUNDEX-PH0ad3ad579d7a29347753 AND resource: LEVENSHTEIN_APPROX-PH10f4c17bbf933cae647f ) ) ) \"@en . ###################################################### # METHOD SIGNATURES # ###################################################### ### METHOD SPECIFICATIONS TIME_DELTA resource: TIME_DELTA-PHe40547b9d3b6381347b4 a ll: MatchingMethod ; ll: hasAlgorithm resource: TIME_DELTA ; ll: hasThresholdRange \"\u2115\" ; ### SOURCE PREDICATE CONFIGURATION ll: hasSubjResourceSelection resource: ResourceSelection-PHbe38976fdf884b6c4a8e ; ll: hasSubjResourceSelection resource: ResourceSelection-PHe8fa664d04ad00aaa697 ; ### TARGET PREDICATE CONFIGURATION ll: hasObjResourceSelection resource: ResourceSelection-PH71818c17d54a8fbec22b ; ll: hasObjResourceSelection resource: ResourceSelection-PHc8a3c6e494d230b79a6b . \u2022\u2022\u2022","title":"2.2 Matching Formulation"},{"location":"03.Ontology/#23-linkset","text":"This step documents a linkset metadata including WHAT - HOW - WHEN - WHO and other processes explaining the aboutness of links. The Matching Formulation specifies HOW entities are matched and Resource Selection specifies WHAT to match as subject and object targets. Also some statistic on the matching results can be reported such as the number of links found, the numbers of entities linked, WHO created the linkset and WHEN . Finally, a Validation entity can also be specified, comprising metadata with statitics and auhtority information on the validation process. Observe that when one or more validations are provided, statistics on this matter can be included in the linkset metadata, including eventual contradictions if one validation says a link is correct while another says it is not. As discussed earlier in this section, according to the [ VoID ] documentation, the void:Linkset definition expects as datasources exactly one source and one target, different from each other. This means it is more restrictive than the ll:Linkset here proposed, since the latter also expects a linkset to contain links within a datasource or across more than two. Therefore, we do not directly reuse that concept (and its correspoding properties void:subjects/objectsTarget). Naturally, one could still use void:Linkset for other purposes, but at the risk of abusing the VoID vocabulary if its instances do not really fit the required restrictions. Moreover, a void:Linkset (i.e. a resource representing a linkset\u2019s metadata) is also not an instance of ll:Linkset since the later requires the description of the processes underlying the creation of the links, which is not the case for the first. Fig 5: Specifying the linkset\u2019s context Example 3: A linkset annotation ### LINKSET 15 linkset : 15 a ll: Linkset ; void: feature format: Turtle ; cc: attributionName \"LenticularLens\" @ en ; cc: license <http://purl.org/NET/rdflicense/W3C1.0> ; dcterms: created \"2020-09-26T09:37:23.933624\" ^^ <http://www.w3.org/2001/XMLSchema#dateTime> ; dcterms: creator \"AL IDRISSOU\" ; dcterms: creator \"GoldenAgents\" ; void: linkPredicate owl: sameAs ; rdfs: label \"Linkset 9\" @ en ; dcterms: description \"LINSET-15-9: Test Baptism against Marriage and burial with several nested methods \" @ en ; ### VOID LINKSET STATS void: entities 12580 ; ### LENTICULAR LENS LINKSET STATS ### SOURCE ENTITY TYPE SELECTION(S) ll: subjectsTarget resource: ResourceSelection-2 ; ### TARGET ENTITY TYPE SELECTION(S) ll: objectsTarget resource: ResourceSelection-1 ; ll: objectsTarget resource: ResourceSelection-3 ; ### THE LOGIC FORMULA ll: hasLogicFormulation resource: PHb6e5e320dc08d7d9dd98 .","title":"2.3 Linkset"},{"location":"03.Ontology/#24-lens","text":"Another process relevant to document is the creation of Lenses. In short, a lens is the result of a set-like operation over one or more Linkset and or Lens. Therefore, the entity Lens documents them as ll:hasTarget Fig 6: Specifying the linkset\u2019s context Example 4: A lens annotation","title":"2.4 Lens"},{"location":"03.Ontology/#3-void-ontology","text":"This section discuses the complete and detailed description of the VoID+ extension in two parts. It first addresses the void+:Partition of void:Dataset. Second, it tackles the void+:LinkDataset which is considered a special sub-types of void:Dataset. The documentation extracted from the owl file is presented in the next section.","title":"3. VoID+ Ontology"},{"location":"03.Ontology/#31-partitions-of-voiddataset","text":"The VoID vocabulary defines void:Dataset as a dataset superset but does make available a granularity of subsets for refined work. VoID+ extends the void:Dataset class by distinguishes between five subsets of void:Dataset. A void:Dataset that is defined as a subset of another one is called void+:Partition . Three types of void+:Partition are distinguished according to the type of partition that is used: (i) void+:ClassPartition : the dataset is the result of an rdfs:Class based-partition; (ii) void+:PropertyPartition : the dataset is the result of a rdf:Property or by a rdf:Seq \u2013 defining a sequence of two or more of properties \u2013 partition; (iii) void+:Language : the dataset is the result of a language partition given by a standardised ISO language code. Another special type of partition is the void+:ResourceSelection . It is defined by one or more partions of the type above described, Fig. 7 provides a straightforward understanding of how the class void:Dataset is extended. On its the left hand side, Fig. 7 presents a view on the classes, their hierarchy and how they are connected via object properties. On the one hand, the property void:subset and its sub-properties are extended such that they provide a directional non-ambiguous reading. On the other and, void:class and void:property are grouped into a superclass void+:partionedBy which also includes void:language to allow for one more type of partition. In particular, void:property is extended with a more generic relation void+:property that allows for describing a sequence of properties like in a property path. Fig 7: VoID+ Extension on the void:Dataset","title":"3.1 Partitions of void:Dataset"},{"location":"03.Ontology/#32-void-link-datasets","text":"Figure 8 presents on the left hand side a view on the classes, their hierarchy and how they are connected via object properties. This provides a very straightforward understanding of how the class void:Linkset is extended. It is extended with superclasses that are less restrictive with respect with its targets. First, a void+:LinkDataset is a void:Dataset that contains links that may have been stabilished among one (deduplication), two or many datasets. When the creation of void+:LinkDataset is such that imposes that subjects always belong to the same datasets as well as objects, this is called void+:DirectedLinkDataset. This is the case for both void:Linkset but also for our definition of void+:Linkset. The former, however, requires excelty one dataset as target for its subjects and onther as target for its objects. In addition, our definition of void+:Linkset is also a void+:DocumentedLinkDataset, which requires more detailed documentation, including targets described as void+:ResourceSelection (all values from) and a void+:Formulation\u2026 A void+:Lens is also a void+:DocumentedLinkDataset which has one void:LensFormulation that specifies which void:LinkDatasets are combined and how. The right hand side of Figure 8 presents a hierarchy of properties in order to provide an undestanding of how void:target and its subproperties are extended. They actually are extended with superclasses having as range not only a void:Linkset but its superclass void+:LinkDataset. Fig 8: VoID+ Extension on the void:Linkset","title":"3.2 VoID+ Link-datasets"},{"location":"03.Ontology/#33-void-owl","text":"Here, we provide a turtle description of the ontology. VoID+ @prefix : <http://lenticularlens.org/voidPlus#> . @prefix owl: <http://www.w3.org/2002/07/owl#> . @prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> . @prefix xml: <http://www.w3.org/XML/1998/namespace> . @prefix xsd: <http://www.w3.org/2001/XMLSchema#> . @prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> . @prefix void: <http://rdfs.org/ns/void#> . @prefix voidPlus: <http://lenticularlens.org/voidPlus/> . @base <http://lenticularlens.org/voidPlus> . <http://lenticularlens.org/voidPlus> rdf: type owl: Ontology . ################################################################# # Object Properties ################################################################# ### http://lenticularlens.org/voidPlus/hasAlgorithm voidPlus: hasAlgorithm rdf: type owl: ObjectProperty , owl: FunctionalProperty ; rdfs: domain voidPlus: MatchingMethod ; rdfs: range voidPlus: MatchingAlgorithm ; rdfs: comment \"relates a void+:MatchingMethod to its void+:MatchingAlgorithm.\" @ en . ### http://lenticularlens.org/voidPlus/hasClassPartition voidPlus: hasClassPartition rdf: type owl: ObjectProperty ; rdfs: subPropertyOf voidPlus: hasSubset , void: classPartition ; rdfs: comment \"relates a void:Dataset to its subset void+:ClassPartition. In practice, the main difference wrt void:classPartition is the name meant to avoid missusage as it can be read as \\\"is classPartition of\\\" as well.\" @ en . ### http://lenticularlens.org/voidPlus/hasFormulation voidPlus: hasFormulation rdf: type owl: ObjectProperty ; rdfs: domain voidPlus: LinkDataset ; rdfs: range voidPlus: Formulation ; rdfs: comment \"relates a void+:LinkDataset to its void+:Formulation.\" @ en . ### http://lenticularlens.org/voidPlus/hasItem voidPlus: hasItem rdf: type owl: ObjectProperty ; rdfs: domain voidPlus: Formulation ; rdfs: comment \"relates a void+:Formulation to its items.\" @ en . ### http://lenticularlens.org/voidPlus/hasLanguagePartition voidPlus: hasLanguagePartition rdf: type owl: ObjectProperty ; rdfs: subPropertyOf voidPlus: hasSubset ; rdfs: comment \"relates a void:Dataset to its subset void+:LanguagePartition.\" @ en . ### http://lenticularlens.org/voidPlus/hasObjectResourceSelection voidPlus: hasObjectResourceSelection rdf: type owl: ObjectProperty ; rdfs: subPropertyOf voidPlus: hasResourceSelection ; rdfs: comment \"a relation to assing a void+:ResourceSelection as the source for the subjects of triples under scrutiny.\" @ en . ### http://lenticularlens.org/voidPlus/hasPropertyPartition voidPlus: hasPropertyPartition rdf: type owl: ObjectProperty ; rdfs: subPropertyOf voidPlus: hasSubset , void: propertyPartition ; rdfs: comment \"relates a void:Dataset to its subset void+:PropertyPartition. In practice, the main difference wrt void:propertyPartition is the name meant to avoid missusage as it can be read as \\\"is propertyPartition of\\\" as well.\" @ en . ### http://lenticularlens.org/voidPlus/hasResourceSelection voidPlus: hasResourceSelection rdf: type owl: ObjectProperty ; rdfs: range voidPlus: ResourceSelection ; rdfs: comment \"a relation to assing a void+:ResourceSelection as the source for entities under scrutiny, for example, in a void+:MatchingMethos\" @ en . ### http://lenticularlens.org/voidPlus/hasSubjectResourceSelection voidPlus: hasSubjectResourceSelection rdf: type owl: ObjectProperty ; rdfs: subPropertyOf voidPlus: hasResourceSelection ; rdfs: comment \"a relation to assing a void+:ResourceSelection as the source for the objects of triples under scrutiny.\" @ en . ### http://lenticularlens.org/voidPlus/hasSubset voidPlus: hasSubset rdf: type owl: ObjectProperty ; rdfs: subPropertyOf void: subset ; owl: inverseOf voidPlus: subsetOf ; rdfs: domain void: Dataset ; rdfs: range voidPlus: Partition ; rdfs: comment \"relates a void:Dataset that has subset another void+:Partition. In practice, the main difference wrt void:subset is the name meant to avoid missusage as it can be read as \\\"is subset of\\\" as well. For a similar puporse, an inverse relation void+:subsetOf is also defined.\" @ en . ### http://lenticularlens.org/voidPlus/hasTarget voidPlus: hasTarget rdf: type owl: ObjectProperty ; rdfs: domain voidPlus: LinkDataset ; rdfs: range void: Dataset ; rdfs: comment \"A relation that assigns one or more void:Datasets linked by the void+:LinkDataset.\" @ en . ### http://lenticularlens.org/voidPlus/hasValidation voidPlus: hasValidation rdf: type owl: ObjectProperty ; rdfs: domain voidPlus: LinkDataset ; rdfs: range voidPlus: Validation ; rdfs: comment \"A relation that assigns a void+:LinkDataset to one or more void+:Validations.\" @ en . ### http://lenticularlens.org/voidPlus/language voidPlus: language rdf: type owl: ObjectProperty ; rdfs: subPropertyOf voidPlus: partitionedBy ; rdfs: range voidPlus: Language ; rdfs: comment \"A relation that assigns to a void:Dataset a void+:Language (for ISO standard language codes) that is the rdf:language of all literals (objects) qualifiying entities (subject) in a language-based partition.\" @ en . ### http://lenticularlens.org/voidPlus/objectsTarget voidPlus: objectsTarget rdf: type owl: ObjectProperty ; rdfs: subPropertyOf voidPlus: hasTarget ; rdfs: domain voidPlus: DirectedLinkDataset ; rdfs: range void: Dataset ; rdfs: comment \"A relation that assigns void:Datasets describing the subjects of triples contained in the void+:DirectedLinkDataset.\" @ en . ### http://lenticularlens.org/voidPlus/partitionedBy voidPlus: partitionedBy rdf: type owl: ObjectProperty ; rdfs: domain void: Dataset ; rdfs: comment \"A relation that assigns to a void:Dataset to the conditions under which it is partitioned.\" @ en . ### http://lenticularlens.org/voidPlus/property voidPlus: property rdf: type owl: ObjectProperty ; rdfs: subPropertyOf voidPlus: partitionedBy ; rdfs: range [ rdf: type owl: Class ; owl: unionOf ( rdf: Property rdf: Seq ) ] ; rdfs: comment \"A relation that assigns to a void:Dataset a rdf:Property or a rdf:Seq of properties that expresses the pattern of all triples in a property-based partition.\" @ en . ### http://lenticularlens.org/voidPlus/subjectsTarget voidPlus: subjectsTarget rdf: type owl: ObjectProperty ; rdfs: subPropertyOf voidPlus: hasTarget ; rdfs: domain voidPlus: DirectedLinkDataset ; rdfs: range void: Dataset ; rdfs: comment \"A relation that assigns void:Datasets describing the objects of triples contained in the void+:DirectedLinkDataset.\" @ en . ### http://lenticularlens.org/voidPlus/subsetOf voidPlus: subsetOf rdf: type owl: ObjectProperty ; rdfs: comment \"relates a void+:Partition to its void:Dataset superset. Define as the inverse relation of void+:hasSubset.\" @ en . ### http://rdfs.org/ns/void#class void: class rdf: type owl: ObjectProperty ; rdfs: subPropertyOf voidPlus: partitionedBy ; rdfs: range rdfs: Class ; rdfs: comment \"A relation that assigns to a void:Dataset a rdfs:Class that is the rdf:type of all entities (subject) in a class-based partition.\" @ en . ### http://rdfs.org/ns/void#classPartition void: classPartition rdf: type owl: ObjectProperty ; rdfs: subPropertyOf void: subset ; rdfs: comment \"A relation between a void:Dataset and its Partition, which is a subset of a void:Dataset that contains only entities of an explicitly defined rdfs:Class.\" @ en . ### http://rdfs.org/ns/void#objectsTarget void: objectsTarget rdf: type owl: ObjectProperty ; rdfs: subPropertyOf voidPlus: objectsTarget , void: target ; rdfs: domain void: Linkset ; rdfs: comment \"A relation that assigns the void:Dataset describing the objects of triples contained in the void:Linkset.\" @ en . ### http://rdfs.org/ns/void#property void: property rdf: type owl: ObjectProperty ; rdfs: subPropertyOf voidPlus: property ; rdfs: domain void: Dataset ; rdfs: range rdf: Property ; rdfs: comment \"A relation that assigns to a void:Dataset a rdf:Property that is the predicate of all triples in a property-based partition.\" @ en . ### http://rdfs.org/ns/void#propertyPartition void: propertyPartition rdf: type owl: ObjectProperty ; rdfs: subPropertyOf void: subset ; rdfs: comment \"A relation between a void:Dataset and its Partition, which is a subset of a void:Dataset that contains only triples composed with an explicitly defined rdf:Property.\" @ en . ### http://rdfs.org/ns/void#subjectsTarget void: subjectsTarget rdf: type owl: ObjectProperty ; rdfs: subPropertyOf voidPlus: subjectsTarget , void: target ; rdfs: domain void: Linkset ; rdfs: comment \"A relation that assigns the void:Dataset describing the subjects of triples contained in the void:Linkset.\" @ en . ### http://rdfs.org/ns/void#subset void: subset rdf: type owl: ObjectProperty ; rdfs: domain void: Dataset ; rdfs: range void: Dataset ; rdfs: comment \"relates a void:Dataset that has subset another void:Dataset.\" @ en . ### http://rdfs.org/ns/void#target void: target rdf: type owl: ObjectProperty ; rdfs: subPropertyOf voidPlus: hasTarget ; rdfs: domain void: Linkset ; rdfs: range void: Dataset ; rdfs: comment \"A relation that assigns one of the two void:Datasets linked by the void:Linkset.\" @ en . ### http://www.w3.org/2000/01/rdf-schema#member rdfs: member rdf: type owl: ObjectProperty ; rdfs: comment \"rdfs:member is an instance of rdf:Property that is a super-property of all the container membership properties. In particular, properties called rdf:_1, rdf:_2, rdf:_3... etc., used for rdf:Seq are sub-properties of rdfs:member.\" @ en . ################################################################# # Data properties ################################################################# ### http://lenticularlens.org/voidPlus/hasFormulaDescription voidPlus: hasFormulaDescription rdf: type owl: DatatypeProperty ; rdfs: range xsd: string . ################################################################# # Classes ################################################################# ### http://lenticularlens.org/voidPlus/ClassPartition voidPlus: ClassPartition rdf: type owl: Class ; owl: equivalentClass [ rdf: type owl: Restriction ; owl: onProperty [ owl: inverseOf voidPlus: hasClassPartition ] ; owl: someValuesFrom void: Dataset ] , [ rdf: type owl: Restriction ; owl: onProperty void: class ; owl: qualifiedCardinality \"1\" ^^ xsd:nonNegativeInteger ; owl: onClass rdfs: Class ] ; rdfs: subClassOf voidPlus: Partition ; rdfs: comment \"A void+:Partition that is partioned by a rdfs:Class.\" @ en . ### http://lenticularlens.org/voidPlus/DirectedLinkDataset voidPlus: DirectedLinkDataset rdf: type owl: Class ; rdfs: subClassOf voidPlus: LinkDataset ; rdfs: comment \"A void+:LinkDataset that imposes that subjects always belong to the same datasets as well as objects.\" @ en . ### http://lenticularlens.org/voidPlus/DocumentedLinkDataset voidPlus: DocumentedLinkDataset rdf: type owl: Class ; owl: equivalentClass [ owl: intersectionOf ( [ rdf: type owl: Restriction ; owl: onProperty voidPlus: hasTarget ; owl: someValuesFrom voidPlus: ResourceSelection ] [ rdf: type owl: Restriction ; owl: onProperty voidPlus: hasTarget ; owl: allValuesFrom voidPlus: ResourceSelection ] ) ; rdf: type owl: Class ] ; rdfs: subClassOf voidPlus: LinkDataset ; rdfs: comment \"A void+:LinkDataset that requires detailed documentation, including targets described as void+:ResourceSelection (all values from) and a void+:Formulation.\" @ en . ### http://lenticularlens.org/voidPlus/Formulation voidPlus: Formulation rdf: type owl: Class ; rdfs: comment \"A (reusable) formulation that lists a number of items (e.g. matching methods or linksets) and describes how they are meant to be combined (e.g. using logic or set operators).\" @ en . ### http://lenticularlens.org/voidPlus/Language voidPlus: Language rdf: type owl: Class ; rdfs: comment \"A set of standardized ISO langague codes.\" @ en . ### http://lenticularlens.org/voidPlus/LanguagePartition voidPlus: LanguagePartition rdf: type owl: Class ; owl: equivalentClass [ rdf: type owl: Restriction ; owl: onProperty voidPlus: language ; owl: someValuesFrom voidPlus: Language ] , [ rdf: type owl: Restriction ; owl: onProperty [ owl: inverseOf voidPlus: hasLanguagePartition ] ; owl: someValuesFrom void: Dataset ] ; rdfs: subClassOf voidPlus: Partition ; rdfs: comment \"A void+:Partition that is partioned by a void+:Language, i.e. an ISO standard language code.\" @ en . ### http://lenticularlens.org/voidPlus/Lens voidPlus: Lens rdf: type owl: Class ; rdfs: subClassOf voidPlus: DocumentedLinkDataset ; rdfs: comment \"Similar to a void+:Linkset (in the sense that it is a collection of links sharing the same linktype) also involving one, two or more datasets, but not necessarilly directed. Moreover, context-wise, it differs from a linkset as it is generated using different processes (set-like link manipulation operators such as Union, Intersection, Difference or Transitivity) as compared to how a linkset comes about (matching algorithms).\" @ en . ### http://lenticularlens.org/voidPlus/LensFormulation voidPlus: LensFormulation rdf: type owl: Class ; rdfs: subClassOf voidPlus: Formulation ; rdfs: comment \"A resource that makes explicit all void+:LinkDatasets involved in the creation of a void+:Lens and how the they are combined.\" @ en . ### http://lenticularlens.org/voidPlus/LinkDataset voidPlus: LinkDataset rdf: type owl: Class ; owl: equivalentClass [ rdf: type owl: Restriction ; owl: onProperty voidPlus: hasTarget ; owl: someValuesFrom void: Dataset ] ; rdfs: subClassOf void: Dataset ; rdfs: comment \"A collection of RDF links between dataset(s), using the same link predicate (regardless of the link being an equality predicate or not). This predicate is called the linktype of the linkset. The links may have been stabilished among one (deduplication), two or many datasets.\" @ en . ### http://lenticularlens.org/voidPlus/Linkset voidPlus: Linkset rdf: type owl: Class ; rdfs: subClassOf voidPlus: DirectedLinkDataset , voidPlus: DocumentedLinkDataset ; rdfs: comment \"A void+DirrectedLinkDataset that is also a void+:DocumentedLinkDataset.\" @ en . ### http://lenticularlens.org/voidPlus/LinksetFormulation voidPlus: LinksetFormulation rdf: type owl: Class ; rdfs: subClassOf voidPlus: Formulation ; rdfs: comment \"A resource that makes explicit all void+:MatchingMethods involved in the creation of a void+:Linkset and how the methods are logically joint.\" @ en . ### http://lenticularlens.org/voidPlus/MatchingAlgorithm voidPlus: MatchingAlgorithm rdf: type owl: Class ; rdfs: comment \"A set of rules followed by a computer for finding pairs of matching resources. An algorithm can be further categorised as automated or semi-automated depending on whether it requires user assistance or not. Most matching algorithms employed in the Lenticular Lens are semi-automated.\" @ en . ### http://lenticularlens.org/voidPlus/MatchingMethod voidPlus: MatchingMethod rdf: type owl: Class ; rdfs: comment \"A resource that makes explicit all parameters/pre-requisites of a matching algorithm including the conditions in which the algorithm is to accept a discovered link (threshold).\" @ en . ### http://lenticularlens.org/voidPlus/Partition voidPlus: Partition rdf: type owl: Class ; owl: equivalentClass [ rdf: type owl: Restriction ; owl: onProperty void: subset ; owl: someValuesFrom void: Dataset ] ; rdfs: comment \"A void:Daset that is subset of another one.\" @ en . ### http://lenticularlens.org/voidPlus/PropertyPartition voidPlus: PropertyPartition rdf: type owl: Class ; owl: equivalentClass [ rdf: type owl: Restriction ; owl: onProperty [ owl: inverseOf voidPlus: hasPropertyPartition ] ; owl: someValuesFrom void: Dataset ] , [ rdf: type owl: Restriction ; owl: onProperty voidPlus: property ; owl: qualifiedCardinality \"1\" ^^ xsd:nonNegativeInteger ; owl: onClass [ rdf: type owl: Class ; owl: unionOf ( rdf: Property rdf: Seq ) ] ] ; rdfs: subClassOf voidPlus: Partition ; rdfs: comment \"A void+:Partition that is partioned by a rdf:Property.\" @ en . ### http://lenticularlens.org/voidPlus/PropertySequence voidPlus: PropertySequence rdf: type owl: Class ; owl: equivalentClass [ rdf: type owl: Restriction ; owl: onProperty rdfs: member ; owl: allValuesFrom rdf: Property ] , [ rdf: type owl: Restriction ; owl: onProperty rdfs: member ; owl: minQualifiedCardinality \"2\" ^^ xsd:nonNegativeInteger ; owl: onClass rdf: Property ] ; rdfs: subClassOf rdf: Seq ; rdfs: comment \"Represents a sequence of properties, analogously to a property path.\" @ en . ### http://lenticularlens.org/voidPlus/ResourceSelection voidPlus: ResourceSelection rdf: type owl: Class ; rdfs: subClassOf void: Dataset , [ rdf: type owl: Restriction ; owl: onProperty voidPlus: hasSubset ; owl: someValuesFrom voidPlus: Partition ] , [ rdf: type owl: Restriction ; owl: onProperty void: subset ; owl: someValuesFrom void: Dataset ] ; rdfs: comment \"A collection of resources stemmed from the same void:Dataset. It is expected to have as partition, directly or indirectly (i.e. as a subset), a void+:ClassPartition. It can also have void+:PropertyPartitions, where property-value(s) can be restricted, as well as void+:LanguagePartitions, where the language of the property-value(s) can be reestricted.\" @ en . ### http://lenticularlens.org/voidPlus/TypedPropertySequence voidPlus: TypedPropertySequence rdf: type owl: Class ; owl: equivalentClass [ rdf: type owl: Restriction ; owl: onProperty rdfs: member ; owl: allValuesFrom [ rdf: type owl: Class ; owl: unionOf ( rdf: Property rdfs: Class ) ] ] , [ rdf: type owl: Restriction ; owl: onProperty rdfs: member ; owl: minQualifiedCardinality \"1\" ^^ xsd:nonNegativeInteger ; owl: onClass rdfs: Class ] , [ rdf: type owl: Restriction ; owl: onProperty rdfs: member ; owl: minQualifiedCardinality \"2\" ^^ xsd:nonNegativeInteger ; owl: onClass rdf: Property ] ; rdfs: subClassOf rdf: Seq ; rdfs: comment \"\"\"Represents a sequence of properties and classes, as in a different type property path with class restriction in between: property -> class -> property -> class\"\"\"@en . ### http://lenticularlens.org/voidPlus/Validation voidPlus:Validation rdf:type owl:Class ; rdfs:subClassOf void:Dataset ; rdfs:comment \"A void:Dataset that contains triples regarding the validation of links from a void+:LinkDataset.\"@en . ### http://rdfs.org/ns/void#Dataset void:Dataset rdf:type owl:Class ; rdfs:comment \"A set of RDF triples that are published, maintained or aggregated by a single provider\"@en . ### http://rdfs.org/ns/void#Linkset void:Linkset rdf:type owl:Class ; rdfs:subClassOf voidPlus:DirectedLinkDataset ; rdfs:comment \"A collection of RDF links between *two* void:Datasets.\"@en . ### http://www.w3.org/1999/02/22-rdf-syntax-ns#Property rdf:Property rdf:type owl:Class ; rdfs:comment \"rdf:Property is the class of RDF properties.\"@en . ### http://www.w3.org/1999/02/22-rdf-syntax-ns#Seq rdf:Seq rdf:type owl:Class ; rdfs:comment \"The rdf:Seq class is the class of RDF 'Sequence' containers.\"@en . ### http://www.w3.org/2000/01/rdf-schema#Class rdfs:Class rdf:type owl:Class ; rdfs:comment \"This is the class of resources that are RDF classes.\"@en . ### Generated by the OWL API (version 4.5.9.2019-02-01T07:24:44Z) https://github.com/owlcs/owlapi","title":"3.3 VoID+ OWL"},{"location":"03.Ontology/#4-void-documentation","text":"Markdown documentation created by pyLODE 2.8.3 URI : http://lenticularlens.org/voidPlus Ontology RDF : download voidPlus.owl","title":"4. VoID+ Documentation"},{"location":"03.Ontology/#41-overview","text":"See Figure 7 and 8 above for an overview.","title":"4.1 Overview"},{"location":"03.Ontology/#42-classes","text":"","title":"4.2 Classes"},{"location":"03.Ontology/#classpartition","text":"Property Value URI http://lenticularlens.org/voidPlus/ClassPartition Description A void+:Partition that is partioned by a rdfs:Class. Super-classes void+:Partition","title":"ClassPartition"},{"location":"03.Ontology/#directedlinkdataset","text":"Property Value URI http://lenticularlens.org/voidPlus/DirectedLinkDataset Description A void+:LinkDataset that imposes that subjects always belong to the same datasets as well as objects. Super-classes void+:LinkDataset Sub-classes void+:Linkset void:Linkset In domain of void+:subjectsTarget void+:objectsTarget","title":"DirectedLinkDataset"},{"location":"03.Ontology/#documentedlinkdataset","text":"Property Value URI http://lenticularlens.org/voidPlus/DocumentedLinkDataset Description A void+:LinkDataset that requires detailed documentation, including targets described as void+:ResourceSelection (all values from) and a void+:Formulation. Super-classes void+:LinkDataset Sub-classes void+:Linkset void+:Lens","title":"DocumentedLinkDataset"},{"location":"03.Ontology/#formulation","text":"Property Value URI http://lenticularlens.org/voidPlus/Formulation Description A (reusable) formulation that lists a number of items (e.g. matching methods or linksets) and describes how they are meant to be combined (e.g. using logic or set operators). Sub-classes void+:LensFormulation void+:LinksetFormulation In domain of void+:hasItem In range of void+:hasFormulation","title":"Formulation"},{"location":"03.Ontology/#language","text":"Property Value URI http://lenticularlens.org/voidPlus/Language Description A set of standardized ISO langague codes. In range of void+:language","title":"Language"},{"location":"03.Ontology/#languagepartition","text":"Property Value URI http://lenticularlens.org/voidPlus/LanguagePartition Description A void+:Partition that is partioned by a void+:Language, i.e. an ISO standard language code. Super-classes void+:Partition","title":"LanguagePartition"},{"location":"03.Ontology/#lens","text":"Property Value URI http://lenticularlens.org/voidPlus/Lens Description Similar to a void+:Linkset (in the sense that it is a collection of links sharing the same linktype) also involving one, two or more datasets, but not necessarilly directed. Moreover, context-wise, it differs from a linkset as it is generated using different processes (set-like link manipulation operators such as Union, Intersection, Difference or Transitivity) as compared to how a linkset comes about (matching algorithms). Super-classes void+:DocumentedLinkDataset","title":"Lens"},{"location":"03.Ontology/#lensformulation","text":"Property Value URI http://lenticularlens.org/voidPlus/LensFormulation Description A resource that makes explicit all void+:LinkDatasets involved in the creation of a void+:Lens and how the they are combined. Super-classes void+:Formulation","title":"LensFormulation"},{"location":"03.Ontology/#linkdataset","text":"Property Value URI http://lenticularlens.org/voidPlus/LinkDataset Description A collection of RDF links between dataset(s), using the same link predicate (regardless of the link being an equality predicate or not). This predicate is called the linktype of the linkset. The links may have been stabilished among one (deduplication), two or many datasets. Super-classes void:Dataset Sub-classes void+:DirectedLinkDataset void+:DocumentedLinkDataset In domain of void+:hasValidation void+:hasFormulation void+:hasTarget","title":"LinkDataset"},{"location":"03.Ontology/#linkset","text":"Property Value URI http://lenticularlens.org/voidPlus/Linkset Description A void+DirrectedLinkDataset that is also a void+:DocumentedLinkDataset. Super-classes void+:DocumentedLinkDataset void+:DirectedLinkDataset","title":"Linkset"},{"location":"03.Ontology/#linksetformulation","text":"Property Value URI http://lenticularlens.org/voidPlus/LinksetFormulation Description A resource that makes explicit all void+:MatchingMethods involved in the creation of a void+:Linkset and how the methods are logically joint. Super-classes void+:Formulation","title":"LinksetFormulation"},{"location":"03.Ontology/#matchingalgorithm","text":"Property Value URI http://lenticularlens.org/voidPlus/MatchingAlgorithm Description A set of rules followed by a computer for finding pairs of matching resources. An algorithm can be further categorised as automated or semi-automated depending on whether it requires user assistance or not. Most matching algorithms employed in the Lenticular Lens are semi-automated. In range of void+:hasAlgorithm","title":"MatchingAlgorithm"},{"location":"03.Ontology/#matchingmethod","text":"Property Value URI http://lenticularlens.org/voidPlus/MatchingMethod Description A resource that makes explicit all parameters/pre-requisites of a matching algorithm including the conditions in which the algorithm is to accept a discovered link (threshold). In domain of void+:hasAlgorithm","title":"MatchingMethod"},{"location":"03.Ontology/#partition","text":"Property Value URI http://lenticularlens.org/voidPlus/Partition Description A void:Daset that is subset of another one. Sub-classes void+:ClassPartition void+:LanguagePartition void+:PropertyPartition In range of void+:hasSubset","title":"Partition"},{"location":"03.Ontology/#propertypartition","text":"Property Value URI http://lenticularlens.org/voidPlus/PropertyPartition Description A void+:Partition that is partioned by a rdf:Property. Super-classes void+:Partition","title":"PropertyPartition"},{"location":"03.Ontology/#propertysequence","text":"Property Value URI http://lenticularlens.org/voidPlus/PropertySequence Description Represents a sequence of properties, analogously to a property path. Super-classes rdf:Seq","title":"PropertySequence"},{"location":"03.Ontology/#resourceselection","text":"Property Value URI http://lenticularlens.org/voidPlus/ResourceSelection Description A collection of resources stemmed from the same void:Dataset. It is expected to have as partition, directly or indirectly (i.e. as a subset), a void+:ClassPartition. It can also have void+:PropertyPartitions, where property-value(s) can be restricted, as well as void+:LanguagePartitions, where the language of the property-value(s) can be reestricted. Super-classes void:Dataset Restrictions void:subset some void:Dataset void+:hasSubset some void+:Partition In range of void+:hasResourceSelection","title":"ResourceSelection"},{"location":"03.Ontology/#typedpropertysequence","text":"Property Value URI http://lenticularlens.org/voidPlus/TypedPropertySequence Description Represents a sequence of properties and classes, as in a different type property path with class restriction in between: property -> class -> property -> class Super-classes rdf:Seq","title":"TypedPropertySequence"},{"location":"03.Ontology/#validation","text":"Property Value URI http://lenticularlens.org/voidPlus/Validation Description A void:Dataset that contains triples regarding the validation of links from a void+:LinkDataset. Super-classes void:Dataset In range of void+:hasValidation","title":"Validation"},{"location":"03.Ontology/#dataset","text":"Property Value URI http://rdfs.org/ns/void#Dataset Description A set of RDF triples that are published, maintained or aggregated by a single provider Sub-classes void+:Validation void+:LinkDataset void+:ResourceSelection In domain of void:property void+:partitionedBy void+:hasSubset void:subset In range of void+:hasTarget void:subset void+:objectsTarget void:target void+:subjectsTarget","title":"Dataset"},{"location":"03.Ontology/#linkset_1","text":"Property Value URI http://rdfs.org/ns/void#Linkset Description A collection of RDF links between two void:Datasets. Super-classes void+:DirectedLinkDataset In domain of void:objectsTarget void:target void:subjectsTarget","title":"Linkset"},{"location":"03.Ontology/#property","text":"Property Value URI http://www.w3.org/1999/02/22-rdf-syntax-ns#Property Description rdf:Property is the class of RDF properties. In range of void:property","title":"Property"},{"location":"03.Ontology/#seq","text":"Property Value URI http://www.w3.org/1999/02/22-rdf-syntax-ns#Seq Description The rdf:Seq class is the class of RDF \u2018Sequence\u2019 containers. Sub-classes void+:PropertySequence void+:TypedPropertySequence","title":"Seq"},{"location":"03.Ontology/#class","text":"Property Value URI http://www.w3.org/2000/01/rdf-schema#Class Description This is the class of resources that are RDF classes. In range of void:class","title":"Class"},{"location":"03.Ontology/#43-object-properties","text":"","title":"4.3 Object Properties"},{"location":"03.Ontology/#hasalgorithm","text":"Property Value URI http://lenticularlens.org/voidPlus/hasAlgorithm Description relates a void+:MatchingMethod to its void+:MatchingAlgorithm. Domain(s) void+:MatchingMethod Range(s) void+:MatchingAlgorithm","title":"hasAlgorithm"},{"location":"03.Ontology/#hasclasspartition","text":"Property Value URI http://lenticularlens.org/voidPlus/hasClassPartition Description relates a void:Dataset to its subset void+:ClassPartition. In practice, the main difference wrt void:classPartition is the name meant to avoid missusage as it can be read as \u201cis classPartition of\u201d as well. Super-properties void+:hasSubset void:classPartition","title":"hasClassPartition"},{"location":"03.Ontology/#hasformulation","text":"Property Value URI http://lenticularlens.org/voidPlus/hasFormulation Description relates a void+:LinkDataset to its void+:Formulation. Domain(s) void+:LinkDataset Range(s) void+:Formulation","title":"hasFormulation"},{"location":"03.Ontology/#hasitem","text":"Property Value URI http://lenticularlens.org/voidPlus/hasItem Description relates a void+:Formulation to its items. Domain(s) void+:Formulation","title":"hasItem"},{"location":"03.Ontology/#haslanguagepartition","text":"Property Value URI http://lenticularlens.org/voidPlus/hasLanguagePartition Description relates a void:Dataset to its subset void+:LanguagePartition. Super-properties void+:hasSubset","title":"hasLanguagePartition"},{"location":"03.Ontology/#hasobjectresourceselection","text":"Property Value URI http://lenticularlens.org/voidPlus/hasObjectResourceSelection Description a relation to assing a void+:ResourceSelection as the source for the subjects of triples under scrutiny. Super-properties void+:hasResourceSelection","title":"hasObjectResourceSelection"},{"location":"03.Ontology/#haspropertypartition","text":"Property Value URI http://lenticularlens.org/voidPlus/hasPropertyPartition Description relates a void:Dataset to its subset void+:PropertyPartition. In practice, the main difference wrt void:propertyPartition is the name meant to avoid missusage as it can be read as \u201cis propertyPartition of\u201d as well. Super-properties void+:hasSubset void:propertyPartition","title":"hasPropertyPartition"},{"location":"03.Ontology/#hasresourceselection","text":"Property Value URI http://lenticularlens.org/voidPlus/hasResourceSelection Description a relation to assing a void+:ResourceSelection as the source for entities under scrutiny, for example, in a void+:MatchingMethos Range(s) void+:ResourceSelection","title":"hasResourceSelection"},{"location":"03.Ontology/#hassubjectresourceselection","text":"Property Value URI http://lenticularlens.org/voidPlus/hasSubjectResourceSelection Description a relation to assing a void+:ResourceSelection as the source for the objects of triples under scrutiny. Super-properties void+:hasResourceSelection","title":"hasSubjectResourceSelection"},{"location":"03.Ontology/#hassubset","text":"Property Value URI http://lenticularlens.org/voidPlus/hasSubset Description relates a void:Dataset that has subset another void+:Partition. In practice, the main difference wrt void:subset is the name meant to avoid missusage as it can be read as \u201cis subset of\u201d as well. For a similar puporse, an inverse relation void+:subsetOf is also defined. Super-properties void:subset Domain(s) void:Dataset Range(s) void+:Partition","title":"hasSubset"},{"location":"03.Ontology/#hastarget","text":"Property Value URI http://lenticularlens.org/voidPlus/hasTarget Description A relation that assigns one or more void:Datasets linked by the void+:LinkDataset. Domain(s) void+:LinkDataset Range(s) void:Dataset","title":"hasTarget"},{"location":"03.Ontology/#hasvalidation","text":"Property Value URI http://lenticularlens.org/voidPlus/hasValidation Description A relation that assigns a void+:LinkDataset to one or more void+:Validations. Domain(s) void+:LinkDataset Range(s) void+:Validation","title":"hasValidation"},{"location":"03.Ontology/#language_1","text":"Property Value URI http://lenticularlens.org/voidPlus/language Description A relation that assigns to a void:Dataset a void+:Language (for ISO standard language codes) that is the rdf:language of all literals (objects) qualifiying entities (subject) in a language-based partition. Super-properties void+:partitionedBy Range(s) void+:Language","title":"language"},{"location":"03.Ontology/#objectstarget","text":"Property Value URI http://lenticularlens.org/voidPlus/objectsTarget Description A relation that assigns void:Datasets describing the subjects of triples contained in the void+:DirectedLinkDataset. Super-properties void+:hasTarget Domain(s) void+:DirectedLinkDataset Range(s) void:Dataset","title":"objectsTarget"},{"location":"03.Ontology/#partitionedby","text":"Property Value URI http://lenticularlens.org/voidPlus/partitionedBy Description A relation that assigns to a void:Dataset to the conditions under which it is partitioned. Domain(s) void:Dataset","title":"partitionedBy"},{"location":"03.Ontology/#property_1","text":"Property Value URI http://lenticularlens.org/voidPlus/property Description A relation that assigns to a void:Dataset a rdf:Property or a rdf:Seq of properties that expresses the pattern of all triples in a property-based partition. Super-properties void+:partitionedBy Range(s) rdf:Property rdf:Seq","title":"property"},{"location":"03.Ontology/#subjectstarget","text":"Property Value URI http://lenticularlens.org/voidPlus/subjectsTarget Description A relation that assigns void:Datasets describing the objects of triples contained in the void+:DirectedLinkDataset. Super-properties void+:hasTarget Domain(s) void+:DirectedLinkDataset Range(s) void:Dataset","title":"subjectsTarget"},{"location":"03.Ontology/#subsetof","text":"Property Value URI http://lenticularlens.org/voidPlus/subsetOf Description relates a void+:Partition to its void:Dataset superset. Define as the inverse relation of void+:hasSubset.","title":"subsetOf"},{"location":"03.Ontology/#class_1","text":"Property Value URI http://rdfs.org/ns/void#class Description A relation that assigns to a void:Dataset a rdfs:Class that is the rdf:type of all entities (subject) in a class-based partition. Super-properties void+:partitionedBy Range(s) rdfs:Class","title":"class"},{"location":"03.Ontology/#classpartition_1","text":"Property Value URI http://rdfs.org/ns/void#classPartition Description A relation between a void:Dataset and its Partition, which is a subset of a void:Dataset that contains only entities of an explicitly defined rdfs:Class. Super-properties void:subset","title":"classPartition"},{"location":"03.Ontology/#objectstarget_1","text":"Property Value URI http://rdfs.org/ns/void#objectsTarget Description A relation that assigns the void:Dataset describing the objects of triples contained in the void:Linkset. Super-properties void+:objectsTarget void:target Domain(s) void:Linkset","title":"objectsTarget"},{"location":"03.Ontology/#property_2","text":"Property Value URI http://rdfs.org/ns/void#property Description A relation that assigns to a void:Dataset a rdf:Property that is the predicate of all triples in a property-based partition. Super-properties void+:property Domain(s) void:Dataset Range(s) rdf:Property","title":"property"},{"location":"03.Ontology/#propertypartition_1","text":"Property Value URI http://rdfs.org/ns/void#propertyPartition Description A relation between a void:Dataset and its Partition, which is a subset of a void:Dataset that contains only triples composed with an explicitly defined rdf:Property. Super-properties void:subset","title":"propertyPartition"},{"location":"03.Ontology/#subjectstarget_1","text":"Property Value URI http://rdfs.org/ns/void#subjectsTarget Description A relation that assigns the void:Dataset describing the subjects of triples contained in the void:Linkset. Super-properties void+:subjectsTarget void:target Domain(s) void:Linkset","title":"subjectsTarget"},{"location":"03.Ontology/#subset","text":"Property Value URI http://rdfs.org/ns/void#subset Description relates a void:Dataset that has subset another void:Dataset. Domain(s) void:Dataset Range(s) void:Dataset","title":"subset"},{"location":"03.Ontology/#target","text":"Property Value URI http://rdfs.org/ns/void#target Description A relation that assigns one of the two void:Datasets linked by the void:Linkset. Super-properties void+:hasTarget Domain(s) void:Linkset Range(s) void:Dataset","title":"target"},{"location":"03.Ontology/#member","text":"Property Value URI http://www.w3.org/2000/01/rdf-schema#member Description rdfs:member is an instance of rdf:Property that is a super-property of all the container membership properties. In particular, properties called rdf:_1, rdf:_2, rdf:_3\u2026 etc., used for rdf:Seq are sub-properties of rdfs:member.","title":"member"},{"location":"03.Ontology/#44-datatype-properties","text":"","title":"4.4 Datatype Properties"},{"location":"03.Ontology/#hasformuladescription","text":"Property Value URI http://lenticularlens.org/voidPlus/hasFormulaDescription Range(s) xsd:string","title":"hasFormulaDescription"},{"location":"03.Ontology/#45-namespaces","text":"owl : http://www.w3.org/2002/07/owl# prov : http://www.w3.org/ns/prov# rdf : http://www.w3.org/1999/02/22-rdf-syntax-ns# rdfs : http://www.w3.org/2000/01/rdf-schema# sdo : https://schema.org/ skos : http://www.w3.org/2004/02/skos/core# void : http://rdfs.org/ns/void# void+ : http://lenticularlens.org/voidPlus/ xsd : http://www.w3.org/2001/XMLSchema#","title":"4.5 Namespaces"},{"location":"04.Algorithms/","text":".katex img { display: block; position: absolute; width: 100%; height: inherit; } Matching Algorithms \u00b6 This section presents the catalogue of algorithms available in the Lenticular Lens and the standard expected Inputs and Outputs. The system offers a variety of existing algorithms from which the user can choose one or more in order to perform the matching among. These algorithms apply, for example, to strings, dates or URIs. Here by we describe the ones currently offered by the system and how they are meant to be used: Exact search Exact Mapping Embedded Change / Edit Jaro Jaro-Winkler Levenshtein Bloothooft Phonetic Soundex Metaphone Double Metaphone NYIIS Hybrid Intermediate ( exact and mapping ) Soundex Approximation ( phonetic and changes/edits ) Approx over Same-Soundex ( phonetic and changes/edits ) Word Intersection ( in-exact and changes/edits ) TeAM:Text-Approximation-Match ( changes/edits and phonetic ) Numerical Numbers Time Delta Make use of above methods List Intersection 1. Discrete Strength \u00b6 Her we present algorithms for which the resulting strength of a matched pair of resources is assigned the value of 1 as 0 means a match could not be found. Exact \u00b6 This method is used to align source and target\u2019s IRIs whenever their respective user selected property values are identical. In Example-1, the linkset ex:ExactLinkset is generated using the exact method over the predicate rdfs:label . Although only sharing the exact same name, these two entities are clearly not the same. Example 1 : Generating a linkset using the Exact algorithm. institutes: grid .1019.9 rdfs: label \"Victoria University\" ; grid: wikipediaPage wiki: Victoria_University , _Australia ; grid: establishedYear \"1916\" ^^ <http://www.w3.org/2001/XMLSchema#gYear> ; gridC: abbreviation > \"VU\" ; skos: prefLabel \"Victoria University\" ; \u2022\u2022\u2022 institutes: grid .449929 . b rdfs: label \"Victoria University\" ; grid: wikipediaPage <https://en.wikipedia.org/wiki/Victoria_University_Uganda> ; grid: establishedYear \"2011\" ^^ <http://www.w3.org/2001/XMLSchema#gYear> ; gridC: abbreviation > \"VUU\" ; skos: prefLabel \"Victoria University\" ; \u2022\u2022\u2022 ex: ExactLinkset { << institutes: grid .1019.9 owl: sameAs institutes: grid .449929 . b>> ll: hasMatchingStrength 1 . } Embedded \u00b6 The Embedded method extracts an alignment already provided within the source dataset. The extraction relies on the value of the linking property, i.e. property of the source that holds the identifier of the target (IRI of the target). The inconvenience in generating a linkset in such way is that the real mechanism used to create the existing alignment is not explicitly provided by the source dataset. Example-2 shows a sample of the Grid dataset with embedded links. With such links, Grid connects its instances to external datasets such as Wikidata for example using the link predicate: grid:hasWikidataId illustrated in Example-2 with the linkset graph ex:EmbeddedLinkset . Example 2 : Generating a linkset using the Embedded algorithm. institutes: grid .1001.0 foaf: homepage <http://www.anu.edu.au/> ; rdfs: label \"Australian National University\" ; grid: isni \"0000 0001 2180 7477\" ; grid: hasWikidataId wikidata: Q127990 ; \u2022 \u2022 \u2022 institutes: grid .1002.3 foaf: homepage <http://www.monash.edu/> ; rdfs: label \"Monash University\" ; grid: isni \"0000 0004 1936 7857\" ; grid: hasWikidataId wikidata: Q598841 ; \u2022 \u2022 \u2022 ex: EmbeddedLinkset { << institutes: grid .1001.0 grid: hasWikidataId wikidata: Q127990 >> ll: hasMatchingStrength 1 . << institutes: grid .1002.3 grid: hasWikidataId wikidata: Q598841 >> ll: hasMatchingStrength 1 . } Intermediate \u00b6 The method aligns the source and the target\u2019s IRIs via an intermediate database by using properties that potentially present different descriptions of the same entity, such as country name and country code. This is possible by providing an intermediate dataset that binds the two alternative descriptions to the very same identifier. Example 3.1 : Generating a linkset using the Intermediate-Datatse algorithm. In the example below, it is possible to align the source and target country entities using the properties country and iso-3 via the intermediate dataset because it contains the information described at both, the Source and Target. dataset: Source-Dataset dataset: Intermediate-Dataset { { ex : 1 rdfs: label \"Benin\" . ex : 7 ex : 2 rdfs: label \"Cote d'Ivoire\" . ex: name \"Cote d'Ivoire\" ; ex : 3 rdfs: label \"Netherlands\" . ex: code \"CIV\" . } ex : 8 dataset: Target-Datas ex: name \"Benin\" ; { ex: code \"BEN\" . ex : 4 ex: iso-3 \"CIV\" . ex : 5 ex: iso-3 \"NLD\" . ex : 9 ex : 6 ex: iso-3 \"BEN\" . ex: name \"Netherlands\" ; } ex: code \"NLD\" . } # --- ALIGNMENT ----------------------------- # \u2022 If rdfs:label is aligned with ex:name # \u2022 AND ex:iso-3 is aligned with ex:code, # \u2022 We then get the following linkset: # ------------------------------------------- linkset: Match-Via-Intermediate { <<ex : 1 owl: sameAs ex : 6 >> ll: hasMatchingStrength 1 . <<ex : 2 owl: sameAs ex : 4 >> ll: hasMatchingStrength 1 . <<ex : 3 owl: sameAs ex : 5 >> ll: hasMatchingStrength 1 . } Example 3.2 : Generating a linkset using the Intermediate-Datatse algorithm. In this second example, it is also possible to align the source and target datasets using the the authoritative intermediate dataset as it contains information described at both, the Source and Target. dataset: Source-Dataset dataset: Intermediate-Dataset { { ex : 10 rdfs: label \"Rembrandt\" . ex : 70 ex : 20 rdfs: label \"van Gogh\" . ex: name \"Vincent Willem van Gogh\" ; ex : 30 rdfs: label \"Vermeer\" . ex: name \"Vincent van Gogh\" ; } ex: name \"van Gogh\" . ex : 80 dataset: Target-Datas ex: name \"Rembrandt\" ; { ex: name \"Rembrandt van Rijn\" . ex : 40 schema: name \"Rembrandt van Rijn\" . ex : 50 schema: name \"Vincent van Gogh\" . ex : 90 ex : 60 schema: name \"Johannes Vermeer\" . ex: name \"Johannes Vermeer\" ; } ex: name \"Vermeer\" . } # --- ALIGNMENT ------------------------------------ # \u2022 If rdfs:label is aligned with ex:name # \u2022 AND schema:name is also aligned with ex:name, # \u2022 we then get the following linkset: # -------------------------------------------------- linkset: Match-Via-Intermediate { <<ex : 10 owl: sameAs ex : 40 >> ll: hasMatchingStrength 1 . <<ex : 20 owl: sameAs ex : 50 >> ll: hasMatchingStrength 1 . <<ex : 30 owl: sameAs ex : 60 >> ll: hasMatchingStrength 1 . } Soundex \u00b6 Soundex is a phonetic algorithm for indexing names by sound, as pronounced in English. The goal is for homophones to be encoded to the same representation so that they can be matched despite minor differences in spelling. The algorithm mainly encodes consonants; a vowel will not be encoded unless it is the first letter. Example 4 : Generating a linkset using the Soundex algorithm The examples below shows the encoding of different names. Here, the size parameter indicates a degree of similarity through the length of the respective soundex codes. For example at size=3, Albert and Albertine have the same soundex representation while at size=5 their respective representations differ. In the Lenticular lens, the default size is set to 3. # ----------------------------- # INPUT SIZE 3 SIZE 5 # ----------------------------- # A. A000 A00000 # AL A400 A40000 # ALI A400 A40000 # ALBERT A416 A41630 # ALBERTINE A416 A41635 ex : 128.45 rdfs: label \"ALBERT\" ; \u2022\u2022\u2022 ex : 6852 : 28 rdfs: label \"ALBERTINE\" ; \u2022\u2022\u2022 ex: ExactLinkset { <<ex : 128.45 owl: sameAs ex : 6852 : 28 >> ll: hasMatchingStrength 1 . } Metaphone \u00b6 TODO Example 5 : Double Metaphone \u00b6 TODO Example 6 : NYIIS \u00b6 TODO Example 7 : Numbers \u00b6 The method is used to align the source and the target IRIs whenever the delta difference between values (number/date) of the user selected properties is within a preset delta-threshold. Example 8 For example, if two entities have been aligned based on the similarity of their names but an extra check is to be investigated based on their respective year of birth, setting the delta-threshold to 1 year will ensure that the birth dates assigned to the two entities are no more than one year apart. Time Delta \u00b6 This function allows for finding co-referent entities on the basis of a minimum time difference between the times reported by the source and the target entities. For example, if the value zero is assigned to the time difference parameter, then, for a matched to be found, the time of the target and the one of the source are to be the exact same times. While accounting for margins of error, one may consider a pair of entities to be co-referent if the real entities are born lambda days, months or years apart among other-things (similar name, place..). Time Delta before, After or Between. Other ways of using time delta are also possible. Because Time Delta has no direction or sign (+ or -), it is not possible to require that the time documented at the source entity occurs before or after the one reported by the target\u2019s event. With the before / After options, this is possible. Using the Between option, we make it possible for the user to define the time interval in which both the source and target reported times can be viewed as acceptable. Example 9 : 2. Continuous Strength \u00b6 Her we present algorithms for which the resulting strength of a matched pair of resources is in the range ]0, 1] where 0 means a match could not be found while 1 means a perfect match is found. Jaro \u00b6 This \u200bmethod is used to align \u200b\u200bsource a\u200bnd \u200b\u200btarget\u2019s IRIs whenever the similarity score of their respective user selected property values are \u200b\u200babove a given threshold in the range ]0, 1]\u200b. Jaro distance is a measure of similarity between two strings. The higher the Jaro distance for two strings is, the more similar the strings are. The score is normalised such that 0 equates to no similarity and 1 is an exact match. Given two strings s 1 and s 2 , Find common characters x i and y j such that x i = y j where x i and y j are not more than d characters aways from each other and the acceptable matching distance d is half the longest input string as expressed in the formula: d = m a x ( \u2223 s 1 \u2223 , \u2223 s 2 \u2223 2 d = \\dfrac{max(|s_1|, |s_2|} {2} d = 2 m a x ( \u2223 s 1 \u200b \u2223 , \u2223 s 2 \u200b \u2223 \u200b Let c be number of common characters shared by s 1 and s 2 . From the resulting common characters in s 1 and s 2 , let t be the number of transposition which is the number of characters that do not share the same position. Compute the strength using the formula: d j = { 0 if c = 0 1 3 ( c \u2223 s 1 \u2223 + c \u2223 s 2 \u2223 + c \u2212 t \u2223 s 1 \u2223 ) otherwise d_j = \\begin{cases} 0 &\\text{if } c = 0 \\\\ \\dfrac{1}{3} \\Bigg( \\dfrac{c}{|s_1|} + \\dfrac{c}{|s_2|} + \\dfrac{c - t}{|s_1|} \\Bigg) &\\text{otherwise} \\end{cases} d j \u200b = \u23a9 \u23aa \u23aa \u23a8 \u23aa \u23aa \u23a7 \u200b 0 3 1 \u200b ( \u2223 s 1 \u200b \u2223 c \u200b + \u2223 s 2 \u200b \u2223 c \u200b + \u2223 s 1 \u200b \u2223 c \u2212 t \u200b ) \u200b if c = 0 otherwise \u200b Example 10: Jaro results SOURCE : |s| = |source| = 6 TARGET : |t| = |target| = 6 MATCHING DISTANCE : d = max(6, 6) = 3 COMMON CHARACTERS : m = |re| = |re| = 2 TRANSPOSITIONS : t = 0 STRENGTH : s = 1/3 * ( 2/6 + 2/6 + (2 - 0/2)/2) = 0.55556 SOURCE : |s| = |jono| = 4 TARGET : |t| = |ojhono| = 6 MATCHING DISTANCE : d = max(4, 6) = 3 COMMON CHARACTERS : m = |jono| = |ojon| = 4 TRANSPOSITIONS : t = 4 STRENGTH : s = 1/3 * ( 4/4 + 4/6 + (4 - 4/2)/4) = 0.72222 SOURCE : |s| = |DUANE| = 5 TARGET : |t| = |DWAYNE| = 6 MATCHING DISTANCE : d = max(5, 6) = 3 COMMON CHARACTERS : m = |DANE| = |DANE| = 4 TRANSPOSITIONS : t = 0 STRENGTH : s = 1/3 * ( 4/5 + 4/6 + (4 - 0/2)/4) = 0.82222 SOURCE : |s| = |DIXON| = 5 TARGET : |t| = |DICKSONX| = 8 MATCHING DISTANCE : d = max(5, 8) = 4 COMMON CHARACTERS : m = |DION| = |DION| = 4 TRANSPOSITIONS : t = 0 STRENGTH : s = 1/3 * ( 4/5 + 4/8 + (4 - 0/2)/4) = 0.76667 SOURCE : |s| = |JELLYFISH| = 9 TARGET : |t| = |SMELLYFISH| = 10 MATCHING DISTANCE : d = max(9, 10) = 5 COMMON CHARACTERS : m = |ELLYFISH| = |ELLYFISH| = 8 TRANSPOSITIONS : t = 0 STRENGTH : s = 1/3 * ( 8/9 + 8/10 + (8 - 0/2)/8) = 0.8963 Jaro-Winkler \u00b6 Given two strings s 1 and s 2 , the Winkler similarity equation boosts up the Jaro algorithm\u2019s result d j by increasing it whenever the compared strings share a prefix of a maximum of four characters. In this shared prefix scenario, the boost is computed as: w b = P l \u2217 P w ( 1 \u2212 d j ) w_b = P_l * P_w ( 1 - d_j ) w b \u200b = P l \u200b \u2217 P w \u200b ( 1 \u2212 d j \u200b ) where P l is the length of the set of shared prefix and P w is a user dependent scaling factor for how much the score is adjusted upwards for having common prefixes. Because four is the maximum number of shared prefix to consider, the user\u2019s choice of P w lies between 0 and \u00bc. Setting P w to \u00bc implies a similarity of always 1 whenever the strings share the maximum of 4 prefixes, no matter the real dissimilarity between the strings. The Jaro-Winkler is computed as: d j w = d j + w b d_{jw}= d_j+ w_b d j w \u200b = d j \u200b + w b \u200b Example 11: Jaro vs Jaro-Winkler jaro ( \"alexander\" , \"alexandrine\" ) = 0.90236 jaro_winkler ( \"alexander\" , \"alexandrine\" , weight = 0.1 ) = 0.94141 Levenshtein \u00b6 This \u200bmethod is used to align \u200b\u200bsource a\u200bnd \u200b\u200btarget\u2019s IRIs whenever the similarity score of their respective user selected property values are \u200b\u200babove a given \u200bLevenshtein Distance threshold\u200b. Levenshtein (a.k.a. Edit Distance) is a way of quantifying how \u200bdissimilar two strings (e.g., words) are to one another by counting the minimum number of operations \u200b\u03b5 \u200b (\u200bremoval, insertion, or substitution of a character in the string)\u200b required to transform one string into the other. For example, \u200bthe \u200bLevenshtein distance between \u201ckitten\u201d and \u201csitting\u201d is \u200b\u03b5 \u200b= 3 as it requires two substitutions (\u201cs\u201d for \u201ck\u201d and \u201ci\u201d for \u201ce\u201d) and one insertion of \u201cg\u201d at the end. Normalisation \u200b\u03a9\u200b: In the Lenticular Lens , the \u200bsimilarity score \u200b\u03a9 \u200bof a matching pair of resources is quantified in the interval \u200b[0, 1]\u200b. For this, the\u200b dissimilarity score \u200b\u03b5 expressing the \u200bminimum number of operations to perform for \u200btwo strings to be the same \u200bis normalised as \u200b\u03a9 based on the length of the longest string. The \u200bdissimilarity score\u200b\u200b \u03b5\u200b = 3 \u200bbetween \u200b\u201dkitten\u201d and \u201csitting\u201d is then normalised to a \u200bsimilarity score \u03a9\u200b \u200b=\u200b \u200b1 - 3 / 7 = 0.57\u200b.\u200b Minimum threshold \u200b\u03c6: Using this algorithm, \u200ba \u200bminimum threshold value\u03c6\u200b \u200bmust be set in the interval \u200b[0,1], \u200bsuch that finding any matched pairs of IRIs based on the similarity of their respective property values depends on whether or not the computed \u200b\u03a9 is \u200bequal or above \u200b\u03c6\u200b. A threshold \u200b\u03c6 = 1 equates an exact match. In our previous example, if a \u200bminimum threshold of \u200b\u03c6 = \u200b0.7 is set, \u201ckitten\u201d and \u201csitting\u201d will not be matched. \u200bIn short, \u200b\u03c6 is the user defined threshold when the similarity score \u200b\u03a9 is selected for accepting or rejecting a match. Maximum character error threshold \u200b\ud835\udeff:\u200b In case the \u200boriginal edit distance score \u200b\u03b5 (minimum number of operations score) is preferred, the number of character errors \u200b\ud835\udeff \u200bof choice is used instead as threshold for deciding whether a match is accepted or rejected. However, for consistency purposes, the corresponding normalisation value \u200b\u03a9 is still computed for the minimum number of operations score computed \u200b\u03b5\u200b. For instance, in our previous example, if a \u200bmaximum \u200bcharacters errors i\u200bs set to \u200b\ud835\udeff = 3, \u201ckitten\u201d and \u201csitting\u201d will be matched but the computed strength will be \u200b\u03a9 = \u200b0.57 a\u200bnd \u200bnot \u200b\u03b5 = 3 as is it only serves the purpose of decision maker. I\u200bn short, \u200b\ud835\udeff i\u200bs the user defined threshold when the dissimilarity score \u03b5\u200b \u200bis selected for accepting or rejecting a match. Example 12 : The Levenshtein options 1. l_dist(Rembrand van Rijn, Rembrandt Harmensz van Rijn) = 10 2. Normalised_l_dist \u200b(Rembrand van Rijn, Rembrandt Harmensz van Rijn) = 0.63 >>> If \u200b\u03c6 (Minimum threshold) = 0.7 >>> t\u200bhen \u200b[\u200bRembrand van Rijn] owl:sameAs [Rembrandt Harmensz van Rijn] >>> is rejected\u200b >>> because \u03a9\u200b = 0.63 < \u03c6\u200b. >>> If \u200b\u03b4 (Maximum character error threshold) = 5 >>> t\u200bhen [\u200b\u200bRembrand van Rijn] and [Rembrandt Harmensz van Rijn] is \u200brejected >>> because \u03b5 \u200b= 10 >\u200b \u200b\u03b4. Soundex Approximation \u00b6 This option is performed in two phases. First, the string values of the user selected properties are normalised (converted to a soundex code). Then a user selected matcher (Levenshtein, Jaro, jaro-Winkler\u2026) is run over the normalised string (Soundex code). Example 13: Links found using soundex In the example below, given ex:E1 and ex:E2 , the matching strength using Edit Distance is 1 - \u215b = 0.875. When directly performing an Edit distance match or a Soundex, we respectively get 0.625 and 0 as strengths. # ------------------------------- # INPUT SIZE 3 SIZE 4 # ------------------------------- # Carretta C630 C6300 # Kareta K630 K6300 ex: E1 rdfs: label \"Carretta\" . ex: E2 rdfs: label \"Kareta\" . ex: ExactLinkset { << ex: E1 skos: closeMatch <ex:E2> > ll: hasMatchingStrength 0.875 . } Approx over Same-Soundex \u00b6 In the Lenticular Lens , Soundex can also be used as a first filtering step (string normalisation). This means that first we select all pairs sharing the same Soundex code. Then, for each of these pairs an extra string sequence matching algorithm such as (Levenshtein, Jaro, Jaro-Winkler\u2026) is applied to the original pair of matched strings (not the Soundex codes) to determine the strength of the match in the interval ]0, 1]. Example 14 : Generating a linkset using the Soundex algorithm. In the table below, the normalisation of both Louijs Rocourt and Lowis Ricourt becomes L200 R263 leading to an edit distance of 0 and a relative strength of 1. However, computing the same names using directly an edit distance results in an edit distance of 3 and a relative matching strength of 0.79. The example below shows the implementation of Soundex Distance in the Lenticular Lens and how it compares with Edit Distance over the original names ( no soundex-based normalisation ). ------------------------------------------------------------------------------------------------------------------------------------------------------ Source Target E . Dist Rel . distance Source soundex Target soundex Code E . Dist Code Rel . Dist ------------------------------------------------------------------------------------------------------------------------------------------------------ Jasper Cornelisz . Lodder Jaspar Cornelisz Lodder 2 0.92 J 216 C 654 L 360 J 216 C 654 L 360 0 1.0 Barent Teunis Barent Teunisz gen . Drent 12 0.52 B 653 T 520 B 653 T 520 G 500 D 653 10 0.47 Louijs Rocourt Louys Rocourt 2 0.86 L 200 R 263 L 200 R 263 0 1.0 Louijs Rocourt Lowis Ricourt 3 0.79 L 200 R 263 L 200 R 263 0 1.0 Louys Rocourt Lowis Ricourt 3 0.77 L 200 R 263 L 200 R 263 0 1.0 Cornelis Dircksz . Clapmus Cornelis Clapmuts 10 0.6 C 654 D 620 C 415 C 654 C 415 5 0.64 Geertruydt van den Breemde Geertruijd van den Bremde 4 0.85 G 636 V 500 D 500 B 653 G 636 V 500 D 500 B 653 0 1.0 Bloothooft \u00b6 This approximation method is specifically tailored for accessing the similarity between a pair of IRIs for which the user selected property values are Dutch names. The algorithm basically normalises the given names by removing or replacing specific characters\u2026. The resulting normalised names are then pairwise compared using the Approximated Levenshtein Distance (see the description of Approximated Levenshtein Distance). Example 15 : Word Intersection \u00b6 This approximation method is originally designed to find a subset of words within a larger text. However, it could also be used for any pair of strings regardless of the strings sizes. Several options are available: Whether or not the order in which the words are found is important. Whether or not the computed strength of each word should be approximated or identical. Whether or not abbreviation should be detected. Whether the default stopping character should be used, not used or modified. A threshold on the number of words not approximated/identical. An overall threshold for accepting or rejecting a match. Example 16 : Expectation For example, it can be used for aligning - [Rembrand van Rijn] and [van Rijn Rembrandt] - [Herdoopers anslagh op Amsterdam] and [Herdoopers anslagh op Amsterdam. Den x. may: 1535. Treur-spel.] regardless of the words\u2019 order. Example 1 With argument APPROX set to True, similarity can be found between Rembrand and Rembrandt (MODE-1). However, this is not possible in the inverse scenario (MODE-2). Furthermore, when the order is of no importance (MODE-1) the sequence in which the intersection of words appears is of no importance. SMALL : Rembrand (van) Rijn BIG : Rembrandt Harmensz. van Rijn MODE-1 : APPROX = True and ORDER = False FOUND : ['rijn', 'rembrandt'] STRENGTH : 0.97059 MODE-2 : APPROX = False and ORDER = True and FOUND : [] STRENGTH : 0.0 Example 2 Because the match is performed over exact occurrences (APPROX = False) and the sequence in which the matched words appear in the text is of importance (ORDER = True), elvervelt is the only intersection found in MODE-2 and thereby bringing the similarity strength to 0.333. SMALL : Elvervelt, Henrik van BIG : Henrik van Elvervelt MODE-1 : APPROX = True and ORDER = False FOUND : ['elvervelt', 'henrik', 'van'] STRENGTH : 1.0 MODE-2 : APPROX = False and ORDER = True and FOUND : ['elvervelt'] STRENGTH : 0.333 Example 3 In here all intersected words appear in the same sequence and without mismatch. SMALL : Herdoopers anslagh op Amsterdam BIG : Herdoopers anslagh op Amsterdam. Den x. may: 1535. Treur-spel. MODE-1 : APPROX = True and ORDER = False FOUND : ['herdoopers', 'anslagh', 'op', 'amsterdam'] STRENGTH : 1.0 MODE-2 : APPROX = False and ORDER = True and FOUND : ['herdoopers', 'anslagh', 'op', 'amsterdam'] STRENGTH : 1.0 List Intersection \u00b6 This method is better suited for matching events. It helps establishing a relationship between the source and target entities whenever a list of entities from the source dataset intersects another list of entities stemmed from the target dataset. For illustration, suppose that we have the two events in Example-17. (1) Event one, defined by the source event-entities, documents event-entities that lists entities representing persons about to get married. This event is the Intended-Marriage event. (2) Event two is the Marriage event. It lists (i) entities representing persons that got married and (ii) the guests who attended the event. Now that the two events are defined, let us imagine that we would like to find out which of the Intended-Marriage couple fulfilled its will to get married. For this to be true, we assume that a couple with the wish to be wed should end-up being present at a Marriage event, hopefully their own marriage. This means that, for a match to occur, a minimum of two elements from a list from the source must also belong to a list from the target. In other words, a match is to be generated whenever 100% (all) of the elements in a source\u2019s lists intersects a target\u2019s list. In this method, two thresholds are to be defined. The first threshold or similarity-threshold imposes a minimum accepted similarity score (generally in ]0, 1]) when elements stemmed from different lists are compared. Passing this threshold is interpreted as the occurrence of an intersection between elements of two lists. The second threshold, the intersection-threshold expressed in quantity or percentage, denotes the minimum number of intersections that must occur for a link to be created. In practice, looking at Example-17, only events ex: intended-1 and ex:married-2 are a match as the pairs ( Catharina Reminck , Catharina Remink ) and ( Mr. Jean de Melie , Jean de Melie ) are respectively similar with a score of 0.94 and 0.82. aaaa Example 17 : List Intersection A source dataset documenting events as lists of couple with the intention of getting married and a target dataset with list of people at a wedding ceremony. Each of these latter lists is expected to includes the wed couple. --------------------------------------------------------------------------------------------- Source Dataset Target Dataset --------------------------------------------------------------------------------------------- ex: intended-1 ex: ceremony-1 ex: wife \"Catharina Reminck\" ; ex: participant \"Pieter Jas\" ; ex: husband \"Mr. Jean van de Melie\" . ex: participant \"Jacob Poppen\" ; ex: participant \"Gillis Graafland\" ; ex: intended-2 ex: participant \"Jacob Fransz. de Witt\" ; ex: wife \"Eva Oostrom\" ; ex: participant \"Elisabeth van Daaken\" ; ex: husband \"Pieter de Vriest\" . ex: participant \"Catharina Berewouts\" ; ex: participant \"Aafje Hendricx\" ; ex: intended-3 ex: participant \"Anthony van Paembergh\" ; ex: wife \"Eva Oostrom ; ex:participant \" Eva van Toorn \" ; ex: husband \"Wiggert van Wesick\" . ex: participant \"Maria Bor\" . ex: married-2 ex: participant \"J. van de Melie\" , \"Bernardus van Vijven\" . \"Margrita Schrik\" , \"Johannes de Bruijn\" , \"Maria Gosina Demol\" , \"Agneta Swartepaart\" , \"Hendrik de Lange\" , \"Catharina Remink\" . With a Similarity-threshold set to 0.8 and an Intersection-threshold set to 2 or 100%, only events ex:intended-1 and ex:married-2 are a match as the pairs ( Catharina Reminck , Catharina Remink ) and ( Mr. Jean de Melie , Jean de Melie ) are respectively similar with a score of 0.94 and 0.82. TeAM \u00b6 The TeAM (Text Approximation Match) method allows for the approximation of the relevance of a document to a query. Such approximation can be done using lexical similarity (word level similarity), semantic similarity or hybrid similarities. In this method, the focus is rather on the lexical similarity. Although tailored to text, it has been adapted to also be applicable to name-based similarity. We now provide an overview of the motivation context supporting the design and implementation of the algorithm. The Amsterdam\u2019s city archives (SAA) possesses physical handwritten inventories records where a record may be for example an inventory of goods (paintings, prints, sculpture, furniture, porcelain, etc.) owned by an Amsterdamer and mentioned in a last will. Interested in documenting the ownership of paintings from the 17 th century, the Yale University Professor John Michael Montias compiled a database by transcribing 1280 physical handwritten inventories (scattered in the Netherlands) of goods. Now that a number of these physical inventories have been digitised using handwriting recognition, one of the goals of the Golden Agent project is to identify Montias\u2019 transcriptions of painting selections within the digitised inventories. This problem can be generically reformulated as, given a source-segment database (e.g. Montias DB) and a target-segment database (e.g. SAA) , find the best similar target segment for each source segment . Fig 4.9: Digitisation of inventory documents available at the Amsterdam\u2019s city archives. Check TeAM for a more detailed explanation. 3. Results Combination \u00b6 This section addresses Complex Methods as ways to combine matching methods, not to be confused with the complexity of the underlying the methods. All of the matching methods described earlier generate links with matching strength scores in the interval ]0, 1]. We saw for example that the relative strength score between \u200b Rembrand van Rijn and Rembrandt Harmensz van Rijn is 0.63 using the Levenshtein algorithm and 0.74 using Soundex. Those methods can be combined at time of creation of the linkset, using logic boxes, or afterwards, using lenses operators. When such combination happens, a decision is necessary regarding the calculation of the resulting strength score. For example, let us assume that links are created whenever a pair of datasets items (subject, object) either sounds alike or looks alike character-wise . To accomplish that, it means that two methods have to be combined, for example, Soundex and Levenshtein. Although combining the methods seems relatively easy, deciding on the matching score requires some extra thoughts. In the example above of Rembrandt, shall we consider 0.63 or 0.74? Or their product? Here we discuss the rationals used in the Lenticular lens to support such decision. The two standard logic operators traditionally used are Conjunction (AND) and Disjunction (OR) . The first takes the minimum strength and the latter takes the maximum strength. This applies for both classic values (True -1- or False -0-) and fuzzy values ( between 0 and 1 ). Since the results from matching methods are fuzzy values in the interval ]0,1], the table bellow illustrates the default behaviour of the Lenticular Lens when combining them. Example 18: Standard logic operations over conjunction (min) and disjunction (max). Source Target Levenshtein Soundex OR(max) AND(min) ------------------------------------------------------------------------------------------------------ Jasper Cornelisz. Lodder Jaspar Cornelisz Lodder 0.92 1.00 1.00 0.92 Rembrand van Rijn Rembrandt Harmensz van Rijn 0.63 0.74 0.74 0.63 Barent Teunis Barent Teunisz gen. Drent 0.52 0.47 0.52 0.47 However, more sophisticated operations can also be used, such as the T-norm binary operations as alternatives for Conjunction (AND) and the T-conorm binary operations as alternatives for Disjunction (OR) as provided in the next subsections. T-norms \u00b6 A list of six different operations can be applied when dealing with methods combined by Conjunction . Here, we present them: Minimum t-norm \u22a4 min (a, b) = min(a, b) Product t-norm \u22a4 prod (a, b) = a . b \u0141ukasiewicz t-norm \u22a4 Luk (a, b) = max(0, a + b - 1) Drastic \u22a4 D ( a , b ) = { b if a = 1 a if b = 1 0 otherwise \u22a4_D(a, b) = \\begin{cases} b &\\text{if } a = 1 \\\\ a &\\text{if } b = 1 \\\\ 0 &\\text{otherwise} \\end{cases} \u22a4 D \u200b ( a , b ) = \u23a9 \u23aa \u23aa \u23a8 \u23aa \u23aa \u23a7 \u200b b a 0 \u200b if a = 1 if b = 1 otherwise \u200b Nilpotent minimum \u22a4 n M ( a , b ) = { m i n ( a , b ) if a + b > 1 0 otherwise \u22a4_{nM}(a, b) = \\begin{cases} min(a, b) &\\text{if } a + b > 1 \\\\ 0 &\\text{otherwise} \\end{cases} \u22a4 n M \u200b ( a , b ) = { m i n ( a , b ) 0 \u200b if a + b > 1 otherwise \u200b Hamacher product \u22a4 H 0 ( a , b ) = { 0 if a = b = 0 a b a + b \u2212 a b otherwise \u22a4_{H_0}(a, b) = \\begin{cases} 0 &\\text{if } a = b = 0 \\\\ \\dfrac{ab}{a + b - ab} &\\text{otherwise} \\end{cases} \u22a4 H 0 \u200b \u200b ( a , b ) = \u23a9 \u23aa \u23a8 \u23aa \u23a7 \u200b 0 a + b \u2212 a b a b \u200b \u200b if a = b = 0 otherwise \u200b The following table provides three case studies to illustrate the application of each of the aforementioned T-norm binary operations . They are presented in order from the less strict ( \u22a4 min ) to the most strict ( \u22a4 D ). Source, Target Levenshtein, Soundex \u22a4 min \u22a4 H 0 \u22a4 prod \u22a4 nM \u22a4 Luk \u22a4 D Src : Jasper Cornelisz. Lodder Trg : Jaspar Cornelisz Lodder 0.92, 1.00 0.920 0.920 0.920 0.920 0.920 0.920 Src : Rembrand van Rijn Trg : Rembrandt Harmensz van Rijn 0.63, 0.74 0.630 0.516 0.466 0.630 0.370 0.000 Src : Barent Teunis Trg : Barent Teunisz gen. Drent 0.52, 0.47 0.470 0.328 0.244 0.000 0.000 0.000 T-conorms \u00b6 A list of six different operations can also be applied when dealing with methods combined by Disjunction . Here, we present them: Maximum t-conorm \u22a5 max (a, b) = max(a, b) Probabilistic sum \u22a5 sum (a, b) = a + b - a.b Bounded sum \u22a5 Luk (a, b) = min(a + b, 1) Drastic t-conorm \u22a5 D ( a , b ) = { b if a = 0 a if b = 0 1 otherwise \u22a5_D(a, b) = \\begin{cases} b &\\text{if } a = 0 \\\\ a &\\text{if } b = 0 \\\\ 1 &\\text{otherwise} \\end{cases} \u22a5 D \u200b ( a , b ) = \u23a9 \u23aa \u23aa \u23a8 \u23aa \u23aa \u23a7 \u200b b a 1 \u200b if a = 0 if b = 0 otherwise \u200b Nilpotent maximum \u22a5 n M ( a , b ) = { m a x ( a , b ) if a + b < 1 1 otherwise \u22a5_{nM}(a, b) = \\begin{cases} max(a, b) &\\text{if } a + b < 1 \\\\ 1 &\\text{otherwise} \\end{cases} \u22a5 n M \u200b ( a , b ) = { m a x ( a , b ) 1 \u200b if a + b < 1 otherwise \u200b Einstein sum \u22a5 H 2 (a, b) = a + b 1 + a b \\dfrac{a + b} {1 + ab} 1 + a b a + b \u200b Source, Target Levenshtein, Soundex \u22a4 D \u22a4 Luk \u22a4 H 2 \u22a4 sum \u22a4 nM \u22a4 max Src : Jasper Cornelisz. Lodder Trg : Jaspar Cornelisz Lodder 0.92, 1.00 1.000 1.000 1.000 1.000 1.000 1.000 Src : Rembrand van Rijn Trg : Rembrandt Harmensz van Rijn 0.63, 0.74 1.000 1.000 0.934 0.904 1.000 0.740 Src : Barent Teunis Trg : Barent Teunisz gen. Drent 0.52, 0.47 1.000 0.990 0.796 0.746 0.520 0.520 Examples \u00b6 Suppose that, two data items E-1 and E-2 have the following information: E-1 Name : Titus Rembrandtsz. van Rijn Mather : Saskia Uylenburgh Father : Rembrand van Rijn Parent\u2019s Marriage date : 1644-06-22 E-2 Name : T. Rembrandtszoon van Rijn Mather : Saske van Uijlenburg Father : Rembrandt Harmensz van Rijn Baptism date :1641-09-22 To interpret E-1 and E-2 as representing co-referent persons, the following four tests are proposed. Test-1 OR Here, the names of E-1 and E-2 are to be compared using the Levenshtein and Soundex algorithms at a threshold of at least 0.7 . MATCHING RESULTS - Levenshtein(Titus Rembrandtsz van Rijn, T. Rembrandtszoon van Rijn) => 0.73 \u2705 - sdx_1 = Soundex(Titus Rembrandtsz van Rijn) = T320 R516 V500 R250 - sdx_2 = Soundex(T. Rembrandtszoon van Rijn) = T000 R516 V500 R250 - Levenshtein(sdx_1, sdx_2) => 0.89 \u2705 DISJUNCTIONS RESULTS - names similarity = t_conorm(0.73, 0.88, 'MAXIMUM') => 0.89 \u2705 - names similarity = t_conorm(0.73, 0.88, 'PROBABILISTIC') => 0.97 \u2705 Test-2 AND Names of the postulated mothers and fathers are to be similar at a threshold of at least 0.6 using the Levenshtein algorithm. MATCHING RESULTS - Levenshtein(Saskia Uylenburgh, Saske van Uijlenburg) => 0.65 \u2705 - Levenshtein(Rembrand van Rijn, Rembrandt Harmensz van Rijn) => 0.63 \u2705 CONJUNCTION RESULTS - Parent's names similarity = t_norm(0.65, 0.63, 'MINIMUM') => 0.63 \u2705 - Parent's names similarity = t_norm(0.65, 0.63, 'HAMACHER') => 0.47 \u274c Test-3 The period between the parent\u2019s marriage date on the one side and the child\u2019s baptism date on the other side are to be no more than 25 years apart . MATCHING RESULTS - Delta(1668-02-28, 1669-03-22, 25) => 1.00 \u2705 Test-4 AND Combining all above three tests considering a the conjunction fuzzy operator should result in a similarity score above or equal to 0.8. -------------------------------------------------------------------------------------- FINAL CONJUNCTIONS WITH A TRUTH VALUE LIST OF [0.850, 0.63, 1] -------------------------------------------------------------------------------------- - t_norm_list([0.850, 0.63, 1], 'MINIMIUM') => 0.63 \u274c - t_norm_list([0.850, 0.63, 1], 'HAMACHER') => 0.58 \u274c - t_norm_list([0.850, 0.63, 1], 'PRODUCT') => 0.56 \u274c - t_norm_list([0.850, 0.63, 1], 'NILPOTENT') => 0.63 \u274c - t_norm_list([0.850, 0.63, 1], '\u0141uk') => 0.52 \u274c - t_norm_list([0.850, 0.63, 1], 'DRASTIC') => 0.00 \u274c -------------------------------------------------------------------------------------- CONJUNCTIONS WITH A DIFFERENT LIST OF TRUTH VALUES [0.89, 0.82, 1] -------------------------------------------------------------------------------------- - t_norm_list([0.89, 0.82, 1], \"MINIMUM\") => 0.82 \u2705 - t_norm_list([0.89, 0.82, 1], \"HAMACHER\") => 0.74 \u274c - t_norm_list([0.89, 0.82, 1], \"PRODUCT\") => 0.73 \u274c - t_norm_list([0.89, 0.82, 1], \"NILPOTENYT\") => 0.82 \u2705 - t_norm_list([0.89, 0.82, 1], \"LUK\") => 0.71 \u274c - t_norm_list([0.89, 0.82, 1], \"DRASTIC\") => 0.0 \u274c -------------------------------------------------------------------------------------- EXAMPLE USING MORE THAN ONE FUZZY LOGIC OPERATOR -------------------------------------------------------------------------------------- - Ops.t_norm(Ops.t_norm(0.850, 0.63, 'HAMACHER'), 1, 'MINIMIUM') => 0.57 \u274c - Ops.t_norm(Ops.t_norm(0.850, 0.63, 'MINIMIUM'), 1, 'HAMACHER') => 0.63 \u274c Conclusion : Given the evidence provided for E-1 and E-2 and the rules described above, the interpretation resulting from the chosen fuzzy logic operations leads to the conclusion that there is no sufficient evidence to infer that the underlying data items are co-referent. This rejection is mainly due to the low similarity of the parents\u2019 names. If the resulting similarity were above 0.8, there would then be a better chance for the data items to be co-referent. Keep in mind that our conjectured rule asserts an identity relation for combination of scores only when above 0.8. A better data or more advanced algorithm could have helped.","title":"4. Matching Algorithms"},{"location":"04.Algorithms/#matching-algorithms","text":"This section presents the catalogue of algorithms available in the Lenticular Lens and the standard expected Inputs and Outputs. The system offers a variety of existing algorithms from which the user can choose one or more in order to perform the matching among. These algorithms apply, for example, to strings, dates or URIs. Here by we describe the ones currently offered by the system and how they are meant to be used: Exact search Exact Mapping Embedded Change / Edit Jaro Jaro-Winkler Levenshtein Bloothooft Phonetic Soundex Metaphone Double Metaphone NYIIS Hybrid Intermediate ( exact and mapping ) Soundex Approximation ( phonetic and changes/edits ) Approx over Same-Soundex ( phonetic and changes/edits ) Word Intersection ( in-exact and changes/edits ) TeAM:Text-Approximation-Match ( changes/edits and phonetic ) Numerical Numbers Time Delta Make use of above methods List Intersection","title":"Matching Algorithms  "},{"location":"04.Algorithms/#1-discrete-strength","text":"Her we present algorithms for which the resulting strength of a matched pair of resources is assigned the value of 1 as 0 means a match could not be found.","title":"1. Discrete Strength"},{"location":"04.Algorithms/#exact","text":"This method is used to align source and target\u2019s IRIs whenever their respective user selected property values are identical. In Example-1, the linkset ex:ExactLinkset is generated using the exact method over the predicate rdfs:label . Although only sharing the exact same name, these two entities are clearly not the same. Example 1 : Generating a linkset using the Exact algorithm. institutes: grid .1019.9 rdfs: label \"Victoria University\" ; grid: wikipediaPage wiki: Victoria_University , _Australia ; grid: establishedYear \"1916\" ^^ <http://www.w3.org/2001/XMLSchema#gYear> ; gridC: abbreviation > \"VU\" ; skos: prefLabel \"Victoria University\" ; \u2022\u2022\u2022 institutes: grid .449929 . b rdfs: label \"Victoria University\" ; grid: wikipediaPage <https://en.wikipedia.org/wiki/Victoria_University_Uganda> ; grid: establishedYear \"2011\" ^^ <http://www.w3.org/2001/XMLSchema#gYear> ; gridC: abbreviation > \"VUU\" ; skos: prefLabel \"Victoria University\" ; \u2022\u2022\u2022 ex: ExactLinkset { << institutes: grid .1019.9 owl: sameAs institutes: grid .449929 . b>> ll: hasMatchingStrength 1 . }","title":"Exact"},{"location":"04.Algorithms/#embedded","text":"The Embedded method extracts an alignment already provided within the source dataset. The extraction relies on the value of the linking property, i.e. property of the source that holds the identifier of the target (IRI of the target). The inconvenience in generating a linkset in such way is that the real mechanism used to create the existing alignment is not explicitly provided by the source dataset. Example-2 shows a sample of the Grid dataset with embedded links. With such links, Grid connects its instances to external datasets such as Wikidata for example using the link predicate: grid:hasWikidataId illustrated in Example-2 with the linkset graph ex:EmbeddedLinkset . Example 2 : Generating a linkset using the Embedded algorithm. institutes: grid .1001.0 foaf: homepage <http://www.anu.edu.au/> ; rdfs: label \"Australian National University\" ; grid: isni \"0000 0001 2180 7477\" ; grid: hasWikidataId wikidata: Q127990 ; \u2022 \u2022 \u2022 institutes: grid .1002.3 foaf: homepage <http://www.monash.edu/> ; rdfs: label \"Monash University\" ; grid: isni \"0000 0004 1936 7857\" ; grid: hasWikidataId wikidata: Q598841 ; \u2022 \u2022 \u2022 ex: EmbeddedLinkset { << institutes: grid .1001.0 grid: hasWikidataId wikidata: Q127990 >> ll: hasMatchingStrength 1 . << institutes: grid .1002.3 grid: hasWikidataId wikidata: Q598841 >> ll: hasMatchingStrength 1 . }","title":"Embedded"},{"location":"04.Algorithms/#intermediate","text":"The method aligns the source and the target\u2019s IRIs via an intermediate database by using properties that potentially present different descriptions of the same entity, such as country name and country code. This is possible by providing an intermediate dataset that binds the two alternative descriptions to the very same identifier. Example 3.1 : Generating a linkset using the Intermediate-Datatse algorithm. In the example below, it is possible to align the source and target country entities using the properties country and iso-3 via the intermediate dataset because it contains the information described at both, the Source and Target. dataset: Source-Dataset dataset: Intermediate-Dataset { { ex : 1 rdfs: label \"Benin\" . ex : 7 ex : 2 rdfs: label \"Cote d'Ivoire\" . ex: name \"Cote d'Ivoire\" ; ex : 3 rdfs: label \"Netherlands\" . ex: code \"CIV\" . } ex : 8 dataset: Target-Datas ex: name \"Benin\" ; { ex: code \"BEN\" . ex : 4 ex: iso-3 \"CIV\" . ex : 5 ex: iso-3 \"NLD\" . ex : 9 ex : 6 ex: iso-3 \"BEN\" . ex: name \"Netherlands\" ; } ex: code \"NLD\" . } # --- ALIGNMENT ----------------------------- # \u2022 If rdfs:label is aligned with ex:name # \u2022 AND ex:iso-3 is aligned with ex:code, # \u2022 We then get the following linkset: # ------------------------------------------- linkset: Match-Via-Intermediate { <<ex : 1 owl: sameAs ex : 6 >> ll: hasMatchingStrength 1 . <<ex : 2 owl: sameAs ex : 4 >> ll: hasMatchingStrength 1 . <<ex : 3 owl: sameAs ex : 5 >> ll: hasMatchingStrength 1 . } Example 3.2 : Generating a linkset using the Intermediate-Datatse algorithm. In this second example, it is also possible to align the source and target datasets using the the authoritative intermediate dataset as it contains information described at both, the Source and Target. dataset: Source-Dataset dataset: Intermediate-Dataset { { ex : 10 rdfs: label \"Rembrandt\" . ex : 70 ex : 20 rdfs: label \"van Gogh\" . ex: name \"Vincent Willem van Gogh\" ; ex : 30 rdfs: label \"Vermeer\" . ex: name \"Vincent van Gogh\" ; } ex: name \"van Gogh\" . ex : 80 dataset: Target-Datas ex: name \"Rembrandt\" ; { ex: name \"Rembrandt van Rijn\" . ex : 40 schema: name \"Rembrandt van Rijn\" . ex : 50 schema: name \"Vincent van Gogh\" . ex : 90 ex : 60 schema: name \"Johannes Vermeer\" . ex: name \"Johannes Vermeer\" ; } ex: name \"Vermeer\" . } # --- ALIGNMENT ------------------------------------ # \u2022 If rdfs:label is aligned with ex:name # \u2022 AND schema:name is also aligned with ex:name, # \u2022 we then get the following linkset: # -------------------------------------------------- linkset: Match-Via-Intermediate { <<ex : 10 owl: sameAs ex : 40 >> ll: hasMatchingStrength 1 . <<ex : 20 owl: sameAs ex : 50 >> ll: hasMatchingStrength 1 . <<ex : 30 owl: sameAs ex : 60 >> ll: hasMatchingStrength 1 . }","title":"Intermediate"},{"location":"04.Algorithms/#soundex","text":"Soundex is a phonetic algorithm for indexing names by sound, as pronounced in English. The goal is for homophones to be encoded to the same representation so that they can be matched despite minor differences in spelling. The algorithm mainly encodes consonants; a vowel will not be encoded unless it is the first letter. Example 4 : Generating a linkset using the Soundex algorithm The examples below shows the encoding of different names. Here, the size parameter indicates a degree of similarity through the length of the respective soundex codes. For example at size=3, Albert and Albertine have the same soundex representation while at size=5 their respective representations differ. In the Lenticular lens, the default size is set to 3. # ----------------------------- # INPUT SIZE 3 SIZE 5 # ----------------------------- # A. A000 A00000 # AL A400 A40000 # ALI A400 A40000 # ALBERT A416 A41630 # ALBERTINE A416 A41635 ex : 128.45 rdfs: label \"ALBERT\" ; \u2022\u2022\u2022 ex : 6852 : 28 rdfs: label \"ALBERTINE\" ; \u2022\u2022\u2022 ex: ExactLinkset { <<ex : 128.45 owl: sameAs ex : 6852 : 28 >> ll: hasMatchingStrength 1 . }","title":"Soundex"},{"location":"04.Algorithms/#metaphone","text":"TODO Example 5 :","title":"Metaphone"},{"location":"04.Algorithms/#double-metaphone","text":"TODO Example 6 :","title":"Double Metaphone"},{"location":"04.Algorithms/#nyiis","text":"TODO Example 7 :","title":"NYIIS"},{"location":"04.Algorithms/#numbers","text":"The method is used to align the source and the target IRIs whenever the delta difference between values (number/date) of the user selected properties is within a preset delta-threshold. Example 8 For example, if two entities have been aligned based on the similarity of their names but an extra check is to be investigated based on their respective year of birth, setting the delta-threshold to 1 year will ensure that the birth dates assigned to the two entities are no more than one year apart.","title":"Numbers"},{"location":"04.Algorithms/#time-delta","text":"This function allows for finding co-referent entities on the basis of a minimum time difference between the times reported by the source and the target entities. For example, if the value zero is assigned to the time difference parameter, then, for a matched to be found, the time of the target and the one of the source are to be the exact same times. While accounting for margins of error, one may consider a pair of entities to be co-referent if the real entities are born lambda days, months or years apart among other-things (similar name, place..). Time Delta before, After or Between. Other ways of using time delta are also possible. Because Time Delta has no direction or sign (+ or -), it is not possible to require that the time documented at the source entity occurs before or after the one reported by the target\u2019s event. With the before / After options, this is possible. Using the Between option, we make it possible for the user to define the time interval in which both the source and target reported times can be viewed as acceptable. Example 9 :","title":"Time Delta"},{"location":"04.Algorithms/#2-continuous-strength","text":"Her we present algorithms for which the resulting strength of a matched pair of resources is in the range ]0, 1] where 0 means a match could not be found while 1 means a perfect match is found.","title":"2.  Continuous Strength"},{"location":"04.Algorithms/#jaro","text":"This \u200bmethod is used to align \u200b\u200bsource a\u200bnd \u200b\u200btarget\u2019s IRIs whenever the similarity score of their respective user selected property values are \u200b\u200babove a given threshold in the range ]0, 1]\u200b. Jaro distance is a measure of similarity between two strings. The higher the Jaro distance for two strings is, the more similar the strings are. The score is normalised such that 0 equates to no similarity and 1 is an exact match. Given two strings s 1 and s 2 , Find common characters x i and y j such that x i = y j where x i and y j are not more than d characters aways from each other and the acceptable matching distance d is half the longest input string as expressed in the formula: d = m a x ( \u2223 s 1 \u2223 , \u2223 s 2 \u2223 2 d = \\dfrac{max(|s_1|, |s_2|} {2} d = 2 m a x ( \u2223 s 1 \u200b \u2223 , \u2223 s 2 \u200b \u2223 \u200b Let c be number of common characters shared by s 1 and s 2 . From the resulting common characters in s 1 and s 2 , let t be the number of transposition which is the number of characters that do not share the same position. Compute the strength using the formula: d j = { 0 if c = 0 1 3 ( c \u2223 s 1 \u2223 + c \u2223 s 2 \u2223 + c \u2212 t \u2223 s 1 \u2223 ) otherwise d_j = \\begin{cases} 0 &\\text{if } c = 0 \\\\ \\dfrac{1}{3} \\Bigg( \\dfrac{c}{|s_1|} + \\dfrac{c}{|s_2|} + \\dfrac{c - t}{|s_1|} \\Bigg) &\\text{otherwise} \\end{cases} d j \u200b = \u23a9 \u23aa \u23aa \u23a8 \u23aa \u23aa \u23a7 \u200b 0 3 1 \u200b ( \u2223 s 1 \u200b \u2223 c \u200b + \u2223 s 2 \u200b \u2223 c \u200b + \u2223 s 1 \u200b \u2223 c \u2212 t \u200b ) \u200b if c = 0 otherwise \u200b Example 10: Jaro results SOURCE : |s| = |source| = 6 TARGET : |t| = |target| = 6 MATCHING DISTANCE : d = max(6, 6) = 3 COMMON CHARACTERS : m = |re| = |re| = 2 TRANSPOSITIONS : t = 0 STRENGTH : s = 1/3 * ( 2/6 + 2/6 + (2 - 0/2)/2) = 0.55556 SOURCE : |s| = |jono| = 4 TARGET : |t| = |ojhono| = 6 MATCHING DISTANCE : d = max(4, 6) = 3 COMMON CHARACTERS : m = |jono| = |ojon| = 4 TRANSPOSITIONS : t = 4 STRENGTH : s = 1/3 * ( 4/4 + 4/6 + (4 - 4/2)/4) = 0.72222 SOURCE : |s| = |DUANE| = 5 TARGET : |t| = |DWAYNE| = 6 MATCHING DISTANCE : d = max(5, 6) = 3 COMMON CHARACTERS : m = |DANE| = |DANE| = 4 TRANSPOSITIONS : t = 0 STRENGTH : s = 1/3 * ( 4/5 + 4/6 + (4 - 0/2)/4) = 0.82222 SOURCE : |s| = |DIXON| = 5 TARGET : |t| = |DICKSONX| = 8 MATCHING DISTANCE : d = max(5, 8) = 4 COMMON CHARACTERS : m = |DION| = |DION| = 4 TRANSPOSITIONS : t = 0 STRENGTH : s = 1/3 * ( 4/5 + 4/8 + (4 - 0/2)/4) = 0.76667 SOURCE : |s| = |JELLYFISH| = 9 TARGET : |t| = |SMELLYFISH| = 10 MATCHING DISTANCE : d = max(9, 10) = 5 COMMON CHARACTERS : m = |ELLYFISH| = |ELLYFISH| = 8 TRANSPOSITIONS : t = 0 STRENGTH : s = 1/3 * ( 8/9 + 8/10 + (8 - 0/2)/8) = 0.8963","title":"Jaro"},{"location":"04.Algorithms/#jaro-winkler","text":"Given two strings s 1 and s 2 , the Winkler similarity equation boosts up the Jaro algorithm\u2019s result d j by increasing it whenever the compared strings share a prefix of a maximum of four characters. In this shared prefix scenario, the boost is computed as: w b = P l \u2217 P w ( 1 \u2212 d j ) w_b = P_l * P_w ( 1 - d_j ) w b \u200b = P l \u200b \u2217 P w \u200b ( 1 \u2212 d j \u200b ) where P l is the length of the set of shared prefix and P w is a user dependent scaling factor for how much the score is adjusted upwards for having common prefixes. Because four is the maximum number of shared prefix to consider, the user\u2019s choice of P w lies between 0 and \u00bc. Setting P w to \u00bc implies a similarity of always 1 whenever the strings share the maximum of 4 prefixes, no matter the real dissimilarity between the strings. The Jaro-Winkler is computed as: d j w = d j + w b d_{jw}= d_j+ w_b d j w \u200b = d j \u200b + w b \u200b Example 11: Jaro vs Jaro-Winkler jaro ( \"alexander\" , \"alexandrine\" ) = 0.90236 jaro_winkler ( \"alexander\" , \"alexandrine\" , weight = 0.1 ) = 0.94141","title":"Jaro-Winkler"},{"location":"04.Algorithms/#levenshtein","text":"This \u200bmethod is used to align \u200b\u200bsource a\u200bnd \u200b\u200btarget\u2019s IRIs whenever the similarity score of their respective user selected property values are \u200b\u200babove a given \u200bLevenshtein Distance threshold\u200b. Levenshtein (a.k.a. Edit Distance) is a way of quantifying how \u200bdissimilar two strings (e.g., words) are to one another by counting the minimum number of operations \u200b\u03b5 \u200b (\u200bremoval, insertion, or substitution of a character in the string)\u200b required to transform one string into the other. For example, \u200bthe \u200bLevenshtein distance between \u201ckitten\u201d and \u201csitting\u201d is \u200b\u03b5 \u200b= 3 as it requires two substitutions (\u201cs\u201d for \u201ck\u201d and \u201ci\u201d for \u201ce\u201d) and one insertion of \u201cg\u201d at the end. Normalisation \u200b\u03a9\u200b: In the Lenticular Lens , the \u200bsimilarity score \u200b\u03a9 \u200bof a matching pair of resources is quantified in the interval \u200b[0, 1]\u200b. For this, the\u200b dissimilarity score \u200b\u03b5 expressing the \u200bminimum number of operations to perform for \u200btwo strings to be the same \u200bis normalised as \u200b\u03a9 based on the length of the longest string. The \u200bdissimilarity score\u200b\u200b \u03b5\u200b = 3 \u200bbetween \u200b\u201dkitten\u201d and \u201csitting\u201d is then normalised to a \u200bsimilarity score \u03a9\u200b \u200b=\u200b \u200b1 - 3 / 7 = 0.57\u200b.\u200b Minimum threshold \u200b\u03c6: Using this algorithm, \u200ba \u200bminimum threshold value\u03c6\u200b \u200bmust be set in the interval \u200b[0,1], \u200bsuch that finding any matched pairs of IRIs based on the similarity of their respective property values depends on whether or not the computed \u200b\u03a9 is \u200bequal or above \u200b\u03c6\u200b. A threshold \u200b\u03c6 = 1 equates an exact match. In our previous example, if a \u200bminimum threshold of \u200b\u03c6 = \u200b0.7 is set, \u201ckitten\u201d and \u201csitting\u201d will not be matched. \u200bIn short, \u200b\u03c6 is the user defined threshold when the similarity score \u200b\u03a9 is selected for accepting or rejecting a match. Maximum character error threshold \u200b\ud835\udeff:\u200b In case the \u200boriginal edit distance score \u200b\u03b5 (minimum number of operations score) is preferred, the number of character errors \u200b\ud835\udeff \u200bof choice is used instead as threshold for deciding whether a match is accepted or rejected. However, for consistency purposes, the corresponding normalisation value \u200b\u03a9 is still computed for the minimum number of operations score computed \u200b\u03b5\u200b. For instance, in our previous example, if a \u200bmaximum \u200bcharacters errors i\u200bs set to \u200b\ud835\udeff = 3, \u201ckitten\u201d and \u201csitting\u201d will be matched but the computed strength will be \u200b\u03a9 = \u200b0.57 a\u200bnd \u200bnot \u200b\u03b5 = 3 as is it only serves the purpose of decision maker. I\u200bn short, \u200b\ud835\udeff i\u200bs the user defined threshold when the dissimilarity score \u03b5\u200b \u200bis selected for accepting or rejecting a match. Example 12 : The Levenshtein options 1. l_dist(Rembrand van Rijn, Rembrandt Harmensz van Rijn) = 10 2. Normalised_l_dist \u200b(Rembrand van Rijn, Rembrandt Harmensz van Rijn) = 0.63 >>> If \u200b\u03c6 (Minimum threshold) = 0.7 >>> t\u200bhen \u200b[\u200bRembrand van Rijn] owl:sameAs [Rembrandt Harmensz van Rijn] >>> is rejected\u200b >>> because \u03a9\u200b = 0.63 < \u03c6\u200b. >>> If \u200b\u03b4 (Maximum character error threshold) = 5 >>> t\u200bhen [\u200b\u200bRembrand van Rijn] and [Rembrandt Harmensz van Rijn] is \u200brejected >>> because \u03b5 \u200b= 10 >\u200b \u200b\u03b4.","title":"Levenshtein"},{"location":"04.Algorithms/#soundex-approximation","text":"This option is performed in two phases. First, the string values of the user selected properties are normalised (converted to a soundex code). Then a user selected matcher (Levenshtein, Jaro, jaro-Winkler\u2026) is run over the normalised string (Soundex code). Example 13: Links found using soundex In the example below, given ex:E1 and ex:E2 , the matching strength using Edit Distance is 1 - \u215b = 0.875. When directly performing an Edit distance match or a Soundex, we respectively get 0.625 and 0 as strengths. # ------------------------------- # INPUT SIZE 3 SIZE 4 # ------------------------------- # Carretta C630 C6300 # Kareta K630 K6300 ex: E1 rdfs: label \"Carretta\" . ex: E2 rdfs: label \"Kareta\" . ex: ExactLinkset { << ex: E1 skos: closeMatch <ex:E2> > ll: hasMatchingStrength 0.875 . }","title":"Soundex Approximation"},{"location":"04.Algorithms/#approx-over-same-soundex","text":"In the Lenticular Lens , Soundex can also be used as a first filtering step (string normalisation). This means that first we select all pairs sharing the same Soundex code. Then, for each of these pairs an extra string sequence matching algorithm such as (Levenshtein, Jaro, Jaro-Winkler\u2026) is applied to the original pair of matched strings (not the Soundex codes) to determine the strength of the match in the interval ]0, 1]. Example 14 : Generating a linkset using the Soundex algorithm. In the table below, the normalisation of both Louijs Rocourt and Lowis Ricourt becomes L200 R263 leading to an edit distance of 0 and a relative strength of 1. However, computing the same names using directly an edit distance results in an edit distance of 3 and a relative matching strength of 0.79. The example below shows the implementation of Soundex Distance in the Lenticular Lens and how it compares with Edit Distance over the original names ( no soundex-based normalisation ). ------------------------------------------------------------------------------------------------------------------------------------------------------ Source Target E . Dist Rel . distance Source soundex Target soundex Code E . Dist Code Rel . Dist ------------------------------------------------------------------------------------------------------------------------------------------------------ Jasper Cornelisz . Lodder Jaspar Cornelisz Lodder 2 0.92 J 216 C 654 L 360 J 216 C 654 L 360 0 1.0 Barent Teunis Barent Teunisz gen . Drent 12 0.52 B 653 T 520 B 653 T 520 G 500 D 653 10 0.47 Louijs Rocourt Louys Rocourt 2 0.86 L 200 R 263 L 200 R 263 0 1.0 Louijs Rocourt Lowis Ricourt 3 0.79 L 200 R 263 L 200 R 263 0 1.0 Louys Rocourt Lowis Ricourt 3 0.77 L 200 R 263 L 200 R 263 0 1.0 Cornelis Dircksz . Clapmus Cornelis Clapmuts 10 0.6 C 654 D 620 C 415 C 654 C 415 5 0.64 Geertruydt van den Breemde Geertruijd van den Bremde 4 0.85 G 636 V 500 D 500 B 653 G 636 V 500 D 500 B 653 0 1.0","title":"Approx over Same-Soundex"},{"location":"04.Algorithms/#bloothooft","text":"This approximation method is specifically tailored for accessing the similarity between a pair of IRIs for which the user selected property values are Dutch names. The algorithm basically normalises the given names by removing or replacing specific characters\u2026. The resulting normalised names are then pairwise compared using the Approximated Levenshtein Distance (see the description of Approximated Levenshtein Distance). Example 15 :","title":"Bloothooft"},{"location":"04.Algorithms/#word-intersection","text":"This approximation method is originally designed to find a subset of words within a larger text. However, it could also be used for any pair of strings regardless of the strings sizes. Several options are available: Whether or not the order in which the words are found is important. Whether or not the computed strength of each word should be approximated or identical. Whether or not abbreviation should be detected. Whether the default stopping character should be used, not used or modified. A threshold on the number of words not approximated/identical. An overall threshold for accepting or rejecting a match. Example 16 : Expectation For example, it can be used for aligning - [Rembrand van Rijn] and [van Rijn Rembrandt] - [Herdoopers anslagh op Amsterdam] and [Herdoopers anslagh op Amsterdam. Den x. may: 1535. Treur-spel.] regardless of the words\u2019 order. Example 1 With argument APPROX set to True, similarity can be found between Rembrand and Rembrandt (MODE-1). However, this is not possible in the inverse scenario (MODE-2). Furthermore, when the order is of no importance (MODE-1) the sequence in which the intersection of words appears is of no importance. SMALL : Rembrand (van) Rijn BIG : Rembrandt Harmensz. van Rijn MODE-1 : APPROX = True and ORDER = False FOUND : ['rijn', 'rembrandt'] STRENGTH : 0.97059 MODE-2 : APPROX = False and ORDER = True and FOUND : [] STRENGTH : 0.0 Example 2 Because the match is performed over exact occurrences (APPROX = False) and the sequence in which the matched words appear in the text is of importance (ORDER = True), elvervelt is the only intersection found in MODE-2 and thereby bringing the similarity strength to 0.333. SMALL : Elvervelt, Henrik van BIG : Henrik van Elvervelt MODE-1 : APPROX = True and ORDER = False FOUND : ['elvervelt', 'henrik', 'van'] STRENGTH : 1.0 MODE-2 : APPROX = False and ORDER = True and FOUND : ['elvervelt'] STRENGTH : 0.333 Example 3 In here all intersected words appear in the same sequence and without mismatch. SMALL : Herdoopers anslagh op Amsterdam BIG : Herdoopers anslagh op Amsterdam. Den x. may: 1535. Treur-spel. MODE-1 : APPROX = True and ORDER = False FOUND : ['herdoopers', 'anslagh', 'op', 'amsterdam'] STRENGTH : 1.0 MODE-2 : APPROX = False and ORDER = True and FOUND : ['herdoopers', 'anslagh', 'op', 'amsterdam'] STRENGTH : 1.0","title":"Word Intersection"},{"location":"04.Algorithms/#list-intersection","text":"This method is better suited for matching events. It helps establishing a relationship between the source and target entities whenever a list of entities from the source dataset intersects another list of entities stemmed from the target dataset. For illustration, suppose that we have the two events in Example-17. (1) Event one, defined by the source event-entities, documents event-entities that lists entities representing persons about to get married. This event is the Intended-Marriage event. (2) Event two is the Marriage event. It lists (i) entities representing persons that got married and (ii) the guests who attended the event. Now that the two events are defined, let us imagine that we would like to find out which of the Intended-Marriage couple fulfilled its will to get married. For this to be true, we assume that a couple with the wish to be wed should end-up being present at a Marriage event, hopefully their own marriage. This means that, for a match to occur, a minimum of two elements from a list from the source must also belong to a list from the target. In other words, a match is to be generated whenever 100% (all) of the elements in a source\u2019s lists intersects a target\u2019s list. In this method, two thresholds are to be defined. The first threshold or similarity-threshold imposes a minimum accepted similarity score (generally in ]0, 1]) when elements stemmed from different lists are compared. Passing this threshold is interpreted as the occurrence of an intersection between elements of two lists. The second threshold, the intersection-threshold expressed in quantity or percentage, denotes the minimum number of intersections that must occur for a link to be created. In practice, looking at Example-17, only events ex: intended-1 and ex:married-2 are a match as the pairs ( Catharina Reminck , Catharina Remink ) and ( Mr. Jean de Melie , Jean de Melie ) are respectively similar with a score of 0.94 and 0.82. aaaa Example 17 : List Intersection A source dataset documenting events as lists of couple with the intention of getting married and a target dataset with list of people at a wedding ceremony. Each of these latter lists is expected to includes the wed couple. --------------------------------------------------------------------------------------------- Source Dataset Target Dataset --------------------------------------------------------------------------------------------- ex: intended-1 ex: ceremony-1 ex: wife \"Catharina Reminck\" ; ex: participant \"Pieter Jas\" ; ex: husband \"Mr. Jean van de Melie\" . ex: participant \"Jacob Poppen\" ; ex: participant \"Gillis Graafland\" ; ex: intended-2 ex: participant \"Jacob Fransz. de Witt\" ; ex: wife \"Eva Oostrom\" ; ex: participant \"Elisabeth van Daaken\" ; ex: husband \"Pieter de Vriest\" . ex: participant \"Catharina Berewouts\" ; ex: participant \"Aafje Hendricx\" ; ex: intended-3 ex: participant \"Anthony van Paembergh\" ; ex: wife \"Eva Oostrom ; ex:participant \" Eva van Toorn \" ; ex: husband \"Wiggert van Wesick\" . ex: participant \"Maria Bor\" . ex: married-2 ex: participant \"J. van de Melie\" , \"Bernardus van Vijven\" . \"Margrita Schrik\" , \"Johannes de Bruijn\" , \"Maria Gosina Demol\" , \"Agneta Swartepaart\" , \"Hendrik de Lange\" , \"Catharina Remink\" . With a Similarity-threshold set to 0.8 and an Intersection-threshold set to 2 or 100%, only events ex:intended-1 and ex:married-2 are a match as the pairs ( Catharina Reminck , Catharina Remink ) and ( Mr. Jean de Melie , Jean de Melie ) are respectively similar with a score of 0.94 and 0.82.","title":"List Intersection"},{"location":"04.Algorithms/#team","text":"The TeAM (Text Approximation Match) method allows for the approximation of the relevance of a document to a query. Such approximation can be done using lexical similarity (word level similarity), semantic similarity or hybrid similarities. In this method, the focus is rather on the lexical similarity. Although tailored to text, it has been adapted to also be applicable to name-based similarity. We now provide an overview of the motivation context supporting the design and implementation of the algorithm. The Amsterdam\u2019s city archives (SAA) possesses physical handwritten inventories records where a record may be for example an inventory of goods (paintings, prints, sculpture, furniture, porcelain, etc.) owned by an Amsterdamer and mentioned in a last will. Interested in documenting the ownership of paintings from the 17 th century, the Yale University Professor John Michael Montias compiled a database by transcribing 1280 physical handwritten inventories (scattered in the Netherlands) of goods. Now that a number of these physical inventories have been digitised using handwriting recognition, one of the goals of the Golden Agent project is to identify Montias\u2019 transcriptions of painting selections within the digitised inventories. This problem can be generically reformulated as, given a source-segment database (e.g. Montias DB) and a target-segment database (e.g. SAA) , find the best similar target segment for each source segment . Fig 4.9: Digitisation of inventory documents available at the Amsterdam\u2019s city archives. Check TeAM for a more detailed explanation.","title":"TeAM"},{"location":"04.Algorithms/#3-results-combination","text":"This section addresses Complex Methods as ways to combine matching methods, not to be confused with the complexity of the underlying the methods. All of the matching methods described earlier generate links with matching strength scores in the interval ]0, 1]. We saw for example that the relative strength score between \u200b Rembrand van Rijn and Rembrandt Harmensz van Rijn is 0.63 using the Levenshtein algorithm and 0.74 using Soundex. Those methods can be combined at time of creation of the linkset, using logic boxes, or afterwards, using lenses operators. When such combination happens, a decision is necessary regarding the calculation of the resulting strength score. For example, let us assume that links are created whenever a pair of datasets items (subject, object) either sounds alike or looks alike character-wise . To accomplish that, it means that two methods have to be combined, for example, Soundex and Levenshtein. Although combining the methods seems relatively easy, deciding on the matching score requires some extra thoughts. In the example above of Rembrandt, shall we consider 0.63 or 0.74? Or their product? Here we discuss the rationals used in the Lenticular lens to support such decision. The two standard logic operators traditionally used are Conjunction (AND) and Disjunction (OR) . The first takes the minimum strength and the latter takes the maximum strength. This applies for both classic values (True -1- or False -0-) and fuzzy values ( between 0 and 1 ). Since the results from matching methods are fuzzy values in the interval ]0,1], the table bellow illustrates the default behaviour of the Lenticular Lens when combining them. Example 18: Standard logic operations over conjunction (min) and disjunction (max). Source Target Levenshtein Soundex OR(max) AND(min) ------------------------------------------------------------------------------------------------------ Jasper Cornelisz. Lodder Jaspar Cornelisz Lodder 0.92 1.00 1.00 0.92 Rembrand van Rijn Rembrandt Harmensz van Rijn 0.63 0.74 0.74 0.63 Barent Teunis Barent Teunisz gen. Drent 0.52 0.47 0.52 0.47 However, more sophisticated operations can also be used, such as the T-norm binary operations as alternatives for Conjunction (AND) and the T-conorm binary operations as alternatives for Disjunction (OR) as provided in the next subsections.","title":"3. Results Combination"},{"location":"04.Algorithms/#t-norms","text":"A list of six different operations can be applied when dealing with methods combined by Conjunction . Here, we present them: Minimum t-norm \u22a4 min (a, b) = min(a, b) Product t-norm \u22a4 prod (a, b) = a . b \u0141ukasiewicz t-norm \u22a4 Luk (a, b) = max(0, a + b - 1) Drastic \u22a4 D ( a , b ) = { b if a = 1 a if b = 1 0 otherwise \u22a4_D(a, b) = \\begin{cases} b &\\text{if } a = 1 \\\\ a &\\text{if } b = 1 \\\\ 0 &\\text{otherwise} \\end{cases} \u22a4 D \u200b ( a , b ) = \u23a9 \u23aa \u23aa \u23a8 \u23aa \u23aa \u23a7 \u200b b a 0 \u200b if a = 1 if b = 1 otherwise \u200b Nilpotent minimum \u22a4 n M ( a , b ) = { m i n ( a , b ) if a + b > 1 0 otherwise \u22a4_{nM}(a, b) = \\begin{cases} min(a, b) &\\text{if } a + b > 1 \\\\ 0 &\\text{otherwise} \\end{cases} \u22a4 n M \u200b ( a , b ) = { m i n ( a , b ) 0 \u200b if a + b > 1 otherwise \u200b Hamacher product \u22a4 H 0 ( a , b ) = { 0 if a = b = 0 a b a + b \u2212 a b otherwise \u22a4_{H_0}(a, b) = \\begin{cases} 0 &\\text{if } a = b = 0 \\\\ \\dfrac{ab}{a + b - ab} &\\text{otherwise} \\end{cases} \u22a4 H 0 \u200b \u200b ( a , b ) = \u23a9 \u23aa \u23a8 \u23aa \u23a7 \u200b 0 a + b \u2212 a b a b \u200b \u200b if a = b = 0 otherwise \u200b The following table provides three case studies to illustrate the application of each of the aforementioned T-norm binary operations . They are presented in order from the less strict ( \u22a4 min ) to the most strict ( \u22a4 D ). Source, Target Levenshtein, Soundex \u22a4 min \u22a4 H 0 \u22a4 prod \u22a4 nM \u22a4 Luk \u22a4 D Src : Jasper Cornelisz. Lodder Trg : Jaspar Cornelisz Lodder 0.92, 1.00 0.920 0.920 0.920 0.920 0.920 0.920 Src : Rembrand van Rijn Trg : Rembrandt Harmensz van Rijn 0.63, 0.74 0.630 0.516 0.466 0.630 0.370 0.000 Src : Barent Teunis Trg : Barent Teunisz gen. Drent 0.52, 0.47 0.470 0.328 0.244 0.000 0.000 0.000","title":"T-norms"},{"location":"04.Algorithms/#t-conorms","text":"A list of six different operations can also be applied when dealing with methods combined by Disjunction . Here, we present them: Maximum t-conorm \u22a5 max (a, b) = max(a, b) Probabilistic sum \u22a5 sum (a, b) = a + b - a.b Bounded sum \u22a5 Luk (a, b) = min(a + b, 1) Drastic t-conorm \u22a5 D ( a , b ) = { b if a = 0 a if b = 0 1 otherwise \u22a5_D(a, b) = \\begin{cases} b &\\text{if } a = 0 \\\\ a &\\text{if } b = 0 \\\\ 1 &\\text{otherwise} \\end{cases} \u22a5 D \u200b ( a , b ) = \u23a9 \u23aa \u23aa \u23a8 \u23aa \u23aa \u23a7 \u200b b a 1 \u200b if a = 0 if b = 0 otherwise \u200b Nilpotent maximum \u22a5 n M ( a , b ) = { m a x ( a , b ) if a + b < 1 1 otherwise \u22a5_{nM}(a, b) = \\begin{cases} max(a, b) &\\text{if } a + b < 1 \\\\ 1 &\\text{otherwise} \\end{cases} \u22a5 n M \u200b ( a , b ) = { m a x ( a , b ) 1 \u200b if a + b < 1 otherwise \u200b Einstein sum \u22a5 H 2 (a, b) = a + b 1 + a b \\dfrac{a + b} {1 + ab} 1 + a b a + b \u200b Source, Target Levenshtein, Soundex \u22a4 D \u22a4 Luk \u22a4 H 2 \u22a4 sum \u22a4 nM \u22a4 max Src : Jasper Cornelisz. Lodder Trg : Jaspar Cornelisz Lodder 0.92, 1.00 1.000 1.000 1.000 1.000 1.000 1.000 Src : Rembrand van Rijn Trg : Rembrandt Harmensz van Rijn 0.63, 0.74 1.000 1.000 0.934 0.904 1.000 0.740 Src : Barent Teunis Trg : Barent Teunisz gen. Drent 0.52, 0.47 1.000 0.990 0.796 0.746 0.520 0.520","title":"T-conorms"},{"location":"04.Algorithms/#examples","text":"Suppose that, two data items E-1 and E-2 have the following information: E-1 Name : Titus Rembrandtsz. van Rijn Mather : Saskia Uylenburgh Father : Rembrand van Rijn Parent\u2019s Marriage date : 1644-06-22 E-2 Name : T. Rembrandtszoon van Rijn Mather : Saske van Uijlenburg Father : Rembrandt Harmensz van Rijn Baptism date :1641-09-22 To interpret E-1 and E-2 as representing co-referent persons, the following four tests are proposed. Test-1 OR Here, the names of E-1 and E-2 are to be compared using the Levenshtein and Soundex algorithms at a threshold of at least 0.7 . MATCHING RESULTS - Levenshtein(Titus Rembrandtsz van Rijn, T. Rembrandtszoon van Rijn) => 0.73 \u2705 - sdx_1 = Soundex(Titus Rembrandtsz van Rijn) = T320 R516 V500 R250 - sdx_2 = Soundex(T. Rembrandtszoon van Rijn) = T000 R516 V500 R250 - Levenshtein(sdx_1, sdx_2) => 0.89 \u2705 DISJUNCTIONS RESULTS - names similarity = t_conorm(0.73, 0.88, 'MAXIMUM') => 0.89 \u2705 - names similarity = t_conorm(0.73, 0.88, 'PROBABILISTIC') => 0.97 \u2705 Test-2 AND Names of the postulated mothers and fathers are to be similar at a threshold of at least 0.6 using the Levenshtein algorithm. MATCHING RESULTS - Levenshtein(Saskia Uylenburgh, Saske van Uijlenburg) => 0.65 \u2705 - Levenshtein(Rembrand van Rijn, Rembrandt Harmensz van Rijn) => 0.63 \u2705 CONJUNCTION RESULTS - Parent's names similarity = t_norm(0.65, 0.63, 'MINIMUM') => 0.63 \u2705 - Parent's names similarity = t_norm(0.65, 0.63, 'HAMACHER') => 0.47 \u274c Test-3 The period between the parent\u2019s marriage date on the one side and the child\u2019s baptism date on the other side are to be no more than 25 years apart . MATCHING RESULTS - Delta(1668-02-28, 1669-03-22, 25) => 1.00 \u2705 Test-4 AND Combining all above three tests considering a the conjunction fuzzy operator should result in a similarity score above or equal to 0.8. -------------------------------------------------------------------------------------- FINAL CONJUNCTIONS WITH A TRUTH VALUE LIST OF [0.850, 0.63, 1] -------------------------------------------------------------------------------------- - t_norm_list([0.850, 0.63, 1], 'MINIMIUM') => 0.63 \u274c - t_norm_list([0.850, 0.63, 1], 'HAMACHER') => 0.58 \u274c - t_norm_list([0.850, 0.63, 1], 'PRODUCT') => 0.56 \u274c - t_norm_list([0.850, 0.63, 1], 'NILPOTENT') => 0.63 \u274c - t_norm_list([0.850, 0.63, 1], '\u0141uk') => 0.52 \u274c - t_norm_list([0.850, 0.63, 1], 'DRASTIC') => 0.00 \u274c -------------------------------------------------------------------------------------- CONJUNCTIONS WITH A DIFFERENT LIST OF TRUTH VALUES [0.89, 0.82, 1] -------------------------------------------------------------------------------------- - t_norm_list([0.89, 0.82, 1], \"MINIMUM\") => 0.82 \u2705 - t_norm_list([0.89, 0.82, 1], \"HAMACHER\") => 0.74 \u274c - t_norm_list([0.89, 0.82, 1], \"PRODUCT\") => 0.73 \u274c - t_norm_list([0.89, 0.82, 1], \"NILPOTENYT\") => 0.82 \u2705 - t_norm_list([0.89, 0.82, 1], \"LUK\") => 0.71 \u274c - t_norm_list([0.89, 0.82, 1], \"DRASTIC\") => 0.0 \u274c -------------------------------------------------------------------------------------- EXAMPLE USING MORE THAN ONE FUZZY LOGIC OPERATOR -------------------------------------------------------------------------------------- - Ops.t_norm(Ops.t_norm(0.850, 0.63, 'HAMACHER'), 1, 'MINIMIUM') => 0.57 \u274c - Ops.t_norm(Ops.t_norm(0.850, 0.63, 'MINIMIUM'), 1, 'HAMACHER') => 0.63 \u274c Conclusion : Given the evidence provided for E-1 and E-2 and the rules described above, the interpretation resulting from the chosen fuzzy logic operations leads to the conclusion that there is no sufficient evidence to infer that the underlying data items are co-referent. This rejection is mainly due to the low similarity of the parents\u2019 names. If the resulting similarity were above 0.8, there would then be a better chance for the data items to be co-referent. Keep in mind that our conjectured rule asserts an identity relation for combination of scores only when above 0.8. A better data or more advanced algorithm could have helped.","title":"Examples"},{"location":"05.LinkConstruction/","text":"LINK CONSTRUCTION \u00b6 Linking co-referent entities across a variety of datasources is a pragmatic and fast way to seamlessly navigate across datasets without having to agree in a uniform vocabulary. This solution offered in the Semantic Web architecture appears attractive as the ultimate goal for the researcher executing this task is not the integration of data but the extraction of vital information for reaching valid conclusions about problems under scrutiny. This said, the Lenticular Lens offers means to reach that ultimate goal of the researcher while making sure that the steps taken by the researcher are documented such that other researchers can easily re-generate the data leading to specific conclusions if need be. Along the way of entity-based data integration and data extraction, the Lenticular Lens aims to document among others: The datasources to integrate; The reasons behind a specific integration; The entity types and restrictions that ensure correctness in bridging across datasources of interest; The matching methods and specifications justifying the existence of a set of links. The Lenticular Lens tool aims to provide generic methods that allows a broader audience suffering the same need for data integration. The first step in creating and documenting links using the Lenticular Lens is defining the scope in witch links are to be created and possibly validated. For that, the tool offers the RESEARCH menu followed by the SELECT and CONSTRUCT menus. We now go through each of these first three menus underlying the existence of links. 1. Scope \u00b6 The RESEARCH menu is the starting point in learning how to interact with the Lenticular Lens tool. In general, a research question somehow sets the scope in which link creations, manipulations or validation take place. This provides the first building block supporting the user with defining the context in which a particular alignment is generated. Using this menu, part of the context is made explicit by selecting the datasets and entity types necessary to continue the investigation. As an overview, the RESEARCH menu provides researchers with means to describe the research of interest in terms of: Research Question for inserting the main research question driving the integration. Hypothesis for pointing out the hypothesis in mind prior to the data extraction. Link and Citation to ensure that, if the results happen to be published, the researcher still has the facility to add a link to the publication and and a bibliographic reference for future reuse. Fig. 4.1 illustrates the different fields to be filled in by the researcher for a quick overview of what can happen in this research project and why. Once providing the information is done, the Save button at the bottom of the page can be clicked to save the provided information and exit the Lenticular Lens if the user which to continue with other tasks. Or, should the user choose to continue the alternative Save and next button can be used to save the project and move to the next window. Fig. 4.1: Describing the scope of he research question. 2. Data \u00b6 In the previous step or window, the researcher has defined the scope of the research for which data are to be extracted and analysed. In this second window labelled SELECT , the user is to describe and select the entity types involved in his research. For that, the location of the datasource needs to be provided and the datasets in which the respective entities of interest reside need to be selected. 2.1 Data Selection \u00b6 As the user activates the Saves and next button at the end of the previous page, she is presented with a new window with a single card labelled Entity-Type Selection 1 as presented in Fig. 4.2. The plus button at the right side of the picture enables the user to create new cards when needed while the arrow-head button at the left side of the card\u2019s label allows for the unveiling of the card as displayed in Fig 3. Fig. 4.2: The card view for data selection Describing the type of an entity can be done using the Description text box for each entity type. To provide the location of the data, the GraphQL Endpoint text box can be use to fill in the URL of any GraphQL end point. Once the endpoint is given and loaded, a dataset can be selected from the list of datasets available at the provided endpoint. The selection of a dataset will prompt a new dropdown text box as Entity type , providing the user with the facility to select the entity type of interest. After loading the provided URL of the default Golden Agent\u2019s endpoint, Fig. 4.3 shows the list of datasets available at that location to choose from. Fig. 4.3: List of datasets available at the default Golden Agent\u2019s GraphQL endpoint. 2.2 Data Restrictions \u00b6 If need be to filter entities based on specific conditions, this is also possible with the Filter card shown in Fig. 4.6. Fig. 4.6: The card for defining entity restrictions. Once the button is clicked, this card presents the user with a Filter-Logic box which enable the creation of a relatively complex and versatile entity restrictions. Fig. 4.7 for example show the list of available filtering options while Fig. 4.8 illustrates an example where the has minimum date and has maximum date filtering options are used to isolate entities of interest. These entities are now those between with a registration date between [1600, 1659] and having their respective literal name exempt of trailing dots (\u2026). Fig. 4.7: List of restriction options. Fig. 4.8: The card for defining entity restrictions. 2.2.1 Restriction options \u00b6 Equal to / Not Equal to. This option allows one to select entities that have the value of a certain property equal (or not) to a certain value. For example, all entities with property ex:workLocation equal (or not) to Amsterdam . Contains / Does not contain. This option is used to make sure that the property-value of the entities of interest contains or does not contain a specific sequence of characters. For example, %...% could be used for (i) excluding people whose names contain trailing dots or (ii) to select those entities to apply a particular modification onto their names, like adding the surname of the father for a baptised child whose surname is given as ... . Has property / Has no property. This option is used to select entities based on the existence (or not) of a certain property. Let assume, for example, that the user is interested in entities that are parents. This option allows one to filter all entities for which the a value exists for the property ex:parentOf for example. It also allows you to exclude all entities that are parents if the option Has no property is used instead. Has minimum / maximum value. This option allows for restricting entities to be within or outside a specified range given user\u2019s specified property-values of type number over which the restriction can be applied. To delimit both upper and lower bounds, the user can combine minimum and maximum using the logical box AND. Has minimum / maximum date. This option allows for restricting entities to be within or outside a specified range given user\u2019s specified property-values of type date over which the restriction can be applied. Within this option, a date format can be specified. The default format is YYYY-MM-DD . The values 10, 300 and 1990 for example will be considered as year while 10-1, 300-1 and 1990-1 will be considered as the first month of the respective year values. To delimit both upper and lower bounds, the user can combine minimum and maximum using the logical box AND. Has minimum / maximum appearances. This option allows for restricting entities for which a given property value occurs within a specified range . For example, to avoid excessive number of possible matches, one can delimit that only entities whose name value occur less than 5 times in the dataset will be included. To delimit both upper and lower bounds, the user can combine minimum and maximum using the logical box AND. In set. This option allows the filtering of a collection of resources of interest based on a set of resources. These set of resources is not manually provided but can be obtained through a list of existing linksets or lenses. The example below provides a detailed understanding of this filtering approach. Example 1: IN SET Two collections A and B to be matched via whatever method would create a se of links labelled linkset-AB. However, we are only interested in a subset of linkset-AB, such that it\u2019s resources (subject, object or both) are present in another given set, namely an input-linkset I. For efficiency purposes, linkset-AB does not need to be fully created to be filtered later on. This implies that the collections A and/or B need to be filtered such that A\u2019 = A \u2229 I and/or B\u2019 = B \u2229 I before executing the matching algorithm. ###################################################### # Linksets as named graphs # ###################################################### ex: input-linkset { A: Chiara owl: sameAs C: Latronico . A: Al owl: sameAs C: Al_Idrissou . A: Al owl: sameAs C: Al_Koudous . } ex: linkset-AB { A: Chiara owl: sameAs B: Chiara . A: Kerim owl: sameAs B: Kerim . } ###################################################### # In Resource Set # ###################################################### ### The set S of resources from input-linkset is: ### S = {A:Chiara, A:Al, C:Latronico, C:Al_Idrissou, C:Al_Koudous} ex: linkset-SubjectInSet { A: Chiara owl: sameAs B: Chiara . } 2.3 Data Exploration \u00b6 At this point, successfully providing the required information ( Dataset and Entity-Type ) triggers the appearance of the Explore Sample button at the right side of the card\u2019s label ( Entity-type selection 1 ) as displayed in Fig. 4.4. As illustrated in Fig. 4.5, with this button, users are now able to explore information of their choice about the entities of interest by selecting properties describing them. Keep in mind that this feature is only intended as exploration alternative to make sure of the choices (dataset, entity-type and restrictions) made. Fig. 4.4: The Explore sample button shows only after the entity type is selected. Fig. 4.5: Exploring the description of entities of choice, stemmed from the dataset of interest. 3. Matching in Practice \u00b6 Now that we have gone through available matching methods and how to combine them in the Lenticular Lens , we show their application in some case-studies aligning resources stemmed from various datasources of one\u2019s choice. We also provide example on the rdf export of the resulting linksets with metadata. For this purpose we choose as syntax the turtle format and RDFstar reification. 3.1 Simple Methods \u00b6 This case-study section aims to showcase matching problems involving a SINGLE matching method (Embedded, Exact, Intermediate, Levenshtein Distance, Soundex Distance, Gerrit Bloothooft, Word Intersection, List Intersection, Numbers and TeAM) run over one or multiple datasets. We call them Simple Methods as opposed to Complex Methods illustrated in the sequel. Keep in mind that the terms Simple and Complex refer to the use of single or combined methods and not to the algorithm complexity of the underlying the method(s). Case-1: Grid \u00b6 In this case study, displayed in Fig 4.10, the goal is to find out whether there exist duplicates Education Instances within the Grid\u2019s dataset. The dataset is composed of nine types of institutions including 27715 Companies , 19353 Educations , 12547 Nonprofit institutes, 12465 Healthcare institutes, 8499 Facility institutes, 5762 Government institutes, 2724 Archive institutes and 7823 institutes with no type specified. Although the dataset is of multiple types of entities, the case-study here aims only to deduplicate instances of type Education . This is depicted in Fig 4.10 where the Sources and Targets cards are GRID[Education] showing that the entity type Education has been selected within the GRID dataset. Case-1: Linkset Specifications Fig 4.10: An example showing how to deduplicate a dataset using edit distance with a user-defined threshold of 0.9. Also in the Matching Methods card, it can be seen that on both sides (source and target) two properties are selected for checking whether duplicates exist. This check relies on whether there exist entities that are documented within the GRID dataset with similar names using rdfs_label and skos_prefLabel . As the similarity score is measured in the interval 0 (not similar) to 1 (exactly similar), the threshold defined as 0.9 ensures that only paired entities with a high similarity (0.9 or above) are accepted. The same card shows the selected algorithm as Levenshtein Distance , which is run over the selected predicates generating 1,692 distinct links as shown in the statistics card (on the top). The latter card also provides statistics on: The number of entities at the Source and Target . In this particular case, over 19K educational institutes at both source and target as they are the same dataset. Such information provides hints on the maximum number of links to expect in the worst case scenario as well as an idea on how long the running algorithm could take. The number of entities matched at the subject and object positions. The number of clusters derived from the links found. Here, this provides a potentially better picture on the number of real entities, as co-referent are grouped together in clusters of various sizes. The Runtime durations informing on the elapsed time for (1) finding links and for (2) clustering them. In this Image 1, we deliberately choose two properties at both the Source and Target datasets for the deduplication. Choosing for more than one property either for the Source or Target triggers a combination of pairwise property-value matching joined with the logic operator OR . For example choosing properties x and y at the source while choosing only z at the target triggers the following pairwise combinations: ( x AND z ) OR ( y AND z ). In the current use-case, choosing for example rdfs_label and skos_prefLabel at both Source AND Target generates the following combination: rdfs_label AND rdfs_label OR rdfs_label AND skos_prefLabel OR skos_prefLabel AND skos_prefLabel . This explicit combination is implemented as an alternative complex method in the next section, where three executions of the `Levenshtein Distance algorithm is required, instead of one. Case-1: RDF Results. This section provides the complete metadata of the resulting Linkset for the specification above in Example 4.15, plus a sample of 9 links due to space limitation. From this metadata, a number of general statistical information on the linkset can be obtained, such as the number of distinct triples , entities or clusters , the number of links accepted or rejected and more. The metadata also presents a detailed description on the methods used to generate the links. For example, for each algorithm used, a uri and description is provided. This algorithm can be used in one or more methods, provided the link acceptance threshold , the vrange of the similarity score, the datasets , data-types and predicates uris used for link findings. Furthermore, a specific annotation is provided in an RDFstar format for each generated link. In this example, we have the strength of the link and whether the link has been validated ( accepted , rejected or not_validated ). Case-1: Turtle file sample ### PREDEFINED SHARED NAMESPACES ### @prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> . @prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> . @prefix owl: <http://www.w3.org/2002/07/owl#> . @prefix void: <http://rdfs.org/ns/void#> . @prefix dcterms: <http://purl.org/dc/terms/> . @prefix format: <http://www.w3.org/ns/formats/> . @prefix pav: <http://purl.org/ontology/similarity/> . @prefix cc: <http://creativecommons.org/ns#> . ### PREDEFINED SPECIFIC NAMESPACES ### @prefix ll: <http://data.goldenagents.org/ontology/> . @prefix ll_algo: <http://data.goldenagents.org/ontology/matching-method/> . @prefix ll_val: <http://data.goldenagents.org/ontology/validation/> . @prefix linkset: <http://data.goldenagents.org/resource/linkset/> . @prefix dataset: <http://data.goldenagents.org/resource/dataset/> . ### AUTOMATED NAMESPACES ### @prefix skos: <http://www.w3.org/2004/02/skos/core#> . @prefix institutes_S1: <http://www.grid.ac/institutes/> . ########################################### # GENERIC METADATA # ########################################### linkset: Grid a void: Linkset ; cc: attributionName \"LenticularLens\" ; void: feature format: Turtle ; cc: license <http://purl.org/NET/rdflicense/W3C1.0> ; ll: has-logic-formulation <http://data.goldenagents.org/resource/PHbb54a8dab0d2954> ; void: linkPredicate skos: exactMatch ; void: subjectsTarget <http://data.goldenagents.org/resource/dataset/Grid> ; void: objectsTarget <http://data.goldenagents.org/resource/dataset/Grid> ; dcterms: description \"Deduplication of entities of type Education in the GRID dataset\" @ en ; void: triples 1692 ; void: entities 1737 ; void: distinctSubjects 1737 ; void: distinctObjects 1737 ; ll: has-clusters 619 ; ll_val: has-validations 18 ; ll_val: has-accepted 3 ; ll_val: has-rejected 6 ; ll_val: has-remaining 1683 . ############################################# # LOGIC FORMULA PARTS # ############################################# <http://data.goldenagents.org/resource/PHbb54a8dab0d2954> a ll: LogicFormulation ; ll: has-method <http://data.goldenagents.org/resource/Normalised-EditDistance-H30d57e26e41bb04> ; ll: has-formula-description \"\"\"<http://data.goldenagents.org/resource/Normalised-EditDistance-H30d57e26e41bb04> \"\"\" . ############################################# # METHOD SIGNATURES # ############################################# ### ll_algo:Normalised-EditDistance ### <http://data.goldenagents.org/resource/Normalised-EditDistance-H30d57e26e41bb04> a ll:MatchingMethod ; ll:has-algorithm ll_algo:Normalised-EditDistance ; ll:has-threshold 0.9 ; ll:has-threshold-range \"]0, 1]\" ; ll:has-threshold-acceptance-operator <http://data.goldenagents.org/resource/Greater-than-or-equal-to> ; ll:has-subj-entity-selection <http://data.goldenagents.org/resource/EntitySelection-PH61bd543e4ce34c2> ; ll:has-subj-predicate-selection <http://data.goldenagents.org/resource/PredicateSelection-PHab504e102405ab0> ; ll:has-subj-predicate-selection <http://data.goldenagents.org/resource/PredicateSelection-PH0d712649af643f3> ; ll:has-obj-entity-selection <http://data.goldenagents.org/resource/EntitySelection-PH61bd543e4ce34c2> ; ll:has-obj-predicate-selection <http://data.goldenagents.org/resource/PredicateSelection-PHab504e102405ab0> ; ll:has-obj-predicate-selection <http://data.goldenagents.org/resource/PredicateSelection-PH0d712649af643f3> . ############################################# # METHOD DESCRIPTIONS # ############################################# ll_algo:Normalised-EditDistance a ll:MatchingAlgorithm ; dcterms:description \"\"\" This \u200bmethod is used to align \u200b\u200bsource a\u200bnd \u200b\u200btarget\u2019s IRIs whenever the similarity score of their respective user selected property values are \u200b\u200babove a given \u200bLevenshtein (edit) Distance threshold\u200b. Edit distance is a way of quantifying how \u200bdissimilar two strings (e.g., words) are to one another by counting the minimum number of operations \u200b\u03b5 \u200b(\u200bremoval, insertion, or substitution of a character in the string)\u200b required to transform one string into the other. For example, \u200bthe \u200bLevenshtein distance between kitten and sitting is \u200b\u03b5 \u200b= 3 as it requires a two substitutions (s for k and i for e) and one insertion of g at the end [https://en.wikipedia.org/wiki/Edit_distance]\u200b. \"\"\"@en . ############################################# # DATASET AND ENTITY SELECTIONS # ############################################# ### ENTITY SELECTION [SOURCE] N0: 1 ### <http://data.goldenagents.org/resource/EntitySelection-PH61bd543e4ce34c2> a ll:EntitySelection ; ll:has-dataset <http://data.goldenagents.org/resource/dataset/Grid> ; ll:has-entity-type <http://www.grid.ac/ontology/Education> . ############################################# # PREDICATE SELECTIONS # ############################################# ### PREDICATE SELECTED [SOURCE] N0: 1 ### <http://data.goldenagents.org/resource/PredicateSelection-PHab504e102405ab0> a ll:PropertySelection ; ll:has-entity-selection <http://data.goldenagents.org/resource/EntitySelection-PH61bd543e4ce34c2> ; ll:has-predicate <http://www.w3.org/2000/01/rdf-schema#label> . ### PREDICATE SELECTED [SOURCE] N0: 2 ### <http://data.goldenagents.org/resource/PredicateSelection-PH0d712649af643f3> a ll:PropertySelection ; ll:has-entity-selection <http://data.goldenagents.org/resource/EntitySelection-PH61bd543e4ce34c2> ; ll:has-predicate <http://www.w3.org/2004/02/skos/core#prefLabel> . ########################################### # ANNOTATED LINKSET # ########################################### linkset:Grid { <<institutes_S1:grid.1017.7 skos:exactMatch institutes_S1:grid.501980.5>> ll_val:has-validation \"rejected\" : ll:has-matching-strength 0.933 . <<institutes_S1:grid.1019.9 skos:exactMatch institutes_S1:grid.449929.b>> ll_val:has-validation \"accepted\" ; ll:has-matching-strength 1 . <<institutes_S1:grid.1020.3 skos:exactMatch institutes_S1:grid.266826.e>> ll_val:has-validation \"not_validated\" ; ll:has-matching-strength 1 . <<institutes_S1:grid.10215.37 skos:exactMatch institutes_S1:grid.10347.31>> ll_val:has-validation \"rejected\" ; ll:has-matching-strength 0.950 . <<institutes_S1:grid.10215.37 skos:exactMatch institutes_S1:grid.10595.38>> ll_val:has-validation \"rejected\" ; ll:has-matching-strength 0.900 . <<institutes_S1:grid.10215.37 skos:exactMatch institutes_S1:grid.4462.4>> ll_val:has-validation \"rejected\" ; ll:has-matching-strength 0.900 . <<institutes_S1:grid.10347.31 skos:exactMatch institutes_S1:grid.10595.38>> ll_val:has-validation \"rejected\" ; ll:has-matching-strength 0.900 . <<institutes_S1:grid.10347.31 skos:exactMatch institutes_S1:grid.441173.4>> ll_val:has-validation \"rejected\" ; ll:has-matching-strength 0.900 . <<institutes_S1:grid.10347.31 skos:exactMatch institutes_S1:grid.4462.4>> lll_val:has-validation \"accepted\" ; ll:has-matching-strength 0.900 . \u2022 \u2022 \u2022 } 3.2 Complex Methods \u00b6 Case-1: Alternative \u00b6 In Fig 4.11 is displayed an alternative where Case-1: Linkset Specifications Fig 4.11: An example showing how to deduplicate a dataset using an edit distance with threshold 0.9. Case-1: RDF Results Case-1: Turtle file sample ########################################### # NAMESPACES # ########################################### ### PREDEFINED SHARED NAMESPACES @prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> . @prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> . @prefix owl: <http://www.w3.org/2002/07/owl#> . @prefix void: <http://rdfs.org/ns/void#> . @prefix dcterms: <http://purl.org/dc/terms/> . @prefix format: <http://www.w3.org/ns/formats/> . @prefix pav: <http://purl.org/ontology/similarity/> . @prefix cc: <http://creativecommons.org/ns#> . ### PREDEFINED SPECIFIC NAMESPACES @prefix ll: <http://data.goldenagents.org/ontology/> . @prefix ll_algo: <http://data.goldenagents.org/ontology/matching-method/> . @prefix ll_val: <http://data.goldenagents.org/ontology/validation/> . @prefix linkset: <http://data.goldenagents.org/resource/linkset/> . @prefix dataset: <http://data.goldenagents.org/resource/dataset/> . ### AUTOMATED NAMESPACES @prefix skos: <http://www.w3.org/2004/02/skos/core#> . @prefix institutes_S1: <http://www.grid.ac/institutes/> . ############################################################################################################## # GENERIC METADATA # ############################################################################################################## linkset: Grid_2 a void: Linkset ; cc: attributionName \"LenticularLens\" ; void: feature format: Turtle ; cc: license <http://purl.org/NET/rdflicense/W3C1.0> ; ll: has-logic-formulation <http://data.goldenagents.org/resource/PH1ec0ee6f368dd62> ; void: linkPredicate skos: exactMatch ; void: subjectsTarget <http://data.goldenagents.org/resource/dataset/Grid> ; void: objectsTarget <http://data.goldenagents.org/resource/dataset/Grid> ; dcterms: description \"Deduplication of entities of type Education in the GRID dataset\" @ en ; void: triples 1692 ; void: entities 1737 ; void: distinctSubjects 1737 ; void: distinctObjects 1737 ; ll: has-clusters 619 ; ll_val: has-validations 18 ; ll_val: has-accepted 3 ; ll_val: has-rejected 6 ; ll_val: has-remaining 1683 . ################################################################################ # LOGIC FORMULA PARTS # ################################################################################ <http://data.goldenagents.org/resource/PH1ec0ee6f368dd62> a ll: LogicFormulation ; ll: has-method <http://data.goldenagents.org/resource/Normalised-EditDistance-H779a0ad1b5e5f93> ; ll: has-method <http://data.goldenagents.org/resource/Normalised-EditDistance-H3de4966a0b8aa01> ; ll: has-method <http://data.goldenagents.org/resource/Normalised-EditDistance-H11cbb0cc77c44a9> ; ll: has-formula-description \"\"\"<http://data.goldenagents.org/resource/Normalised-EditDistance-H779a0ad1b5e5f93> and (\u22a4min) <http://data.goldenagents.org/resource/Normalised-EditDistance-H3de4966a0b8aa01> and (\u22a4min) <http://data.goldenagents.org/resource/Normalised-EditDistance-H11cbb0cc77c44a9> \"\"\" . ################################################################################ # METHOD SIGNATURES # ################################################################################ ### ll_algo:Normalised-EditDistance <http://data.goldenagents.org/resource/Normalised-EditDistance-H779a0ad1b5e5f93> a ll:MatchingMethod ; ll:has-algorithm ll_algo:Normalised-EditDistance ; ll:has-threshold 0.9 ; ll:has-threshold-range \"]0, 1]\" ; ll:has-threshold-acceptance-operator <http://data.goldenagents.org/resource/Greater-than-or-equal-to> ; ll:has-subj-entity-selection <http://data.goldenagents.org/resource/EntitySelection-PH61bd543e4ce34c2> ; ll:has-subj-predicate-selection <http://data.goldenagents.org/resource/PredicateSelection-PHab504e102405ab0> ; ll:has-obj-entity-selection <http://data.goldenagents.org/resource/EntitySelection-PH61bd543e4ce34c2> ; ll:has-obj-predicate-selection <http://data.goldenagents.org/resource/PredicateSelection-PHab504e102405ab0> . ### ll_algo:Normalised-EditDistance <http://data.goldenagents.org/resource/Normalised-EditDistance-H3de4966a0b8aa01> a ll:MatchingMethod ; ll:has-algorithm ll_algo:Normalised-EditDistance ; ll:has-threshold 0.9 ; ll:has-threshold-range \"]0, 1]\" ; ll:has-threshold-acceptance-operator <http://data.goldenagents.org/resource/Greater-than-or-equal-to> ; ll:has-subj-entity-selection <http://data.goldenagents.org/resource/EntitySelection-PH61bd543e4ce34c2> ; ll:has-subj-predicate-selection <http://data.goldenagents.org/resource/PredicateSelection-PHab504e102405ab0> ; ll:has-obj-entity-selection <http://data.goldenagents.org/resource/EntitySelection-PH61bd543e4ce34c2> ; ll:has-obj-predicate-selection <http://data.goldenagents.org/resource/PredicateSelection-PH0d712649af643f3> . ### ll_algo:Normalised-EditDistance <http://data.goldenagents.org/resource/Normalised-EditDistance-H11cbb0cc77c44a9> a ll:MatchingMethod ; ll:has-algorithm ll_algo:Normalised-EditDistance ; ll:has-threshold 0.9 ; ll:has-threshold-range \"]0, 1]\" ; ll:has-threshold-acceptance-operator <http://data.goldenagents.org/resource/Greater-than-or-equal-to> ; ll:has-subj-entity-selection <http://data.goldenagents.org/resource/EntitySelection-PH61bd543e4ce34c2> ; ll:has-subj-predicate-selection <http://data.goldenagents.org/resource/PredicateSelection-PH0d712649af643f3> ; ll:has-obj-entity-selection <http://data.goldenagents.org/resource/EntitySelection-PH61bd543e4ce34c2> ; ll:has-obj-predicate-selection <http://data.goldenagents.org/resource/PredicateSelection-PH0d712649af643f3> . ################################################################################ # METHOD DESCRIPTIONS # ################################################################################ ll_algo:Normalised-EditDistance a ll:MatchingAlgorithm ; dcterms:description \"\"\" This \u200bmethod is used to align \u200b\u200bsource a\u200bnd \u200b\u200btarget\u2019s IRIs whenever the similarity score of their respective user selected property values are \u200b\u200babove a given \u200bLevenshtein (edit) Distance threshold\u200b. Edit distance is a way of quantifying how \u200bdissimilar two strings (e.g., words) are to one another by counting the minimum number of operations \u200b\u03b5 \u200b(\u200bremoval, insertion, or substitution of a character in the string)\u200b required to transform one string into the other. For example, \u200bthe \u200bLevenshtein distance between kitten and sitting is \u200b\u03b5 \u200b= 3 as it requires a two substitutions (s for k and i for e) and one insertion of g at the end [https://en.wikipedia.org/wiki/Edit_distance]\u200b. \"\"\"@en . ################################################################################ # DATASET AND ENTITY SELECTIONS # ################################################################################ ### ENTITY SELECTION [SOURCE] N0: 1 ### <http://data.goldenagents.org/resource/EntitySelection-PH61bd543e4ce34c2> a ll:EntitySelection ; ll:has-dataset <http://data.goldenagents.org/resource/dataset/Grid> ; ll:has-entity-type <http://www.grid.ac/ontology/Education> . ################################################################################ # PREDICATE SELECTIONS # ################################################################################ ### PREDICATE SELECTED [SOURCE] N0: 1 ### <http://data.goldenagents.org/resource/PredicateSelection-PHab504e102405ab0> a ll:PropertySelection ; ll:has-entity-selection <http://data.goldenagents.org/resource/EntitySelection-PH61bd543e4ce34c2> ; ll:has-predicate <http://www.w3.org/2000/01/rdf-schema#label> . ### PREDICATE SELECTED [TARGET] N0: 2 ### <http://data.goldenagents.org/resource/PredicateSelection-PH0d712649af643f3> a ll:PropertySelection ; ll:has-entity-selection <http://data.goldenagents.org/resource/EntitySelection-PH61bd543e4ce34c2> ; ll:has-predicate <http://www.w3.org/2004/02/skos/core#prefLabel> . ############################################################################################################## # ANNOTATED LINKSET # ############################################################################################################## linkset:Grid_2 { <<institutes_S1:grid.1017.7 skos:exactMatch institutes_S1:grid.501980.5>> ll_val:has-validation \"rejected\" . <<institutes_S1:grid.1019.9 skos:exactMatch institutes_S1:grid.449929.b>> ll_val:has-validation \"accepted\" . <<institutes_S1:grid.1020.3 skos:exactMatch institutes_S1:grid.266826.e>> ll_val:has-validation \"accepted\" . <<institutes_S1:grid.10215.37 skos:exactMatch institutes_S1:grid.10347.31>> ll_val:has-validation \"rejected\" . <<institutes_S1:grid.10215.37 skos:exactMatch institutes_S1:grid.10595.38>> ll_val:has-validation \"rejected\" . <<institutes_S1:grid.10215.37 skos:exactMatch institutes_S1:grid.4462.4>> ll_val:has-validation \"rejected\" . <<institutes_S1:grid.10347.31 skos:exactMatch institutes_S1:grid.10595.38>> ll_val:has-validation \"rejected\" . <<institutes_S1:grid.10347.31 skos:exactMatch institutes_S1:grid.441173.4>> ll_val:has-validation \"rejected\" . <<institutes_S1:grid.10347.31 skos:exactMatch institutes_S1:grid.4462.4>> ll_val:has-validation \"accepted\" . <<institutes_S1:grid.10373.36 skos:exactMatch institutes_S1:grid.266769.a>> ll_val:has-validation \"not_validated\" . \u2022 \u2022 \u2022 } Case-2: Getty \u00b6 In Fig 4.12 is displayed an alternative where Case-2: Linkset Specifications. Fig 4.12: An example showing how to deduplicate a dataset using an edit distance with threshold 0.9. Case-2: RDF Results. Case-2: Turtle file sample. NAMESPACES \u00b6 PREDEFINED SHARED NAMESPACES \u00b6 @prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> . @prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> . @prefix owl: <http://www.w3.org/2002/07/owl#> . @prefix void: <http://rdfs.org/ns/void#> . @prefix dcterms: <http://purl.org/dc/terms/> . @prefix format: <http://www.w3.org/ns/formats/> . @prefix pav: <http://purl.org/ontology/similarity/> . @prefix cc: <http://creativecommons.org/ns#> . PREDEFINED SPECIFIC NAMESPACES \u00b6 @prefix ll: <http://data.goldenagents.org/ontology/> . @prefix ll_algo: <http://data.goldenagents.org/ontology/matching-method/> . @prefix ll_val: <http://data.goldenagents.org/ontology/validation/> . @prefix linkset: <http://data.goldenagents.org/resource/linkset/> . @prefix dataset: <http://data.goldenagents.org/resource/dataset/> . AUTOMATED NAMESPACES \u00b6 @prefix skos: <http://www.w3.org/2004/02/skos/core#> . @prefix institutes_S1: <http://www.grid.ac/institutes/> . @prefix time: <http://www.w3.org/2006/time#> . @prefix owl: <http://www.w3.org/2002/07/owl#> . @prefix Person_S1: <http://goldenagents.org/uva/SAA/Person/> . @prefix PersonName_T1: <https://data.goldenagents.org/datasets/SAA/PersonName/> . GENERIC METADATA \u00b6 linkset:Getty a void:Linkset ; cc:attributionName \"LenticularLens\" ; void:feature format:Turtle ; cc:license <http://purl.org/NET/rdflicense/W3C1.0> ; ll:has-logic-formulation <http://data.goldenagents.org/resource/PH6d47b550d1695d5> ; void:linkPredicate owl:sameAs ; void:subjectsTarget <https://data.goldenagents.org/datasets/ufab7d657a250e3461361c982ce9b38f3816e0c4b/frick_collection_montias_data_20200604> ; void:subjectsTarget <https://data.goldenagents.org/datasets/ufab7d657a250e3461361c982ce9b38f3816e0c4b/getty_provenance_index_montias_data_20200604> ; void:objectsTarget <https://data.goldenagents.org/datasets/ufab7d657a250e3461361c982ce9b38f3816e0c4b/index_op_notarieel_archief_enriched_20191202> ; dcterms:description \"Deduplication of entities of type Education in the GRID dataset\"@en ; void:triples 147 ; void:entities 261 ; void:distinctSubjects 135 ; void:distinctObjects 126 ; ll:has-clusters 117 ; ll_val:has-remaining 147 . ################################################################################ # LOGIC FORMULA PARTS # ################################################################################ http://data.goldenagents.org/resource/PH6d47b550d1695d5 a ll:LogicFormulation ; ll:has-method <http://data.goldenagents.org/resource/Normalised-Soundex-H4970fc2fe79ea5f> ; ll:has-method <http://data.goldenagents.org/resource/Exact-H918a02351d48ca9> ; ll:has-method <http://data.goldenagents.org/resource/Time-Delta-Hdcc5070996853e9> ; ll:has-formula-description \"\"\"<http://data.goldenagents.org/resource/Normalised-Soundex-H4970fc2fe79ea5f> and (\u22a4min) <http://data.goldenagents.org/resource/Exact-H918a02351d48ca9> and (\u22a4min) <http://data.goldenagents.org/resource/Time-Delta-Hdcc5070996853e9> \"\"\" . ################################################################################ # METHOD SIGNATURES # ################################################################################ ll_algo:Normalised-Soundex \u00b6 http://data.goldenagents.org/resource/Normalised-Soundex-H4970fc2fe79ea5f a ll:MatchingMethod ; ll:has-algorithm ll_algo:Normalised-Soundex ; ll:has-threshold 0.85 ; ll:has-threshold-range \"]0, 1]\" ; ll:has-threshold-acceptance-operator <http://data.goldenagents.org/resource/Greater-than-or-equal-to> ; ll:has-subj-entity-selection <http://data.goldenagents.org/resource/EntitySelection-PH4ba00e26b03e5dc> ; ll:has-subj-entity-selection <http://data.goldenagents.org/resource/EntitySelection-PHb97c2bc9d29ba36> ; ll:has-subj-predicate-selection <http://data.goldenagents.org/resource/PredicateSelection-PH914a94c6f3c93b4> ; ll:has-subj-predicate-selection <http://data.goldenagents.org/resource/PredicateSelection-PH10aaeebb6832fdf> ; ll:has-obj-entity-selection <http://data.goldenagents.org/resource/EntitySelection-PH769c39438419b10> ; ll:has-obj-predicate-selection <http://data.goldenagents.org/resource/PredicateSelection-PH7879419327d373d> . ll_algo:Exact \u00b6 http://data.goldenagents.org/resource/Exact-H918a02351d48ca9 a ll:MatchingMethod ; ll:has-algorithm ll_algo:Exact ; ll:has-threshold 1 ; ll:has-threshold-range \"1\" ; ll:has-threshold-acceptance-operator <http://data.goldenagents.org/resource/Equal> ; ll:has-subj-entity-selection <http://data.goldenagents.org/resource/EntitySelection-PHb97c2bc9d29ba36> ; ll:has-subj-entity-selection <http://data.goldenagents.org/resource/EntitySelection-PH4ba00e26b03e5dc> ; ll:has-subj-predicate-selection <http://data.goldenagents.org/resource/PredicateSelection-PH46d91d4f6e2209e> ; ll:has-subj-predicate-selection <http://data.goldenagents.org/resource/PredicateSelection-PH0df0471cb5df515> ; ll:has-obj-entity-selection <http://data.goldenagents.org/resource/EntitySelection-PH769c39438419b10> ; ll:has-obj-predicate-selection <http://data.goldenagents.org/resource/PredicateSelection-PHe3cb3236c5b11b1> ; ll:has-obj-predicate-selection <http://data.goldenagents.org/resource/PredicateSelection-PHb2a681013fbb430> ; ll:has-obj-predicate-selection <http://data.goldenagents.org/resource/PredicateSelection-PH9f7bd41ea902bd0> . ll_algo:Time-Delta \u00b6 http://data.goldenagents.org/resource/Time-Delta-Hdcc5070996853e9 a ll:MatchingMethod ; ll:has-algorithm ll_algo:Time-Delta ; ll:has-threshold 0 ; ll:has-threshold-range \"\u2115\" ; time:unitType time:unitYear ; ll:has-threshold-acceptance-operator <http://data.goldenagents.org/resource/Equal> ; ll:has-subj-entity-selection <http://data.goldenagents.org/resource/EntitySelection-PHb97c2bc9d29ba36> ; ll:has-subj-entity-selection <http://data.goldenagents.org/resource/EntitySelection-PH4ba00e26b03e5dc> ; ll:has-subj-predicate-selection <http://data.goldenagents.org/resource/PredicateSelection-PHeb98e7f77b22fce> ; ll:has-subj-predicate-selection <http://data.goldenagents.org/resource/PredicateSelection-PHf741a098569afb1> ; ll:has-obj-entity-selection <http://data.goldenagents.org/resource/EntitySelection-PH769c39438419b10> ; ll:has-obj-predicate-selection <http://data.goldenagents.org/resource/PredicateSelection-PHee886bb3d021a6a> ; ll:has-obj-predicate-selection <http://data.goldenagents.org/resource/PredicateSelection-PH715d032180bd40c> ; ll:has-obj-predicate-selection <http://data.goldenagents.org/resource/PredicateSelection-PHe349eb18e5ba638> . ################################################################################ # METHOD DESCRIPTIONS # ################################################################################ ll_algo:Normalised-Soundex a ll:MatchingAlgorithm ; dcterms:description \u201c\u201d\u201d \u201cSoundex is a phonetic algorithm for indexing names by sound, as pronounced in English. The goal is for ho- mophones to be encoded to the same representation so that they can be matched despite minor differences in spelling. The algorithm mainly encodes consonants; a vowel will not be encoded unless it is the first let- ter\u201d [ https://en.wikipedia.org/wiki/Soundex ]. In the Lenticular Lens, Soundex is used as a normaliser in the sense that an edit distance is run over the soundex code version of a name. For example, the in the table below, the normalisation of both Louijs Roc- ourt and `Lowis Ricourt becomes L200 R263 leading to an edit distance of 0 and a relative strength of 1. However, computing the same names using directly an edit distance results in an edit distance of 3 and a relative matching strength of 0. 79. -------------- -- Example -- THE USE OF SOUNDEX CODE FOR STRING APPROXIMATION -------------- The example below shows the implementation of Soundex Distance in the Lenticular Lens and how it compares with Edit Distance over the original names (no soundex-based normalisation). ------------------------------------------------------------------------------------------------------------------------------------------------------ Source Target E. Dist Rel. distance Source soundex Target soundex Code E. Dist Code Rel. Dist ------------------------------------------------------------------------------------------------------------------------------------------------------ Jasper Cornelisz. Lodder Jaspar Cornelisz Lodder 2 0.92 J216 C654 L360 J216 C654 L360 0 1.0 Barent Teunis Barent Teunisz gen. Drent 12 0.52 B653 T520 B653 T520 G500 D653 10 0.47 Louijs Rocourt Louys Rocourt 2 0.86 L200 R263 L200 R263 0 1.0 Louijs Rocourt Lowis Ricourt 3 0.79 L200 R263 L200 R263 0 1.0 Louys Rocourt Lowis Ricourt 3 0.77 L200 R263 L200 R263 0 1.0 Cornelis Dircksz. Clapmus Cornelis Clapmuts 10 0.6 C654 D620 C415 C654 C415 5 0.64 Geertruydt van den Breemde Geertruijd van den Bremde 4 0.85 G636 V500 D500 B653 G636 V500 D500 B653 \"\"\"@en . ll_algo:Exact a ll:MatchingAlgorithm ; dcterms:description \u201c\u201d\u201d Aligns source and target\u2019s IRIs whenever their respective user selected property values are identical.\u201d\u201c\u201d@en . ll_algo:Time-Delta a ll:MatchingAlgorithm ; dcterms:description \u201c\u201d\u201d 10.1 Time Delta. This function allows for finding co-referent entities on the basis of a minimum time dif- ference between the times reported by the source and the target entities. For example, if the value zero is assigned to the time difference parameter, then, for a matched to be found, the time of the target and the one of the source are to be the exact same times. While accounting for margins of error, one may consider a pair of entities to be co-referent if the real entities are born lambda days, months or years apart among other-things (similar name, place..). \u201c\u201d\u201c@en . ################################################################################ # DATASET AND ENTITY SELECTIONS # ################################################################################ ENTITY SELECTION [SOURCE] N0: 1 \u00b6 http://data.goldenagents.org/resource/EntitySelection-PH4ba00e26b03e5dc a ll:EntitySelection ; ll:has-dataset https://data.goldenagents.org/datasets/ufab7d657a250e3461361c982ce9b38f3816e0c4b/frick_collection_montias_data_20200604 ; ll:has-entity-type https://data.goldenagents.org/datasets/SAA/ontology/Person . ENTITY SELECTION [SOURCE] N0: 2 \u00b6 http://data.goldenagents.org/resource/EntitySelection-PHb97c2bc9d29ba36 a ll:EntitySelection ; ll:has-dataset https://data.goldenagents.org/datasets/ufab7d657a250e3461361c982ce9b38f3816e0c4b/getty_provenance_index_montias_data_20200604 ; ll:has-entity-type https://data.goldenagents.org/datasets/SAA/ontology/Person . ENTITY SELECTION [TARGET] N0: 3 \u00b6 http://data.goldenagents.org/resource/EntitySelection-PH769c39438419b10 a ll:EntitySelection ; ll:has-dataset https://data.goldenagents.org/datasets/ufab7d657a250e3461361c982ce9b38f3816e0c4b/index_op_notarieel_archief_enriched_20191202 ; ll:has-entity-type https://w3id.org/pnv#PersonName . ################################################################################ # PREDICATE SELECTIONS # ################################################################################ PREDICATE SELECTED [SOURCE] N0: 1 \u00b6 http://data.goldenagents.org/resource/PredicateSelection-PH914a94c6f3c93b4 a ll:PropertySelection ; ll:has-entity-selection http://data.goldenagents.org/resource/EntitySelection-PH4ba00e26b03e5dc ; ll:has-predicate http://www.w3.org/2000/01/rdf-schema#label . PREDICATE SELECTED [SOURCE] N0: 2 \u00b6 http://data.goldenagents.org/resource/PredicateSelection-PH10aaeebb6832fdf a ll:PropertySelection ; ll:has-entity-selection http://data.goldenagents.org/resource/EntitySelection-PHb97c2bc9d29ba36 ; ll:has-predicate http://www.w3.org/2000/01/rdf-schema#label . PREDICATE SELECTED [TARGET] N0: 3 \u00b6 http://data.goldenagents.org/resource/PredicateSelection-PH7879419327d373d a ll:PropertySelection ; ll:has-entity-selection http://data.goldenagents.org/resource/EntitySelection-PH769c39438419b10 ; ll:has-predicate http://www.w3.org/2000/01/rdf-schema#label . PREDICATE SELECTED [SOURCE] N0: 4 \u00b6 http://data.goldenagents.org/resource/PredicateSelection-PH46d91d4f6e2209e a ll:PropertySelection ; ll:has-entity-selection http://data.goldenagents.org/resource/EntitySelection-PHb97c2bc9d29ba36 ; ll:has-predicate http://data.goldenagents.org/resource/PH1df7dbfdf1d1eb8 . http://data.goldenagents.org/resource/PH1df7dbfdf1d1eb8 a ll:SequenceSelection ; rdf:_1 https://data.goldenagents.org/datasets/SAA/ontology/isInRecord ; rdf:_2 https://data.goldenagents.org/datasets/SAA/ontology/Inventory ; rdf:_3 https://data.goldenagents.org/datasets/SAA/ontology/documentedIn ; rdf:_4 https://data.goldenagents.org/datasets/SAA/ontology/InventoryBook ; rdf:_5 https://data.goldenagents.org/datasets/SAA/ontology/inventoryNumber . PREDICATE SELECTED [SOURCE] N0: 5 \u00b6 http://data.goldenagents.org/resource/PredicateSelection-PH0df0471cb5df515 a ll:PropertySelection ; ll:has-entity-selection http://data.goldenagents.org/resource/EntitySelection-PH4ba00e26b03e5dc ; ll:has-predicate http://data.goldenagents.org/resource/PH1df7dbfdf1d1eb8 . PREDICATE SELECTED [TARGET] N0: 6 \u00b6 http://data.goldenagents.org/resource/PredicateSelection-PHe3cb3236c5b11b1 a ll:PropertySelection ; ll:has-entity-selection http://data.goldenagents.org/resource/EntitySelection-PH769c39438419b10 ; ll:has-predicate http://data.goldenagents.org/resource/PH7334cc09b832a17 . http://data.goldenagents.org/resource/PH7334cc09b832a17 a ll:SequenceSelection ; rdf:_1 https://data.goldenagents.org/datasets/SAA/ontology/isInRecord ; rdf:_2 https://data.goldenagents.org/datasets/SAA/ontology/HuwelijkseVoorwaarden ; rdf:_3 https://data.goldenagents.org/datasets/SAA/ontology/inventoryNumber . PREDICATE SELECTED [TARGET] N0: 7 \u00b6 http://data.goldenagents.org/resource/PredicateSelection-PHb2a681013fbb430 a ll:PropertySelection ; ll:has-entity-selection http://data.goldenagents.org/resource/EntitySelection-PH769c39438419b10 ; ll:has-predicate http://data.goldenagents.org/resource/PH00d91362d72928f . http://data.goldenagents.org/resource/PH00d91362d72928f a ll:SequenceSelection ; rdf:_1 https://data.goldenagents.org/datasets/SAA/ontology/isInRecord ; rdf:_2 https://data.goldenagents.org/datasets/SAA/ontology/Boedelinventaris ; rdf:_3 https://data.goldenagents.org/datasets/SAA/ontology/inventoryNumber . PREDICATE SELECTED [TARGET] N0: 8 \u00b6 http://data.goldenagents.org/resource/PredicateSelection-PH9f7bd41ea902bd0 a ll:PropertySelection ; ll:has-entity-selection http://data.goldenagents.org/resource/EntitySelection-PH769c39438419b10 ; ll:has-predicate http://data.goldenagents.org/resource/PH9f325d76d5fa623 . http://data.goldenagents.org/resource/PH9f325d76d5fa623 a ll:SequenceSelection ; rdf:_1 https://data.goldenagents.org/datasets/SAA/ontology/isInRecord ; rdf:_2 https://data.goldenagents.org/datasets/SAA/ontology/Boedelscheiding ; rdf:_3 https://data.goldenagents.org/datasets/SAA/ontology/inventoryNumber . PREDICATE SELECTED [SOURCE] N0: 9 \u00b6 http://data.goldenagents.org/resource/PredicateSelection-PHeb98e7f77b22fce a ll:PropertySelection ; ll:has-entity-selection http://data.goldenagents.org/resource/EntitySelection-PHb97c2bc9d29ba36 ; ll:has-predicate http://data.goldenagents.org/resource/PH22c48ebe6b24223 . http://data.goldenagents.org/resource/PH22c48ebe6b24223 a ll:SequenceSelection ; rdf:_1 https://data.goldenagents.org/datasets/SAA/ontology/isInRecord ; rdf:_2 https://data.goldenagents.org/datasets/SAA/ontology/Inventory ; rdf:_3 https://data.goldenagents.org/datasets/SAA/ontology/registrationDate . PREDICATE SELECTED [SOURCE] N0: 10 \u00b6 http://data.goldenagents.org/resource/PredicateSelection-PHf741a098569afb1 a ll:PropertySelection ; ll:has-entity-selection http://data.goldenagents.org/resource/EntitySelection-PH4ba00e26b03e5dc ; ll:has-predicate http://data.goldenagents.org/resource/PH22c48ebe6b24223 . PREDICATE SELECTED [TARGET] N0: 11 \u00b6 http://data.goldenagents.org/resource/PredicateSelection-PHee886bb3d021a6a a ll:PropertySelection ; ll:has-entity-selection http://data.goldenagents.org/resource/EntitySelection-PH769c39438419b10 ; ll:has-predicate http://data.goldenagents.org/resource/PHda68158d0b9f392 . http://data.goldenagents.org/resource/PHda68158d0b9f392 a ll:SequenceSelection ; rdf:_1 https://data.goldenagents.org/datasets/SAA/ontology/isInRecord ; rdf:_2 https://data.goldenagents.org/datasets/SAA/ontology/HuwelijkseVoorwaarden ; rdf:_3 https://data.goldenagents.org/datasets/SAA/ontology/registrationDate . PREDICATE SELECTED [TARGET] N0: 12 \u00b6 http://data.goldenagents.org/resource/PredicateSelection-PH715d032180bd40c a ll:PropertySelection ; ll:has-entity-selection http://data.goldenagents.org/resource/EntitySelection-PH769c39438419b10 ; ll:has-predicate http://data.goldenagents.org/resource/PH956023596f37d1b . http://data.goldenagents.org/resource/PH956023596f37d1b a ll:SequenceSelection ; rdf:_1 https://data.goldenagents.org/datasets/SAA/ontology/isInRecord ; rdf:_2 https://data.goldenagents.org/datasets/SAA/ontology/Boedelinventaris ; rdf:_3 https://data.goldenagents.org/datasets/SAA/ontology/registrationDate . PREDICATE SELECTED [TARGET] N0: 13 \u00b6 http://data.goldenagents.org/resource/PredicateSelection-PHe349eb18e5ba638 a ll:PropertySelection ; ll:has-entity-selection http://data.goldenagents.org/resource/EntitySelection-PH769c39438419b10 ; ll:has-predicate http://data.goldenagents.org/resource/PH0ef342da86f3226 . http://data.goldenagents.org/resource/PH0ef342da86f3226 a ll:SequenceSelection ; rdf:_1 https://data.goldenagents.org/datasets/SAA/ontology/isInRecord ; rdf:_2 https://data.goldenagents.org/datasets/SAA/ontology/Boedelscheiding ; rdf:_3 https://data.goldenagents.org/datasets/SAA/ontology/registrationDate . ANNOTATED LINKSET \u00b6 linkset:Getty { < > ll_val:has-validation \u201cnot_validated\u201d . \u2022 \u2022 \u2022 } ```","title":"5. Linkset - Link Construction"},{"location":"05.LinkConstruction/#link-construction","text":"Linking co-referent entities across a variety of datasources is a pragmatic and fast way to seamlessly navigate across datasets without having to agree in a uniform vocabulary. This solution offered in the Semantic Web architecture appears attractive as the ultimate goal for the researcher executing this task is not the integration of data but the extraction of vital information for reaching valid conclusions about problems under scrutiny. This said, the Lenticular Lens offers means to reach that ultimate goal of the researcher while making sure that the steps taken by the researcher are documented such that other researchers can easily re-generate the data leading to specific conclusions if need be. Along the way of entity-based data integration and data extraction, the Lenticular Lens aims to document among others: The datasources to integrate; The reasons behind a specific integration; The entity types and restrictions that ensure correctness in bridging across datasources of interest; The matching methods and specifications justifying the existence of a set of links. The Lenticular Lens tool aims to provide generic methods that allows a broader audience suffering the same need for data integration. The first step in creating and documenting links using the Lenticular Lens is defining the scope in witch links are to be created and possibly validated. For that, the tool offers the RESEARCH menu followed by the SELECT and CONSTRUCT menus. We now go through each of these first three menus underlying the existence of links.","title":"LINK CONSTRUCTION"},{"location":"05.LinkConstruction/#1-scope","text":"The RESEARCH menu is the starting point in learning how to interact with the Lenticular Lens tool. In general, a research question somehow sets the scope in which link creations, manipulations or validation take place. This provides the first building block supporting the user with defining the context in which a particular alignment is generated. Using this menu, part of the context is made explicit by selecting the datasets and entity types necessary to continue the investigation. As an overview, the RESEARCH menu provides researchers with means to describe the research of interest in terms of: Research Question for inserting the main research question driving the integration. Hypothesis for pointing out the hypothesis in mind prior to the data extraction. Link and Citation to ensure that, if the results happen to be published, the researcher still has the facility to add a link to the publication and and a bibliographic reference for future reuse. Fig. 4.1 illustrates the different fields to be filled in by the researcher for a quick overview of what can happen in this research project and why. Once providing the information is done, the Save button at the bottom of the page can be clicked to save the provided information and exit the Lenticular Lens if the user which to continue with other tasks. Or, should the user choose to continue the alternative Save and next button can be used to save the project and move to the next window. Fig. 4.1: Describing the scope of he research question.","title":"1. Scope"},{"location":"05.LinkConstruction/#2-data","text":"In the previous step or window, the researcher has defined the scope of the research for which data are to be extracted and analysed. In this second window labelled SELECT , the user is to describe and select the entity types involved in his research. For that, the location of the datasource needs to be provided and the datasets in which the respective entities of interest reside need to be selected.","title":"2. Data"},{"location":"05.LinkConstruction/#21-data-selection","text":"As the user activates the Saves and next button at the end of the previous page, she is presented with a new window with a single card labelled Entity-Type Selection 1 as presented in Fig. 4.2. The plus button at the right side of the picture enables the user to create new cards when needed while the arrow-head button at the left side of the card\u2019s label allows for the unveiling of the card as displayed in Fig 3. Fig. 4.2: The card view for data selection Describing the type of an entity can be done using the Description text box for each entity type. To provide the location of the data, the GraphQL Endpoint text box can be use to fill in the URL of any GraphQL end point. Once the endpoint is given and loaded, a dataset can be selected from the list of datasets available at the provided endpoint. The selection of a dataset will prompt a new dropdown text box as Entity type , providing the user with the facility to select the entity type of interest. After loading the provided URL of the default Golden Agent\u2019s endpoint, Fig. 4.3 shows the list of datasets available at that location to choose from. Fig. 4.3: List of datasets available at the default Golden Agent\u2019s GraphQL endpoint.","title":"2.1 Data Selection"},{"location":"05.LinkConstruction/#22-data-restrictions","text":"If need be to filter entities based on specific conditions, this is also possible with the Filter card shown in Fig. 4.6. Fig. 4.6: The card for defining entity restrictions. Once the button is clicked, this card presents the user with a Filter-Logic box which enable the creation of a relatively complex and versatile entity restrictions. Fig. 4.7 for example show the list of available filtering options while Fig. 4.8 illustrates an example where the has minimum date and has maximum date filtering options are used to isolate entities of interest. These entities are now those between with a registration date between [1600, 1659] and having their respective literal name exempt of trailing dots (\u2026). Fig. 4.7: List of restriction options. Fig. 4.8: The card for defining entity restrictions.","title":"2.2 Data Restrictions"},{"location":"05.LinkConstruction/#221-restriction-options","text":"Equal to / Not Equal to. This option allows one to select entities that have the value of a certain property equal (or not) to a certain value. For example, all entities with property ex:workLocation equal (or not) to Amsterdam . Contains / Does not contain. This option is used to make sure that the property-value of the entities of interest contains or does not contain a specific sequence of characters. For example, %...% could be used for (i) excluding people whose names contain trailing dots or (ii) to select those entities to apply a particular modification onto their names, like adding the surname of the father for a baptised child whose surname is given as ... . Has property / Has no property. This option is used to select entities based on the existence (or not) of a certain property. Let assume, for example, that the user is interested in entities that are parents. This option allows one to filter all entities for which the a value exists for the property ex:parentOf for example. It also allows you to exclude all entities that are parents if the option Has no property is used instead. Has minimum / maximum value. This option allows for restricting entities to be within or outside a specified range given user\u2019s specified property-values of type number over which the restriction can be applied. To delimit both upper and lower bounds, the user can combine minimum and maximum using the logical box AND. Has minimum / maximum date. This option allows for restricting entities to be within or outside a specified range given user\u2019s specified property-values of type date over which the restriction can be applied. Within this option, a date format can be specified. The default format is YYYY-MM-DD . The values 10, 300 and 1990 for example will be considered as year while 10-1, 300-1 and 1990-1 will be considered as the first month of the respective year values. To delimit both upper and lower bounds, the user can combine minimum and maximum using the logical box AND. Has minimum / maximum appearances. This option allows for restricting entities for which a given property value occurs within a specified range . For example, to avoid excessive number of possible matches, one can delimit that only entities whose name value occur less than 5 times in the dataset will be included. To delimit both upper and lower bounds, the user can combine minimum and maximum using the logical box AND. In set. This option allows the filtering of a collection of resources of interest based on a set of resources. These set of resources is not manually provided but can be obtained through a list of existing linksets or lenses. The example below provides a detailed understanding of this filtering approach. Example 1: IN SET Two collections A and B to be matched via whatever method would create a se of links labelled linkset-AB. However, we are only interested in a subset of linkset-AB, such that it\u2019s resources (subject, object or both) are present in another given set, namely an input-linkset I. For efficiency purposes, linkset-AB does not need to be fully created to be filtered later on. This implies that the collections A and/or B need to be filtered such that A\u2019 = A \u2229 I and/or B\u2019 = B \u2229 I before executing the matching algorithm. ###################################################### # Linksets as named graphs # ###################################################### ex: input-linkset { A: Chiara owl: sameAs C: Latronico . A: Al owl: sameAs C: Al_Idrissou . A: Al owl: sameAs C: Al_Koudous . } ex: linkset-AB { A: Chiara owl: sameAs B: Chiara . A: Kerim owl: sameAs B: Kerim . } ###################################################### # In Resource Set # ###################################################### ### The set S of resources from input-linkset is: ### S = {A:Chiara, A:Al, C:Latronico, C:Al_Idrissou, C:Al_Koudous} ex: linkset-SubjectInSet { A: Chiara owl: sameAs B: Chiara . }","title":"2.2.1 Restriction options"},{"location":"05.LinkConstruction/#23-data-exploration","text":"At this point, successfully providing the required information ( Dataset and Entity-Type ) triggers the appearance of the Explore Sample button at the right side of the card\u2019s label ( Entity-type selection 1 ) as displayed in Fig. 4.4. As illustrated in Fig. 4.5, with this button, users are now able to explore information of their choice about the entities of interest by selecting properties describing them. Keep in mind that this feature is only intended as exploration alternative to make sure of the choices (dataset, entity-type and restrictions) made. Fig. 4.4: The Explore sample button shows only after the entity type is selected. Fig. 4.5: Exploring the description of entities of choice, stemmed from the dataset of interest.","title":"2.3 Data Exploration"},{"location":"05.LinkConstruction/#3-matching-in-practice","text":"Now that we have gone through available matching methods and how to combine them in the Lenticular Lens , we show their application in some case-studies aligning resources stemmed from various datasources of one\u2019s choice. We also provide example on the rdf export of the resulting linksets with metadata. For this purpose we choose as syntax the turtle format and RDFstar reification.","title":"3. Matching in Practice"},{"location":"05.LinkConstruction/#31-simple-methods","text":"This case-study section aims to showcase matching problems involving a SINGLE matching method (Embedded, Exact, Intermediate, Levenshtein Distance, Soundex Distance, Gerrit Bloothooft, Word Intersection, List Intersection, Numbers and TeAM) run over one or multiple datasets. We call them Simple Methods as opposed to Complex Methods illustrated in the sequel. Keep in mind that the terms Simple and Complex refer to the use of single or combined methods and not to the algorithm complexity of the underlying the method(s).","title":"3.1 Simple Methods"},{"location":"05.LinkConstruction/#case-1-grid","text":"In this case study, displayed in Fig 4.10, the goal is to find out whether there exist duplicates Education Instances within the Grid\u2019s dataset. The dataset is composed of nine types of institutions including 27715 Companies , 19353 Educations , 12547 Nonprofit institutes, 12465 Healthcare institutes, 8499 Facility institutes, 5762 Government institutes, 2724 Archive institutes and 7823 institutes with no type specified. Although the dataset is of multiple types of entities, the case-study here aims only to deduplicate instances of type Education . This is depicted in Fig 4.10 where the Sources and Targets cards are GRID[Education] showing that the entity type Education has been selected within the GRID dataset. Case-1: Linkset Specifications Fig 4.10: An example showing how to deduplicate a dataset using edit distance with a user-defined threshold of 0.9. Also in the Matching Methods card, it can be seen that on both sides (source and target) two properties are selected for checking whether duplicates exist. This check relies on whether there exist entities that are documented within the GRID dataset with similar names using rdfs_label and skos_prefLabel . As the similarity score is measured in the interval 0 (not similar) to 1 (exactly similar), the threshold defined as 0.9 ensures that only paired entities with a high similarity (0.9 or above) are accepted. The same card shows the selected algorithm as Levenshtein Distance , which is run over the selected predicates generating 1,692 distinct links as shown in the statistics card (on the top). The latter card also provides statistics on: The number of entities at the Source and Target . In this particular case, over 19K educational institutes at both source and target as they are the same dataset. Such information provides hints on the maximum number of links to expect in the worst case scenario as well as an idea on how long the running algorithm could take. The number of entities matched at the subject and object positions. The number of clusters derived from the links found. Here, this provides a potentially better picture on the number of real entities, as co-referent are grouped together in clusters of various sizes. The Runtime durations informing on the elapsed time for (1) finding links and for (2) clustering them. In this Image 1, we deliberately choose two properties at both the Source and Target datasets for the deduplication. Choosing for more than one property either for the Source or Target triggers a combination of pairwise property-value matching joined with the logic operator OR . For example choosing properties x and y at the source while choosing only z at the target triggers the following pairwise combinations: ( x AND z ) OR ( y AND z ). In the current use-case, choosing for example rdfs_label and skos_prefLabel at both Source AND Target generates the following combination: rdfs_label AND rdfs_label OR rdfs_label AND skos_prefLabel OR skos_prefLabel AND skos_prefLabel . This explicit combination is implemented as an alternative complex method in the next section, where three executions of the `Levenshtein Distance algorithm is required, instead of one. Case-1: RDF Results. This section provides the complete metadata of the resulting Linkset for the specification above in Example 4.15, plus a sample of 9 links due to space limitation. From this metadata, a number of general statistical information on the linkset can be obtained, such as the number of distinct triples , entities or clusters , the number of links accepted or rejected and more. The metadata also presents a detailed description on the methods used to generate the links. For example, for each algorithm used, a uri and description is provided. This algorithm can be used in one or more methods, provided the link acceptance threshold , the vrange of the similarity score, the datasets , data-types and predicates uris used for link findings. Furthermore, a specific annotation is provided in an RDFstar format for each generated link. In this example, we have the strength of the link and whether the link has been validated ( accepted , rejected or not_validated ). Case-1: Turtle file sample ### PREDEFINED SHARED NAMESPACES ### @prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> . @prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> . @prefix owl: <http://www.w3.org/2002/07/owl#> . @prefix void: <http://rdfs.org/ns/void#> . @prefix dcterms: <http://purl.org/dc/terms/> . @prefix format: <http://www.w3.org/ns/formats/> . @prefix pav: <http://purl.org/ontology/similarity/> . @prefix cc: <http://creativecommons.org/ns#> . ### PREDEFINED SPECIFIC NAMESPACES ### @prefix ll: <http://data.goldenagents.org/ontology/> . @prefix ll_algo: <http://data.goldenagents.org/ontology/matching-method/> . @prefix ll_val: <http://data.goldenagents.org/ontology/validation/> . @prefix linkset: <http://data.goldenagents.org/resource/linkset/> . @prefix dataset: <http://data.goldenagents.org/resource/dataset/> . ### AUTOMATED NAMESPACES ### @prefix skos: <http://www.w3.org/2004/02/skos/core#> . @prefix institutes_S1: <http://www.grid.ac/institutes/> . ########################################### # GENERIC METADATA # ########################################### linkset: Grid a void: Linkset ; cc: attributionName \"LenticularLens\" ; void: feature format: Turtle ; cc: license <http://purl.org/NET/rdflicense/W3C1.0> ; ll: has-logic-formulation <http://data.goldenagents.org/resource/PHbb54a8dab0d2954> ; void: linkPredicate skos: exactMatch ; void: subjectsTarget <http://data.goldenagents.org/resource/dataset/Grid> ; void: objectsTarget <http://data.goldenagents.org/resource/dataset/Grid> ; dcterms: description \"Deduplication of entities of type Education in the GRID dataset\" @ en ; void: triples 1692 ; void: entities 1737 ; void: distinctSubjects 1737 ; void: distinctObjects 1737 ; ll: has-clusters 619 ; ll_val: has-validations 18 ; ll_val: has-accepted 3 ; ll_val: has-rejected 6 ; ll_val: has-remaining 1683 . ############################################# # LOGIC FORMULA PARTS # ############################################# <http://data.goldenagents.org/resource/PHbb54a8dab0d2954> a ll: LogicFormulation ; ll: has-method <http://data.goldenagents.org/resource/Normalised-EditDistance-H30d57e26e41bb04> ; ll: has-formula-description \"\"\"<http://data.goldenagents.org/resource/Normalised-EditDistance-H30d57e26e41bb04> \"\"\" . ############################################# # METHOD SIGNATURES # ############################################# ### ll_algo:Normalised-EditDistance ### <http://data.goldenagents.org/resource/Normalised-EditDistance-H30d57e26e41bb04> a ll:MatchingMethod ; ll:has-algorithm ll_algo:Normalised-EditDistance ; ll:has-threshold 0.9 ; ll:has-threshold-range \"]0, 1]\" ; ll:has-threshold-acceptance-operator <http://data.goldenagents.org/resource/Greater-than-or-equal-to> ; ll:has-subj-entity-selection <http://data.goldenagents.org/resource/EntitySelection-PH61bd543e4ce34c2> ; ll:has-subj-predicate-selection <http://data.goldenagents.org/resource/PredicateSelection-PHab504e102405ab0> ; ll:has-subj-predicate-selection <http://data.goldenagents.org/resource/PredicateSelection-PH0d712649af643f3> ; ll:has-obj-entity-selection <http://data.goldenagents.org/resource/EntitySelection-PH61bd543e4ce34c2> ; ll:has-obj-predicate-selection <http://data.goldenagents.org/resource/PredicateSelection-PHab504e102405ab0> ; ll:has-obj-predicate-selection <http://data.goldenagents.org/resource/PredicateSelection-PH0d712649af643f3> . ############################################# # METHOD DESCRIPTIONS # ############################################# ll_algo:Normalised-EditDistance a ll:MatchingAlgorithm ; dcterms:description \"\"\" This \u200bmethod is used to align \u200b\u200bsource a\u200bnd \u200b\u200btarget\u2019s IRIs whenever the similarity score of their respective user selected property values are \u200b\u200babove a given \u200bLevenshtein (edit) Distance threshold\u200b. Edit distance is a way of quantifying how \u200bdissimilar two strings (e.g., words) are to one another by counting the minimum number of operations \u200b\u03b5 \u200b(\u200bremoval, insertion, or substitution of a character in the string)\u200b required to transform one string into the other. For example, \u200bthe \u200bLevenshtein distance between kitten and sitting is \u200b\u03b5 \u200b= 3 as it requires a two substitutions (s for k and i for e) and one insertion of g at the end [https://en.wikipedia.org/wiki/Edit_distance]\u200b. \"\"\"@en . ############################################# # DATASET AND ENTITY SELECTIONS # ############################################# ### ENTITY SELECTION [SOURCE] N0: 1 ### <http://data.goldenagents.org/resource/EntitySelection-PH61bd543e4ce34c2> a ll:EntitySelection ; ll:has-dataset <http://data.goldenagents.org/resource/dataset/Grid> ; ll:has-entity-type <http://www.grid.ac/ontology/Education> . ############################################# # PREDICATE SELECTIONS # ############################################# ### PREDICATE SELECTED [SOURCE] N0: 1 ### <http://data.goldenagents.org/resource/PredicateSelection-PHab504e102405ab0> a ll:PropertySelection ; ll:has-entity-selection <http://data.goldenagents.org/resource/EntitySelection-PH61bd543e4ce34c2> ; ll:has-predicate <http://www.w3.org/2000/01/rdf-schema#label> . ### PREDICATE SELECTED [SOURCE] N0: 2 ### <http://data.goldenagents.org/resource/PredicateSelection-PH0d712649af643f3> a ll:PropertySelection ; ll:has-entity-selection <http://data.goldenagents.org/resource/EntitySelection-PH61bd543e4ce34c2> ; ll:has-predicate <http://www.w3.org/2004/02/skos/core#prefLabel> . ########################################### # ANNOTATED LINKSET # ########################################### linkset:Grid { <<institutes_S1:grid.1017.7 skos:exactMatch institutes_S1:grid.501980.5>> ll_val:has-validation \"rejected\" : ll:has-matching-strength 0.933 . <<institutes_S1:grid.1019.9 skos:exactMatch institutes_S1:grid.449929.b>> ll_val:has-validation \"accepted\" ; ll:has-matching-strength 1 . <<institutes_S1:grid.1020.3 skos:exactMatch institutes_S1:grid.266826.e>> ll_val:has-validation \"not_validated\" ; ll:has-matching-strength 1 . <<institutes_S1:grid.10215.37 skos:exactMatch institutes_S1:grid.10347.31>> ll_val:has-validation \"rejected\" ; ll:has-matching-strength 0.950 . <<institutes_S1:grid.10215.37 skos:exactMatch institutes_S1:grid.10595.38>> ll_val:has-validation \"rejected\" ; ll:has-matching-strength 0.900 . <<institutes_S1:grid.10215.37 skos:exactMatch institutes_S1:grid.4462.4>> ll_val:has-validation \"rejected\" ; ll:has-matching-strength 0.900 . <<institutes_S1:grid.10347.31 skos:exactMatch institutes_S1:grid.10595.38>> ll_val:has-validation \"rejected\" ; ll:has-matching-strength 0.900 . <<institutes_S1:grid.10347.31 skos:exactMatch institutes_S1:grid.441173.4>> ll_val:has-validation \"rejected\" ; ll:has-matching-strength 0.900 . <<institutes_S1:grid.10347.31 skos:exactMatch institutes_S1:grid.4462.4>> lll_val:has-validation \"accepted\" ; ll:has-matching-strength 0.900 . \u2022 \u2022 \u2022 }","title":"Case-1: Grid"},{"location":"05.LinkConstruction/#32-complex-methods","text":"","title":"3.2 Complex Methods"},{"location":"05.LinkConstruction/#case-1-alternative","text":"In Fig 4.11 is displayed an alternative where Case-1: Linkset Specifications Fig 4.11: An example showing how to deduplicate a dataset using an edit distance with threshold 0.9. Case-1: RDF Results Case-1: Turtle file sample ########################################### # NAMESPACES # ########################################### ### PREDEFINED SHARED NAMESPACES @prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> . @prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> . @prefix owl: <http://www.w3.org/2002/07/owl#> . @prefix void: <http://rdfs.org/ns/void#> . @prefix dcterms: <http://purl.org/dc/terms/> . @prefix format: <http://www.w3.org/ns/formats/> . @prefix pav: <http://purl.org/ontology/similarity/> . @prefix cc: <http://creativecommons.org/ns#> . ### PREDEFINED SPECIFIC NAMESPACES @prefix ll: <http://data.goldenagents.org/ontology/> . @prefix ll_algo: <http://data.goldenagents.org/ontology/matching-method/> . @prefix ll_val: <http://data.goldenagents.org/ontology/validation/> . @prefix linkset: <http://data.goldenagents.org/resource/linkset/> . @prefix dataset: <http://data.goldenagents.org/resource/dataset/> . ### AUTOMATED NAMESPACES @prefix skos: <http://www.w3.org/2004/02/skos/core#> . @prefix institutes_S1: <http://www.grid.ac/institutes/> . ############################################################################################################## # GENERIC METADATA # ############################################################################################################## linkset: Grid_2 a void: Linkset ; cc: attributionName \"LenticularLens\" ; void: feature format: Turtle ; cc: license <http://purl.org/NET/rdflicense/W3C1.0> ; ll: has-logic-formulation <http://data.goldenagents.org/resource/PH1ec0ee6f368dd62> ; void: linkPredicate skos: exactMatch ; void: subjectsTarget <http://data.goldenagents.org/resource/dataset/Grid> ; void: objectsTarget <http://data.goldenagents.org/resource/dataset/Grid> ; dcterms: description \"Deduplication of entities of type Education in the GRID dataset\" @ en ; void: triples 1692 ; void: entities 1737 ; void: distinctSubjects 1737 ; void: distinctObjects 1737 ; ll: has-clusters 619 ; ll_val: has-validations 18 ; ll_val: has-accepted 3 ; ll_val: has-rejected 6 ; ll_val: has-remaining 1683 . ################################################################################ # LOGIC FORMULA PARTS # ################################################################################ <http://data.goldenagents.org/resource/PH1ec0ee6f368dd62> a ll: LogicFormulation ; ll: has-method <http://data.goldenagents.org/resource/Normalised-EditDistance-H779a0ad1b5e5f93> ; ll: has-method <http://data.goldenagents.org/resource/Normalised-EditDistance-H3de4966a0b8aa01> ; ll: has-method <http://data.goldenagents.org/resource/Normalised-EditDistance-H11cbb0cc77c44a9> ; ll: has-formula-description \"\"\"<http://data.goldenagents.org/resource/Normalised-EditDistance-H779a0ad1b5e5f93> and (\u22a4min) <http://data.goldenagents.org/resource/Normalised-EditDistance-H3de4966a0b8aa01> and (\u22a4min) <http://data.goldenagents.org/resource/Normalised-EditDistance-H11cbb0cc77c44a9> \"\"\" . ################################################################################ # METHOD SIGNATURES # ################################################################################ ### ll_algo:Normalised-EditDistance <http://data.goldenagents.org/resource/Normalised-EditDistance-H779a0ad1b5e5f93> a ll:MatchingMethod ; ll:has-algorithm ll_algo:Normalised-EditDistance ; ll:has-threshold 0.9 ; ll:has-threshold-range \"]0, 1]\" ; ll:has-threshold-acceptance-operator <http://data.goldenagents.org/resource/Greater-than-or-equal-to> ; ll:has-subj-entity-selection <http://data.goldenagents.org/resource/EntitySelection-PH61bd543e4ce34c2> ; ll:has-subj-predicate-selection <http://data.goldenagents.org/resource/PredicateSelection-PHab504e102405ab0> ; ll:has-obj-entity-selection <http://data.goldenagents.org/resource/EntitySelection-PH61bd543e4ce34c2> ; ll:has-obj-predicate-selection <http://data.goldenagents.org/resource/PredicateSelection-PHab504e102405ab0> . ### ll_algo:Normalised-EditDistance <http://data.goldenagents.org/resource/Normalised-EditDistance-H3de4966a0b8aa01> a ll:MatchingMethod ; ll:has-algorithm ll_algo:Normalised-EditDistance ; ll:has-threshold 0.9 ; ll:has-threshold-range \"]0, 1]\" ; ll:has-threshold-acceptance-operator <http://data.goldenagents.org/resource/Greater-than-or-equal-to> ; ll:has-subj-entity-selection <http://data.goldenagents.org/resource/EntitySelection-PH61bd543e4ce34c2> ; ll:has-subj-predicate-selection <http://data.goldenagents.org/resource/PredicateSelection-PHab504e102405ab0> ; ll:has-obj-entity-selection <http://data.goldenagents.org/resource/EntitySelection-PH61bd543e4ce34c2> ; ll:has-obj-predicate-selection <http://data.goldenagents.org/resource/PredicateSelection-PH0d712649af643f3> . ### ll_algo:Normalised-EditDistance <http://data.goldenagents.org/resource/Normalised-EditDistance-H11cbb0cc77c44a9> a ll:MatchingMethod ; ll:has-algorithm ll_algo:Normalised-EditDistance ; ll:has-threshold 0.9 ; ll:has-threshold-range \"]0, 1]\" ; ll:has-threshold-acceptance-operator <http://data.goldenagents.org/resource/Greater-than-or-equal-to> ; ll:has-subj-entity-selection <http://data.goldenagents.org/resource/EntitySelection-PH61bd543e4ce34c2> ; ll:has-subj-predicate-selection <http://data.goldenagents.org/resource/PredicateSelection-PH0d712649af643f3> ; ll:has-obj-entity-selection <http://data.goldenagents.org/resource/EntitySelection-PH61bd543e4ce34c2> ; ll:has-obj-predicate-selection <http://data.goldenagents.org/resource/PredicateSelection-PH0d712649af643f3> . ################################################################################ # METHOD DESCRIPTIONS # ################################################################################ ll_algo:Normalised-EditDistance a ll:MatchingAlgorithm ; dcterms:description \"\"\" This \u200bmethod is used to align \u200b\u200bsource a\u200bnd \u200b\u200btarget\u2019s IRIs whenever the similarity score of their respective user selected property values are \u200b\u200babove a given \u200bLevenshtein (edit) Distance threshold\u200b. Edit distance is a way of quantifying how \u200bdissimilar two strings (e.g., words) are to one another by counting the minimum number of operations \u200b\u03b5 \u200b(\u200bremoval, insertion, or substitution of a character in the string)\u200b required to transform one string into the other. For example, \u200bthe \u200bLevenshtein distance between kitten and sitting is \u200b\u03b5 \u200b= 3 as it requires a two substitutions (s for k and i for e) and one insertion of g at the end [https://en.wikipedia.org/wiki/Edit_distance]\u200b. \"\"\"@en . ################################################################################ # DATASET AND ENTITY SELECTIONS # ################################################################################ ### ENTITY SELECTION [SOURCE] N0: 1 ### <http://data.goldenagents.org/resource/EntitySelection-PH61bd543e4ce34c2> a ll:EntitySelection ; ll:has-dataset <http://data.goldenagents.org/resource/dataset/Grid> ; ll:has-entity-type <http://www.grid.ac/ontology/Education> . ################################################################################ # PREDICATE SELECTIONS # ################################################################################ ### PREDICATE SELECTED [SOURCE] N0: 1 ### <http://data.goldenagents.org/resource/PredicateSelection-PHab504e102405ab0> a ll:PropertySelection ; ll:has-entity-selection <http://data.goldenagents.org/resource/EntitySelection-PH61bd543e4ce34c2> ; ll:has-predicate <http://www.w3.org/2000/01/rdf-schema#label> . ### PREDICATE SELECTED [TARGET] N0: 2 ### <http://data.goldenagents.org/resource/PredicateSelection-PH0d712649af643f3> a ll:PropertySelection ; ll:has-entity-selection <http://data.goldenagents.org/resource/EntitySelection-PH61bd543e4ce34c2> ; ll:has-predicate <http://www.w3.org/2004/02/skos/core#prefLabel> . ############################################################################################################## # ANNOTATED LINKSET # ############################################################################################################## linkset:Grid_2 { <<institutes_S1:grid.1017.7 skos:exactMatch institutes_S1:grid.501980.5>> ll_val:has-validation \"rejected\" . <<institutes_S1:grid.1019.9 skos:exactMatch institutes_S1:grid.449929.b>> ll_val:has-validation \"accepted\" . <<institutes_S1:grid.1020.3 skos:exactMatch institutes_S1:grid.266826.e>> ll_val:has-validation \"accepted\" . <<institutes_S1:grid.10215.37 skos:exactMatch institutes_S1:grid.10347.31>> ll_val:has-validation \"rejected\" . <<institutes_S1:grid.10215.37 skos:exactMatch institutes_S1:grid.10595.38>> ll_val:has-validation \"rejected\" . <<institutes_S1:grid.10215.37 skos:exactMatch institutes_S1:grid.4462.4>> ll_val:has-validation \"rejected\" . <<institutes_S1:grid.10347.31 skos:exactMatch institutes_S1:grid.10595.38>> ll_val:has-validation \"rejected\" . <<institutes_S1:grid.10347.31 skos:exactMatch institutes_S1:grid.441173.4>> ll_val:has-validation \"rejected\" . <<institutes_S1:grid.10347.31 skos:exactMatch institutes_S1:grid.4462.4>> ll_val:has-validation \"accepted\" . <<institutes_S1:grid.10373.36 skos:exactMatch institutes_S1:grid.266769.a>> ll_val:has-validation \"not_validated\" . \u2022 \u2022 \u2022 }","title":"Case-1: Alternative"},{"location":"05.LinkConstruction/#case-2-getty","text":"In Fig 4.12 is displayed an alternative where Case-2: Linkset Specifications. Fig 4.12: An example showing how to deduplicate a dataset using an edit distance with threshold 0.9. Case-2: RDF Results. Case-2: Turtle file sample.","title":"Case-2: Getty"},{"location":"05.LinkConstruction/#namespaces","text":"","title":"NAMESPACES"},{"location":"05.LinkConstruction/#predefined-shared-namespaces","text":"@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> . @prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> . @prefix owl: <http://www.w3.org/2002/07/owl#> . @prefix void: <http://rdfs.org/ns/void#> . @prefix dcterms: <http://purl.org/dc/terms/> . @prefix format: <http://www.w3.org/ns/formats/> . @prefix pav: <http://purl.org/ontology/similarity/> . @prefix cc: <http://creativecommons.org/ns#> .","title":"PREDEFINED SHARED NAMESPACES"},{"location":"05.LinkConstruction/#predefined-specific-namespaces","text":"@prefix ll: <http://data.goldenagents.org/ontology/> . @prefix ll_algo: <http://data.goldenagents.org/ontology/matching-method/> . @prefix ll_val: <http://data.goldenagents.org/ontology/validation/> . @prefix linkset: <http://data.goldenagents.org/resource/linkset/> . @prefix dataset: <http://data.goldenagents.org/resource/dataset/> .","title":"PREDEFINED SPECIFIC NAMESPACES"},{"location":"05.LinkConstruction/#automated-namespaces","text":"@prefix skos: <http://www.w3.org/2004/02/skos/core#> . @prefix institutes_S1: <http://www.grid.ac/institutes/> . @prefix time: <http://www.w3.org/2006/time#> . @prefix owl: <http://www.w3.org/2002/07/owl#> . @prefix Person_S1: <http://goldenagents.org/uva/SAA/Person/> . @prefix PersonName_T1: <https://data.goldenagents.org/datasets/SAA/PersonName/> .","title":"AUTOMATED NAMESPACES"},{"location":"05.LinkConstruction/#generic-metadata","text":"","title":"GENERIC METADATA"},{"location":"05.LinkConstruction/#ll_algonormalised-soundex","text":"http://data.goldenagents.org/resource/Normalised-Soundex-H4970fc2fe79ea5f a ll:MatchingMethod ; ll:has-algorithm ll_algo:Normalised-Soundex ; ll:has-threshold 0.85 ; ll:has-threshold-range \"]0, 1]\" ; ll:has-threshold-acceptance-operator <http://data.goldenagents.org/resource/Greater-than-or-equal-to> ; ll:has-subj-entity-selection <http://data.goldenagents.org/resource/EntitySelection-PH4ba00e26b03e5dc> ; ll:has-subj-entity-selection <http://data.goldenagents.org/resource/EntitySelection-PHb97c2bc9d29ba36> ; ll:has-subj-predicate-selection <http://data.goldenagents.org/resource/PredicateSelection-PH914a94c6f3c93b4> ; ll:has-subj-predicate-selection <http://data.goldenagents.org/resource/PredicateSelection-PH10aaeebb6832fdf> ; ll:has-obj-entity-selection <http://data.goldenagents.org/resource/EntitySelection-PH769c39438419b10> ; ll:has-obj-predicate-selection <http://data.goldenagents.org/resource/PredicateSelection-PH7879419327d373d> .","title":"ll_algo:Normalised-Soundex"},{"location":"05.LinkConstruction/#ll_algoexact","text":"http://data.goldenagents.org/resource/Exact-H918a02351d48ca9 a ll:MatchingMethod ; ll:has-algorithm ll_algo:Exact ; ll:has-threshold 1 ; ll:has-threshold-range \"1\" ; ll:has-threshold-acceptance-operator <http://data.goldenagents.org/resource/Equal> ; ll:has-subj-entity-selection <http://data.goldenagents.org/resource/EntitySelection-PHb97c2bc9d29ba36> ; ll:has-subj-entity-selection <http://data.goldenagents.org/resource/EntitySelection-PH4ba00e26b03e5dc> ; ll:has-subj-predicate-selection <http://data.goldenagents.org/resource/PredicateSelection-PH46d91d4f6e2209e> ; ll:has-subj-predicate-selection <http://data.goldenagents.org/resource/PredicateSelection-PH0df0471cb5df515> ; ll:has-obj-entity-selection <http://data.goldenagents.org/resource/EntitySelection-PH769c39438419b10> ; ll:has-obj-predicate-selection <http://data.goldenagents.org/resource/PredicateSelection-PHe3cb3236c5b11b1> ; ll:has-obj-predicate-selection <http://data.goldenagents.org/resource/PredicateSelection-PHb2a681013fbb430> ; ll:has-obj-predicate-selection <http://data.goldenagents.org/resource/PredicateSelection-PH9f7bd41ea902bd0> .","title":"ll_algo:Exact"},{"location":"05.LinkConstruction/#ll_algotime-delta","text":"http://data.goldenagents.org/resource/Time-Delta-Hdcc5070996853e9 a ll:MatchingMethod ; ll:has-algorithm ll_algo:Time-Delta ; ll:has-threshold 0 ; ll:has-threshold-range \"\u2115\" ; time:unitType time:unitYear ; ll:has-threshold-acceptance-operator <http://data.goldenagents.org/resource/Equal> ; ll:has-subj-entity-selection <http://data.goldenagents.org/resource/EntitySelection-PHb97c2bc9d29ba36> ; ll:has-subj-entity-selection <http://data.goldenagents.org/resource/EntitySelection-PH4ba00e26b03e5dc> ; ll:has-subj-predicate-selection <http://data.goldenagents.org/resource/PredicateSelection-PHeb98e7f77b22fce> ; ll:has-subj-predicate-selection <http://data.goldenagents.org/resource/PredicateSelection-PHf741a098569afb1> ; ll:has-obj-entity-selection <http://data.goldenagents.org/resource/EntitySelection-PH769c39438419b10> ; ll:has-obj-predicate-selection <http://data.goldenagents.org/resource/PredicateSelection-PHee886bb3d021a6a> ; ll:has-obj-predicate-selection <http://data.goldenagents.org/resource/PredicateSelection-PH715d032180bd40c> ; ll:has-obj-predicate-selection <http://data.goldenagents.org/resource/PredicateSelection-PHe349eb18e5ba638> . ################################################################################ # METHOD DESCRIPTIONS # ################################################################################ ll_algo:Normalised-Soundex a ll:MatchingAlgorithm ; dcterms:description \u201c\u201d\u201d \u201cSoundex is a phonetic algorithm for indexing names by sound, as pronounced in English. The goal is for ho- mophones to be encoded to the same representation so that they can be matched despite minor differences in spelling. The algorithm mainly encodes consonants; a vowel will not be encoded unless it is the first let- ter\u201d [ https://en.wikipedia.org/wiki/Soundex ]. In the Lenticular Lens, Soundex is used as a normaliser in the sense that an edit distance is run over the soundex code version of a name. For example, the in the table below, the normalisation of both Louijs Roc- ourt and `Lowis Ricourt becomes L200 R263 leading to an edit distance of 0 and a relative strength of 1. However, computing the same names using directly an edit distance results in an edit distance of 3 and a relative matching strength of 0. 79. -------------- -- Example -- THE USE OF SOUNDEX CODE FOR STRING APPROXIMATION -------------- The example below shows the implementation of Soundex Distance in the Lenticular Lens and how it compares with Edit Distance over the original names (no soundex-based normalisation). ------------------------------------------------------------------------------------------------------------------------------------------------------ Source Target E. Dist Rel. distance Source soundex Target soundex Code E. Dist Code Rel. Dist ------------------------------------------------------------------------------------------------------------------------------------------------------ Jasper Cornelisz. Lodder Jaspar Cornelisz Lodder 2 0.92 J216 C654 L360 J216 C654 L360 0 1.0 Barent Teunis Barent Teunisz gen. Drent 12 0.52 B653 T520 B653 T520 G500 D653 10 0.47 Louijs Rocourt Louys Rocourt 2 0.86 L200 R263 L200 R263 0 1.0 Louijs Rocourt Lowis Ricourt 3 0.79 L200 R263 L200 R263 0 1.0 Louys Rocourt Lowis Ricourt 3 0.77 L200 R263 L200 R263 0 1.0 Cornelis Dircksz. Clapmus Cornelis Clapmuts 10 0.6 C654 D620 C415 C654 C415 5 0.64 Geertruydt van den Breemde Geertruijd van den Bremde 4 0.85 G636 V500 D500 B653 G636 V500 D500 B653 \"\"\"@en . ll_algo:Exact a ll:MatchingAlgorithm ; dcterms:description \u201c\u201d\u201d Aligns source and target\u2019s IRIs whenever their respective user selected property values are identical.\u201d\u201c\u201d@en . ll_algo:Time-Delta a ll:MatchingAlgorithm ; dcterms:description \u201c\u201d\u201d 10.1 Time Delta. This function allows for finding co-referent entities on the basis of a minimum time dif- ference between the times reported by the source and the target entities. For example, if the value zero is assigned to the time difference parameter, then, for a matched to be found, the time of the target and the one of the source are to be the exact same times. While accounting for margins of error, one may consider a pair of entities to be co-referent if the real entities are born lambda days, months or years apart among other-things (similar name, place..). \u201c\u201d\u201c@en . ################################################################################ # DATASET AND ENTITY SELECTIONS # ################################################################################","title":"ll_algo:Time-Delta"},{"location":"05.LinkConstruction/#entity-selection-source-n0-1","text":"http://data.goldenagents.org/resource/EntitySelection-PH4ba00e26b03e5dc a ll:EntitySelection ; ll:has-dataset https://data.goldenagents.org/datasets/ufab7d657a250e3461361c982ce9b38f3816e0c4b/frick_collection_montias_data_20200604 ; ll:has-entity-type https://data.goldenagents.org/datasets/SAA/ontology/Person .","title":"ENTITY SELECTION [SOURCE] N0: 1"},{"location":"05.LinkConstruction/#entity-selection-source-n0-2","text":"http://data.goldenagents.org/resource/EntitySelection-PHb97c2bc9d29ba36 a ll:EntitySelection ; ll:has-dataset https://data.goldenagents.org/datasets/ufab7d657a250e3461361c982ce9b38f3816e0c4b/getty_provenance_index_montias_data_20200604 ; ll:has-entity-type https://data.goldenagents.org/datasets/SAA/ontology/Person .","title":"ENTITY SELECTION [SOURCE] N0: 2"},{"location":"05.LinkConstruction/#entity-selection-target-n0-3","text":"http://data.goldenagents.org/resource/EntitySelection-PH769c39438419b10 a ll:EntitySelection ; ll:has-dataset https://data.goldenagents.org/datasets/ufab7d657a250e3461361c982ce9b38f3816e0c4b/index_op_notarieel_archief_enriched_20191202 ; ll:has-entity-type https://w3id.org/pnv#PersonName . ################################################################################ # PREDICATE SELECTIONS # ################################################################################","title":"ENTITY SELECTION [TARGET] N0: 3"},{"location":"05.LinkConstruction/#predicate-selected-source-n0-1","text":"http://data.goldenagents.org/resource/PredicateSelection-PH914a94c6f3c93b4 a ll:PropertySelection ; ll:has-entity-selection http://data.goldenagents.org/resource/EntitySelection-PH4ba00e26b03e5dc ; ll:has-predicate http://www.w3.org/2000/01/rdf-schema#label .","title":"PREDICATE SELECTED [SOURCE]  N0: 1"},{"location":"05.LinkConstruction/#predicate-selected-source-n0-2","text":"http://data.goldenagents.org/resource/PredicateSelection-PH10aaeebb6832fdf a ll:PropertySelection ; ll:has-entity-selection http://data.goldenagents.org/resource/EntitySelection-PHb97c2bc9d29ba36 ; ll:has-predicate http://www.w3.org/2000/01/rdf-schema#label .","title":"PREDICATE SELECTED [SOURCE]  N0: 2"},{"location":"05.LinkConstruction/#predicate-selected-target-n0-3","text":"http://data.goldenagents.org/resource/PredicateSelection-PH7879419327d373d a ll:PropertySelection ; ll:has-entity-selection http://data.goldenagents.org/resource/EntitySelection-PH769c39438419b10 ; ll:has-predicate http://www.w3.org/2000/01/rdf-schema#label .","title":"PREDICATE SELECTED [TARGET]  N0: 3"},{"location":"05.LinkConstruction/#predicate-selected-source-n0-4","text":"http://data.goldenagents.org/resource/PredicateSelection-PH46d91d4f6e2209e a ll:PropertySelection ; ll:has-entity-selection http://data.goldenagents.org/resource/EntitySelection-PHb97c2bc9d29ba36 ; ll:has-predicate http://data.goldenagents.org/resource/PH1df7dbfdf1d1eb8 . http://data.goldenagents.org/resource/PH1df7dbfdf1d1eb8 a ll:SequenceSelection ; rdf:_1 https://data.goldenagents.org/datasets/SAA/ontology/isInRecord ; rdf:_2 https://data.goldenagents.org/datasets/SAA/ontology/Inventory ; rdf:_3 https://data.goldenagents.org/datasets/SAA/ontology/documentedIn ; rdf:_4 https://data.goldenagents.org/datasets/SAA/ontology/InventoryBook ; rdf:_5 https://data.goldenagents.org/datasets/SAA/ontology/inventoryNumber .","title":"PREDICATE SELECTED [SOURCE]  N0: 4"},{"location":"05.LinkConstruction/#predicate-selected-source-n0-5","text":"http://data.goldenagents.org/resource/PredicateSelection-PH0df0471cb5df515 a ll:PropertySelection ; ll:has-entity-selection http://data.goldenagents.org/resource/EntitySelection-PH4ba00e26b03e5dc ; ll:has-predicate http://data.goldenagents.org/resource/PH1df7dbfdf1d1eb8 .","title":"PREDICATE SELECTED [SOURCE]  N0: 5"},{"location":"05.LinkConstruction/#predicate-selected-target-n0-6","text":"http://data.goldenagents.org/resource/PredicateSelection-PHe3cb3236c5b11b1 a ll:PropertySelection ; ll:has-entity-selection http://data.goldenagents.org/resource/EntitySelection-PH769c39438419b10 ; ll:has-predicate http://data.goldenagents.org/resource/PH7334cc09b832a17 . http://data.goldenagents.org/resource/PH7334cc09b832a17 a ll:SequenceSelection ; rdf:_1 https://data.goldenagents.org/datasets/SAA/ontology/isInRecord ; rdf:_2 https://data.goldenagents.org/datasets/SAA/ontology/HuwelijkseVoorwaarden ; rdf:_3 https://data.goldenagents.org/datasets/SAA/ontology/inventoryNumber .","title":"PREDICATE SELECTED [TARGET]  N0: 6"},{"location":"05.LinkConstruction/#predicate-selected-target-n0-7","text":"http://data.goldenagents.org/resource/PredicateSelection-PHb2a681013fbb430 a ll:PropertySelection ; ll:has-entity-selection http://data.goldenagents.org/resource/EntitySelection-PH769c39438419b10 ; ll:has-predicate http://data.goldenagents.org/resource/PH00d91362d72928f . http://data.goldenagents.org/resource/PH00d91362d72928f a ll:SequenceSelection ; rdf:_1 https://data.goldenagents.org/datasets/SAA/ontology/isInRecord ; rdf:_2 https://data.goldenagents.org/datasets/SAA/ontology/Boedelinventaris ; rdf:_3 https://data.goldenagents.org/datasets/SAA/ontology/inventoryNumber .","title":"PREDICATE SELECTED [TARGET]  N0: 7"},{"location":"05.LinkConstruction/#predicate-selected-target-n0-8","text":"http://data.goldenagents.org/resource/PredicateSelection-PH9f7bd41ea902bd0 a ll:PropertySelection ; ll:has-entity-selection http://data.goldenagents.org/resource/EntitySelection-PH769c39438419b10 ; ll:has-predicate http://data.goldenagents.org/resource/PH9f325d76d5fa623 . http://data.goldenagents.org/resource/PH9f325d76d5fa623 a ll:SequenceSelection ; rdf:_1 https://data.goldenagents.org/datasets/SAA/ontology/isInRecord ; rdf:_2 https://data.goldenagents.org/datasets/SAA/ontology/Boedelscheiding ; rdf:_3 https://data.goldenagents.org/datasets/SAA/ontology/inventoryNumber .","title":"PREDICATE SELECTED [TARGET]  N0: 8"},{"location":"05.LinkConstruction/#predicate-selected-source-n0-9","text":"http://data.goldenagents.org/resource/PredicateSelection-PHeb98e7f77b22fce a ll:PropertySelection ; ll:has-entity-selection http://data.goldenagents.org/resource/EntitySelection-PHb97c2bc9d29ba36 ; ll:has-predicate http://data.goldenagents.org/resource/PH22c48ebe6b24223 . http://data.goldenagents.org/resource/PH22c48ebe6b24223 a ll:SequenceSelection ; rdf:_1 https://data.goldenagents.org/datasets/SAA/ontology/isInRecord ; rdf:_2 https://data.goldenagents.org/datasets/SAA/ontology/Inventory ; rdf:_3 https://data.goldenagents.org/datasets/SAA/ontology/registrationDate .","title":"PREDICATE SELECTED [SOURCE]  N0: 9"},{"location":"05.LinkConstruction/#predicate-selected-source-n0-10","text":"http://data.goldenagents.org/resource/PredicateSelection-PHf741a098569afb1 a ll:PropertySelection ; ll:has-entity-selection http://data.goldenagents.org/resource/EntitySelection-PH4ba00e26b03e5dc ; ll:has-predicate http://data.goldenagents.org/resource/PH22c48ebe6b24223 .","title":"PREDICATE SELECTED [SOURCE]  N0: 10"},{"location":"05.LinkConstruction/#predicate-selected-target-n0-11","text":"http://data.goldenagents.org/resource/PredicateSelection-PHee886bb3d021a6a a ll:PropertySelection ; ll:has-entity-selection http://data.goldenagents.org/resource/EntitySelection-PH769c39438419b10 ; ll:has-predicate http://data.goldenagents.org/resource/PHda68158d0b9f392 . http://data.goldenagents.org/resource/PHda68158d0b9f392 a ll:SequenceSelection ; rdf:_1 https://data.goldenagents.org/datasets/SAA/ontology/isInRecord ; rdf:_2 https://data.goldenagents.org/datasets/SAA/ontology/HuwelijkseVoorwaarden ; rdf:_3 https://data.goldenagents.org/datasets/SAA/ontology/registrationDate .","title":"PREDICATE SELECTED [TARGET]  N0: 11"},{"location":"05.LinkConstruction/#predicate-selected-target-n0-12","text":"http://data.goldenagents.org/resource/PredicateSelection-PH715d032180bd40c a ll:PropertySelection ; ll:has-entity-selection http://data.goldenagents.org/resource/EntitySelection-PH769c39438419b10 ; ll:has-predicate http://data.goldenagents.org/resource/PH956023596f37d1b . http://data.goldenagents.org/resource/PH956023596f37d1b a ll:SequenceSelection ; rdf:_1 https://data.goldenagents.org/datasets/SAA/ontology/isInRecord ; rdf:_2 https://data.goldenagents.org/datasets/SAA/ontology/Boedelinventaris ; rdf:_3 https://data.goldenagents.org/datasets/SAA/ontology/registrationDate .","title":"PREDICATE SELECTED [TARGET]  N0: 12"},{"location":"05.LinkConstruction/#predicate-selected-target-n0-13","text":"http://data.goldenagents.org/resource/PredicateSelection-PHe349eb18e5ba638 a ll:PropertySelection ; ll:has-entity-selection http://data.goldenagents.org/resource/EntitySelection-PH769c39438419b10 ; ll:has-predicate http://data.goldenagents.org/resource/PH0ef342da86f3226 . http://data.goldenagents.org/resource/PH0ef342da86f3226 a ll:SequenceSelection ; rdf:_1 https://data.goldenagents.org/datasets/SAA/ontology/isInRecord ; rdf:_2 https://data.goldenagents.org/datasets/SAA/ontology/Boedelscheiding ; rdf:_3 https://data.goldenagents.org/datasets/SAA/ontology/registrationDate .","title":"PREDICATE SELECTED [TARGET]  N0: 13"},{"location":"05.LinkConstruction/#annotated-linkset","text":"","title":"ANNOTATED LINKSET"},{"location":"06.LinkManipulation/","text":".katex img { display: block; position: absolute; width: 100%; height: inherit; } LINK MANIPULATION \u00b6 After generating a number of sets of linksets, one may want to merge, split or filter out some links while others may want to infer new links using existing alignments. The LENS menu provides means for exactly doing that. The LENS menu makes it possible to apply set like operators such as UNION, INTERSECTION, DIFFERENCE, TRANSITIVE and IN-SET over alignments in ways that suit best the user according to her envisaged final integration goal. For the purpose of illustration, we provide two linksets ( ex:DC-Heroes-Identity , ex:Marvel-Heroes-Identity ) of superheroes from the DC and Marvel Universe. According to the metadata of these linksets, they originate from an attempt to de-duplicate the datasets of each universe. This can be observed as the source and target entities composing the links in each linkset are respectively from the same dataset. From the metadata we also observe that, the value of the property void:triples highlights that each linkset is composed of ten identity links. Furthermore, When taking a look at the links within each linkset, the RDF* format of the triples informs that a link validation took place for each link in the set. Theses sets will be used for illustrating the set-like operators discussed in this section. Example 1: Linksets originating from deduplications. ex: DC-Heroes-Identity a void: Linkset ; dcterms: description \"Identifying DC's comics superheroes\" ; ll: subjectsTarget dataset: DC-Comics ; ll: objectsTarget dataset: DC-Comics ; void: triples 10 ; \u2022 \u2022 \u2022 ex: Marvel-Heroes-Identity a void: Linkset ; dcterms: description \"Identifying Marvel Universes' superheroes\" ; ll: subjectsTarget dataset: Marvel-Universe ; ll: objectsTarget dataset: Marvel-Universe ; void: triples 10 ; \u2022 \u2022 \u2022 ex: DC-Heroes-Identity { << hero: Superman owl: sameAs person: Clark-Kent >> validation: status \"accepted\" . << hero: Batman owl: sameAs person: Bruce-Wane >> validation: status \"accepted\" . << hero: Flash owl: sameAs person: Barry-Allen >> validation: status \"accepted\" . << hero: GreenLantern owl: sameAs person: Alan-Scott >> validation: status \"accepted\" . << hero: WonderWoman owl: sameAs person: Diana-Prince >> validation: status \"accepted\" . << hero: Aquaman owl: sameAs person: Arthur-Curry >> validation: status \"accepted\" . << hero: GreenArrow owl: sameAs person: OliverQueen >> validation: status \"accepted\" . << hero: BoosterGold owl: sameAs person: Michael-Jon-Carter >> validation: status \"accepted\" . << hero: Spider-man owl: sameAs person: Peter-Parker >> validation: status \"rejected\" . << hero: Iron-man owl: sameAs person: Tony-Stark >> validation: status \"rejected\" . } ex: Marvel-Heroes-Identity { << hero: Captain-Marvel owl: sameAs person: Carol-Danvers >> validation: status \"accepted\" . << hero: Captain-America owl: sameAs person: Steve-Rogers >> validation: status \"accepted\" . << hero: Deadpool owl: sameAs person: Wade-Wilson >> validation: status \"accepted\" . << hero: Black-Panther owl: sameAs person: T-Challa >> validation: status \"accepted\" . << hero: Spider-man owl: sameAs person: Peter-Parker >> validation: status \"accepted\" . << hero: Iron-man owl: sameAs person: Tony-Stark >> validation: status \"accepted\" . << hero: Ant-man owl: sameAs person: Tony-Stark >> validation: status \"accepted\" . << hero: Black-Widow owl: sameAs person: Natasha-Romanoff >> validation: status \"accepted\" . << hero: Hulk owl: sameAs person: Bruce-Banner >> validation: status \"accepted\" . << hero: Hawkeye owl: sameAs person: Clint-Barton >> validation: status \"accepted\" . } 1. Union \u00b6 Imagine having three linksets ex:Marvel-Heroes-Identity-1 , ex:Marvel-Heroes-Identity-2 and ex:DC-Heroes-Identity . Example 2: Sample of three linksets to merge. ############################################################## # MARVEL: Annotated Linkset of 6 Identity Statements # ############################################################## # Superheroes vs Fictitious-Persons ex: Marvel-Heroes-Identity-1 a void: Linkset ; dcterms: subject \"Fictitious Heroes\" ; dcterms: description \"Identifying Marvel Universes' superheroes\" ; ll: subjectsTarget dataset: Marvel-Universe ; ll: objectsTarget dataset: Marvel-Universe ; void: triples 6 . ex: Marvel-Heroes-Identity-1 { << hero: Black-Widow owl: sameAs person: Natasha-Romanoff >> validation: status true . << person: Bruce-Banner owl: sameAs hero: Hulk >> validation: status true . << hero: Captain-America owl: sameAs person: Steve-Rogers >> validation: status true . << hero: Captain-Marvel owl: sameAs person: Carol-Danvers >> validation: status true . << hero: Deadpool owl: sameAs person: Wade-Wilson >> validation: status true . << hero: Black-Panther owl: sameAs person: T-Challa >> validation: status true . } ############################################################## # MARVEL: Annotated Linkset of 4 Identity Statements # ############################################################## ex: Marvel-Heroes-Identity-2 a void: Linkset ; dcterms: subject \"Fictitious Heroes\" ; dcterms: description \"Identifying Marvel Universes' superheroes\" ; ll: subjectsTarget dataset: Marvel-Universe ; ll: objectsTarget dataset: Marvel-Universe ; void: triples 4 . ex: Marvel-Heroes-Identity-2 { << person: Peter-Parker owl: sameAs hero: Spider-man >> validation: status true . << person: Tony-Stark owl: sameAs hero: Iron-man >> validation: status true . << person: Tony-Stark owl: sameAs hero: Ant-man >> validation: status False . << person: Clint-Barton owl: sameAs hero: Hawkeye >> validation: status true . } ############################################################## # DC-COMICS: Non Annotated Linkset of 10 Identity Statements # ############################################################## ex: DC-Heroes-Identity a void: Linkset ; dcterms: subject \"Fictitious Heroes\" ; dcterms: description \"Identifying DC Comics Universes' superheroes\" ; void: triples 9 . ex: DC-Heroes-Identity { hero: Superman owl: sameAs person: Clark-Kent . hero: Batman owl: sameAs person: Bruce-Wane . hero: GreenLantern owl: sameAs person: Alan-Scott . hero: WonderWoman owl: sameAs person: Diana-Prince . hero: Aquaman owl: sameAs person: Arthur-Curry . hero: GreenArrow owl: sameAs person: OliverQueen . hero: BoosterGold owl: sameAs person: Michael-Jon-Carter . hero: Spider-man owl: sameAs person: Peter-Parker . hero: Iron-man owl: sameAs person: Tony-Stark . } As the above linksets individually make an attempt to align superheroes and fictitious persons in their respective universe, how about unifying these sets as the set of links identifying superheroes in the limited universe of DC and Marvel. To generate such a lens, the UNION set-like operator is required. Using such operator over the three linksets generates the ex:Union-Marvel-DC-Heroes lens. Here, each link is annotated with its provenance as they all originate from one or more linksets. For example, the identity triple hero:Iron-man owl:sameAs person:Tony-Stark is derive from the linksets ex:Marvel-Heroes-Identity-2 and ex:DC-Heroes-Identity . This enables the links in the newly created lens to carry their own annotations while being able to still use the annotations present it their respective linkset of origin (linkset they are derived from). Example 3: UNION of three linksets. With the UNION operator, the same link appearing in various sets (linksets and/or lenses) regardless of its direction is represented only once in the resulting lens of UNION . In a linkset for example, the subject and object targets are explicitly defined. As such, \u27e8 ex:e1 owl:sameAs ex:e2 \u27e9 \\lang \\text{ ex:e1 owl:sameAs ex:e2 } \\rang \u27e8 ex:e1 owl:sameAs ex:e2 \u27e9 and \u27e8 ex:e2 owl:sameAs ex:e1 \u27e9 \\lang \\text{ ex:e2 owl:sameAs ex:e1 } \\rang \u27e8 ex:e2 owl:sameAs ex:e1 \u27e9 are different and stem from different linksets. However, in the resulting UNION , a distinction between the two triples is not explicitly made, meaning that the direction is not of much importance here. This can be observed in the metadata of the union where only the property void:target is used instead of void:subjectsTarget and void:objectsTarget . ### Lens metadata ex: Union-Marvel-DC-Heroes a voidPlus: Lens ; voidPlus: has-lens-operator voidPlus: Union ; dcterms: description \"Identifying superheroes from DC and Marvel Universes'\" ; ll: target ex: Marvel-Heroes-Identity-1 ; ll: target ex: Marvel-Heroes-Identity-2 ; ll: target ex: DC-Heroes-Identity-1 ; void: triples 10 . ### The annotated Lens ex: Union-Marvel-Heroes { << hero: Black-Panther owl: sameAs person: T-Challa >> prov: wasDerivedFrom ex: Marvel-Heroes-Identity-1 . << hero: Black-Widow owl: sameAs person: Natasha-Romanoff >> prov: wasDerivedFrom ex: Marvel-Heroes-Identity-1 . << hero: Captain-America owl: sameAs person: Steve-Rogers >> prov: wasDerivedFrom ex: Marvel-Heroes-Identity-1 . << hero: Captain-Marvel owl: sameAs person: Carol-Danvers >> prov: wasDerivedFrom ex: Marvel-Heroes-Identity-1 . << hero: Deadpool owl: sameAs person: Wade-Wilson >> prov: wasDerivedFrom ex: Marvel-Heroes-Identity-1 . << hero: Hulk owl: sameAs person: Bruce-Banner >> prov: wasDerivedFrom ex: Marvel-Heroes-Identity-1 . << hero: Ant-man owl: sameAs person: Tony-Stark >> prov: wasDerivedFrom ex: Marvel-Heroes-Identity-2 . << hero: Hawkeye owl: sameAs person: Clint-Barton >> prov: wasDerivedFrom ex: Marvel-Heroes-Identity-2 . << hero: Iron-man owl: sameAs person: Tony-Stark >> prov: wasDerivedFrom ex: Marvel-Heroes-Identity-2 ; prov: wasDerivedFrom ex: DC-Heroes-Identity . << hero: Spider-man owl: sameAs person: Peter-Parker >> prov: wasDerivedFrom ex: Marvel-Heroes-Identity-2 ; prov: wasDerivedFrom ex: DC-Heroes-Identity . << hero: Superman owl: sameAs person: Clark-Kent >> prov: wasDerivedFrom ex: Marvel-Heroes-Identity . << hero: Batman owl: sameAs person: Bruce-Wane >> prov: wasDerivedFrom ex: Marvel-Heroes-Identity . << hero: Flash owl: sameAs person: Barry-Allen >> prov: wasDerivedFrom ex: Marvel-Heroes-Identity . << hero: GreenLantern owl: sameAs person: Alan-Scott >> prov: wasDerivedFrom ex: Marvel-Heroes-Identity . << hero: WonderWoman owl: sameAs person: Diana-Prince >> prov: wasDerivedFrom ex: Marvel-Heroes-Identity . << hero: Aquaman owl: sameAs person: Arthur-Curry >> prov: wasDerivedFrom ex: Marvel-Heroes-Identity . << hero: GreenArrow owl: sameAs person: OliverQueen >> prov: wasDerivedFrom ex: Marvel-Heroes-Identity . << hero: BoosterGold owl: sameAs person: Michael-Jon-Carter >> prov: wasDerivedFrom ex: Marvel-Heroes-Identity . } 2. Intersection \u00b6 Intersecting the DC ( ex:DC-Heroes-Identity ) and Marvel ( ex:Marvel-Heroes-Identity ) linksets of superheroes results in ex:Comics-Heroes-Identity , a lens which reveals the only two links shared by the sets. The first link in this lens establishes an identity relation between hero:Spider-man the hero and person:Peter-Parker the fictitious character, while the second link asserts that the superhero hero:Iron-man and the fictitious entity representing Tony Stark are co-referent entities. Example 4: Intersection: Extracting shared links. ex: Comics-Heroes-Identity a voidPlus: Lens ; voidPlus: has-lens-operator voidPlus: Intersection ; dcterms: description \"Quality Check: Identifying superheroes from both Marvel and DC comics\" ; voidPlus: expression \"ex:DC-Heroes-Identity INTERSECTION ex:Marvel-Heroes-Identity\" ; void: target ex: DC-Heroes-Identity , ex: Marvel-Heroes-Identity ; void: triples 4 ; \u2022 \u2022 \u2022 ex: Comics-Heroes-Identity { << hero: Spider-man owl: sameAs person: Peter-Parker >> prov: wasDerivedFrom ex: DC-Heroes-Identity ; prov: wasDerivedFrom ex: Marvel-Heroes-Identity . << hero: Iron-man owl: sameAs person: Tony-Stark >> prov: wasDerivedFrom ex: DC-Heroes-Identity ; prov: wasDerivedFrom ex: Marvel-Heroes-Identity . } 3. Difference \u00b6 Contrarily to the UNION and INTERSECTION operators, the DIFFERENCE operator requires assigning values to the following two properties: void:subjectsTarget and void:objectsTarget . This allows for the explicit and accurate documentation of the lens resulting from performing the Difference manipulation over linksets, lenses or the combination of both a linkset and a lens. This specification is not to put a particular emphasis on the direction of the links instead, it is for knowing the linkset or lens from which the resulting links will stem from. Example 5: DIFFERENCE for extracting triples only existing in void:subjectsTarget . ex: Comics-Heroes-Identity a voidPlus: Lens ; voidPlus: has-lens-operator voidPlus: Difference ; dcterms: description \"Quality Check: Identifying superheroes from both Marvel and DC comics\" ; voidPlus: expression \"ex:DC-Heroes-Identity DIFFERENCE ex:Marvel-Heroes-Identity\" ; void: target ex: DC-Heroes-Identity , ex: Marvel-Heroes-Identity ; void: triples 8 ; \u2022 \u2022 \u2022 ex: DC-Heroes-Identity { << hero: Superman owl: sameAs person: Clark-Kent >> validation: status \"True\" . << hero: Batman owl: sameAs person: Bruce-Wane >> validation: status \"True\" . << hero: Flash owl: sameAs person: Barry-Allen >> validation: status \"True\" . << hero: GreenLantern owl: sameAs person: Alan-Scott >> validation: status \"True\" . << hero: WonderWoman owl: sameAs person: Diana-Prince >> validation: status \"True\" . << hero: Aquaman owl: sameAs person: Arthur-Curry >> validation: status \"True\" . << hero: GreenArrow owl: sameAs person: OliverQueen >> validation: status \"True\" . << hero: BoosterGold owl: sameAs person: Michael-Jon-Carter >> validation: status \"True\" . } 4. Composition \u00b6 5. In Set \u00b6 Imagine being a movie fan particularly interested in knowing more on a set of ten fictional characters carefully handpicked. This intellectual knowledge includes discovering for example knowing in what movies a fictional character played in, what was the rate of the movies, and so on\u2026 Example 6 exhaustively lists these movie characters of interest. Example 6: ex:preference , set of movie characters. ex: preference rdf : _ 4735532571260424746 hero: Captain-Marvel , person: Carol-Danvers , hero: Captain-America , person: Steve-Rogers , hero: Deadpool , person: Wade-Wilson , hero: Black-Panther , person: T-Challa , hero: Spider-man , person: Peter-Parker , hero: Iron-man , person: Tony-Stark , hero: Ant-man , person: Tony-Stark , hero: Black-Widow , person: Natasha-Romanoff , hero: Hulk , person: Bruce-Banner , hero: Hawkeye , person: Clint-Barton . To know more about these handpicked characters, we have isolated ex:MovieInfo , a dataset where information such as movie\u2019s fictional character and movie\u2019s rate are documented. Example 7: ex:MovieCharacter , a movie database. ex: MovieInfo { movie: WonderWoman schema: character hero: WonderWoman ; schema: contentRating 7.4 . movie: WonderWoman-Bloodlines schema: character hero : WonderWoman ; schema: contentRating 5.8 . movie: Superman schema: character hero: Superman ; schema: contentRating 7.3 . movie: Superman-Returns schema: character hero: Superman ; schema: contentRating 6 . movie: Man-of-Steel schema: character hero: Superman ; schema: contentRating 7 . movie: Batman schema: character hero: Batman ; schema: contentRating 7.5 . movie: Batman-Returns schema: character hero: Batman ; schema: contentRating 7 . movie: Batman-Robin schema: character hero: Batman ; schema: contentRating 3.7 . movie: Spider-man schema: character hero: Spider-man ; schema: contentRating 7.3 . movie: The-amazing-Spider-man schema: character hero: Spider-man ; schema: contentRating 6.5 . movie: Spider-man-home-coming schema: character hero: Spider-man ; schema: contentRating 7.4 . } From the dataset ex:MovieInfo , an embedded linkset defined by the link predicate schema:character is extracted and presented in Example 8. In this example, four fictional characters (hero:WonderWoman, Superman, Batman and Spider-man) are linked to various superhero-movies leading to a total of eleven links. Example 8: ex:LinksetMovieCharacter , the movie character linkset. ex: LinksetMovieCharacter { movie: WonderWoman schema: character hero: WonderWoman . movie: WonderWoman-Bloodlines schema: character hero: WonderWoman . movie: Superman schema: character hero: Superman . movie: Superman-Return schema: character hero: Superman . movie: Man-of-Steel schema: character hero: Superman . movie: Batman schema: character hero: Batman . movie: Batman-Returns schema: character hero: Batman . movie: Batman-Robin schema: character hero: Batman . movie: Spider-man schema: character hero: Spider-man . movie: The-amazing-Spider-man schema: character hero: Spider-man . movie: Spider-man-home-coming schema: character hero: Spider-man . } A close look at Example 6 reveals that the set of handpicked characters is a subset of the Marvel Universe. Now, overlaying this set ( ex:preference ) onto the linkset of movie characters ( ex:LinksetMovieCharacter ) implies extracting the links in ex:LinksetMovieCharacter where entities at the subject or object position of the link can be find in ex:preference . Formally, this can be translated into: ex:LinksetMovieCharacter InSet ex:preference . Example 9: Movie Characters from ex:LinksetMovieCharacter that are derived from Marvel\u2019s matched universe set. ex: MovieCharacter { movie: Spider-man schema: character hero: Spider-man . movie: The-amazing-Spider-man schema: character hero: Spider-man . movie: Spider-man-home-coming schema: character hero: Spider-man . }","title":"6. Lens - Link Manipulation"},{"location":"06.LinkManipulation/#link-manipulation","text":"After generating a number of sets of linksets, one may want to merge, split or filter out some links while others may want to infer new links using existing alignments. The LENS menu provides means for exactly doing that. The LENS menu makes it possible to apply set like operators such as UNION, INTERSECTION, DIFFERENCE, TRANSITIVE and IN-SET over alignments in ways that suit best the user according to her envisaged final integration goal. For the purpose of illustration, we provide two linksets ( ex:DC-Heroes-Identity , ex:Marvel-Heroes-Identity ) of superheroes from the DC and Marvel Universe. According to the metadata of these linksets, they originate from an attempt to de-duplicate the datasets of each universe. This can be observed as the source and target entities composing the links in each linkset are respectively from the same dataset. From the metadata we also observe that, the value of the property void:triples highlights that each linkset is composed of ten identity links. Furthermore, When taking a look at the links within each linkset, the RDF* format of the triples informs that a link validation took place for each link in the set. Theses sets will be used for illustrating the set-like operators discussed in this section. Example 1: Linksets originating from deduplications. ex: DC-Heroes-Identity a void: Linkset ; dcterms: description \"Identifying DC's comics superheroes\" ; ll: subjectsTarget dataset: DC-Comics ; ll: objectsTarget dataset: DC-Comics ; void: triples 10 ; \u2022 \u2022 \u2022 ex: Marvel-Heroes-Identity a void: Linkset ; dcterms: description \"Identifying Marvel Universes' superheroes\" ; ll: subjectsTarget dataset: Marvel-Universe ; ll: objectsTarget dataset: Marvel-Universe ; void: triples 10 ; \u2022 \u2022 \u2022 ex: DC-Heroes-Identity { << hero: Superman owl: sameAs person: Clark-Kent >> validation: status \"accepted\" . << hero: Batman owl: sameAs person: Bruce-Wane >> validation: status \"accepted\" . << hero: Flash owl: sameAs person: Barry-Allen >> validation: status \"accepted\" . << hero: GreenLantern owl: sameAs person: Alan-Scott >> validation: status \"accepted\" . << hero: WonderWoman owl: sameAs person: Diana-Prince >> validation: status \"accepted\" . << hero: Aquaman owl: sameAs person: Arthur-Curry >> validation: status \"accepted\" . << hero: GreenArrow owl: sameAs person: OliverQueen >> validation: status \"accepted\" . << hero: BoosterGold owl: sameAs person: Michael-Jon-Carter >> validation: status \"accepted\" . << hero: Spider-man owl: sameAs person: Peter-Parker >> validation: status \"rejected\" . << hero: Iron-man owl: sameAs person: Tony-Stark >> validation: status \"rejected\" . } ex: Marvel-Heroes-Identity { << hero: Captain-Marvel owl: sameAs person: Carol-Danvers >> validation: status \"accepted\" . << hero: Captain-America owl: sameAs person: Steve-Rogers >> validation: status \"accepted\" . << hero: Deadpool owl: sameAs person: Wade-Wilson >> validation: status \"accepted\" . << hero: Black-Panther owl: sameAs person: T-Challa >> validation: status \"accepted\" . << hero: Spider-man owl: sameAs person: Peter-Parker >> validation: status \"accepted\" . << hero: Iron-man owl: sameAs person: Tony-Stark >> validation: status \"accepted\" . << hero: Ant-man owl: sameAs person: Tony-Stark >> validation: status \"accepted\" . << hero: Black-Widow owl: sameAs person: Natasha-Romanoff >> validation: status \"accepted\" . << hero: Hulk owl: sameAs person: Bruce-Banner >> validation: status \"accepted\" . << hero: Hawkeye owl: sameAs person: Clint-Barton >> validation: status \"accepted\" . }","title":"LINK MANIPULATION"},{"location":"06.LinkManipulation/#1-union","text":"Imagine having three linksets ex:Marvel-Heroes-Identity-1 , ex:Marvel-Heroes-Identity-2 and ex:DC-Heroes-Identity . Example 2: Sample of three linksets to merge. ############################################################## # MARVEL: Annotated Linkset of 6 Identity Statements # ############################################################## # Superheroes vs Fictitious-Persons ex: Marvel-Heroes-Identity-1 a void: Linkset ; dcterms: subject \"Fictitious Heroes\" ; dcterms: description \"Identifying Marvel Universes' superheroes\" ; ll: subjectsTarget dataset: Marvel-Universe ; ll: objectsTarget dataset: Marvel-Universe ; void: triples 6 . ex: Marvel-Heroes-Identity-1 { << hero: Black-Widow owl: sameAs person: Natasha-Romanoff >> validation: status true . << person: Bruce-Banner owl: sameAs hero: Hulk >> validation: status true . << hero: Captain-America owl: sameAs person: Steve-Rogers >> validation: status true . << hero: Captain-Marvel owl: sameAs person: Carol-Danvers >> validation: status true . << hero: Deadpool owl: sameAs person: Wade-Wilson >> validation: status true . << hero: Black-Panther owl: sameAs person: T-Challa >> validation: status true . } ############################################################## # MARVEL: Annotated Linkset of 4 Identity Statements # ############################################################## ex: Marvel-Heroes-Identity-2 a void: Linkset ; dcterms: subject \"Fictitious Heroes\" ; dcterms: description \"Identifying Marvel Universes' superheroes\" ; ll: subjectsTarget dataset: Marvel-Universe ; ll: objectsTarget dataset: Marvel-Universe ; void: triples 4 . ex: Marvel-Heroes-Identity-2 { << person: Peter-Parker owl: sameAs hero: Spider-man >> validation: status true . << person: Tony-Stark owl: sameAs hero: Iron-man >> validation: status true . << person: Tony-Stark owl: sameAs hero: Ant-man >> validation: status False . << person: Clint-Barton owl: sameAs hero: Hawkeye >> validation: status true . } ############################################################## # DC-COMICS: Non Annotated Linkset of 10 Identity Statements # ############################################################## ex: DC-Heroes-Identity a void: Linkset ; dcterms: subject \"Fictitious Heroes\" ; dcterms: description \"Identifying DC Comics Universes' superheroes\" ; void: triples 9 . ex: DC-Heroes-Identity { hero: Superman owl: sameAs person: Clark-Kent . hero: Batman owl: sameAs person: Bruce-Wane . hero: GreenLantern owl: sameAs person: Alan-Scott . hero: WonderWoman owl: sameAs person: Diana-Prince . hero: Aquaman owl: sameAs person: Arthur-Curry . hero: GreenArrow owl: sameAs person: OliverQueen . hero: BoosterGold owl: sameAs person: Michael-Jon-Carter . hero: Spider-man owl: sameAs person: Peter-Parker . hero: Iron-man owl: sameAs person: Tony-Stark . } As the above linksets individually make an attempt to align superheroes and fictitious persons in their respective universe, how about unifying these sets as the set of links identifying superheroes in the limited universe of DC and Marvel. To generate such a lens, the UNION set-like operator is required. Using such operator over the three linksets generates the ex:Union-Marvel-DC-Heroes lens. Here, each link is annotated with its provenance as they all originate from one or more linksets. For example, the identity triple hero:Iron-man owl:sameAs person:Tony-Stark is derive from the linksets ex:Marvel-Heroes-Identity-2 and ex:DC-Heroes-Identity . This enables the links in the newly created lens to carry their own annotations while being able to still use the annotations present it their respective linkset of origin (linkset they are derived from). Example 3: UNION of three linksets. With the UNION operator, the same link appearing in various sets (linksets and/or lenses) regardless of its direction is represented only once in the resulting lens of UNION . In a linkset for example, the subject and object targets are explicitly defined. As such, \u27e8 ex:e1 owl:sameAs ex:e2 \u27e9 \\lang \\text{ ex:e1 owl:sameAs ex:e2 } \\rang \u27e8 ex:e1 owl:sameAs ex:e2 \u27e9 and \u27e8 ex:e2 owl:sameAs ex:e1 \u27e9 \\lang \\text{ ex:e2 owl:sameAs ex:e1 } \\rang \u27e8 ex:e2 owl:sameAs ex:e1 \u27e9 are different and stem from different linksets. However, in the resulting UNION , a distinction between the two triples is not explicitly made, meaning that the direction is not of much importance here. This can be observed in the metadata of the union where only the property void:target is used instead of void:subjectsTarget and void:objectsTarget . ### Lens metadata ex: Union-Marvel-DC-Heroes a voidPlus: Lens ; voidPlus: has-lens-operator voidPlus: Union ; dcterms: description \"Identifying superheroes from DC and Marvel Universes'\" ; ll: target ex: Marvel-Heroes-Identity-1 ; ll: target ex: Marvel-Heroes-Identity-2 ; ll: target ex: DC-Heroes-Identity-1 ; void: triples 10 . ### The annotated Lens ex: Union-Marvel-Heroes { << hero: Black-Panther owl: sameAs person: T-Challa >> prov: wasDerivedFrom ex: Marvel-Heroes-Identity-1 . << hero: Black-Widow owl: sameAs person: Natasha-Romanoff >> prov: wasDerivedFrom ex: Marvel-Heroes-Identity-1 . << hero: Captain-America owl: sameAs person: Steve-Rogers >> prov: wasDerivedFrom ex: Marvel-Heroes-Identity-1 . << hero: Captain-Marvel owl: sameAs person: Carol-Danvers >> prov: wasDerivedFrom ex: Marvel-Heroes-Identity-1 . << hero: Deadpool owl: sameAs person: Wade-Wilson >> prov: wasDerivedFrom ex: Marvel-Heroes-Identity-1 . << hero: Hulk owl: sameAs person: Bruce-Banner >> prov: wasDerivedFrom ex: Marvel-Heroes-Identity-1 . << hero: Ant-man owl: sameAs person: Tony-Stark >> prov: wasDerivedFrom ex: Marvel-Heroes-Identity-2 . << hero: Hawkeye owl: sameAs person: Clint-Barton >> prov: wasDerivedFrom ex: Marvel-Heroes-Identity-2 . << hero: Iron-man owl: sameAs person: Tony-Stark >> prov: wasDerivedFrom ex: Marvel-Heroes-Identity-2 ; prov: wasDerivedFrom ex: DC-Heroes-Identity . << hero: Spider-man owl: sameAs person: Peter-Parker >> prov: wasDerivedFrom ex: Marvel-Heroes-Identity-2 ; prov: wasDerivedFrom ex: DC-Heroes-Identity . << hero: Superman owl: sameAs person: Clark-Kent >> prov: wasDerivedFrom ex: Marvel-Heroes-Identity . << hero: Batman owl: sameAs person: Bruce-Wane >> prov: wasDerivedFrom ex: Marvel-Heroes-Identity . << hero: Flash owl: sameAs person: Barry-Allen >> prov: wasDerivedFrom ex: Marvel-Heroes-Identity . << hero: GreenLantern owl: sameAs person: Alan-Scott >> prov: wasDerivedFrom ex: Marvel-Heroes-Identity . << hero: WonderWoman owl: sameAs person: Diana-Prince >> prov: wasDerivedFrom ex: Marvel-Heroes-Identity . << hero: Aquaman owl: sameAs person: Arthur-Curry >> prov: wasDerivedFrom ex: Marvel-Heroes-Identity . << hero: GreenArrow owl: sameAs person: OliverQueen >> prov: wasDerivedFrom ex: Marvel-Heroes-Identity . << hero: BoosterGold owl: sameAs person: Michael-Jon-Carter >> prov: wasDerivedFrom ex: Marvel-Heroes-Identity . }","title":"1. Union"},{"location":"06.LinkManipulation/#2-intersection","text":"Intersecting the DC ( ex:DC-Heroes-Identity ) and Marvel ( ex:Marvel-Heroes-Identity ) linksets of superheroes results in ex:Comics-Heroes-Identity , a lens which reveals the only two links shared by the sets. The first link in this lens establishes an identity relation between hero:Spider-man the hero and person:Peter-Parker the fictitious character, while the second link asserts that the superhero hero:Iron-man and the fictitious entity representing Tony Stark are co-referent entities. Example 4: Intersection: Extracting shared links. ex: Comics-Heroes-Identity a voidPlus: Lens ; voidPlus: has-lens-operator voidPlus: Intersection ; dcterms: description \"Quality Check: Identifying superheroes from both Marvel and DC comics\" ; voidPlus: expression \"ex:DC-Heroes-Identity INTERSECTION ex:Marvel-Heroes-Identity\" ; void: target ex: DC-Heroes-Identity , ex: Marvel-Heroes-Identity ; void: triples 4 ; \u2022 \u2022 \u2022 ex: Comics-Heroes-Identity { << hero: Spider-man owl: sameAs person: Peter-Parker >> prov: wasDerivedFrom ex: DC-Heroes-Identity ; prov: wasDerivedFrom ex: Marvel-Heroes-Identity . << hero: Iron-man owl: sameAs person: Tony-Stark >> prov: wasDerivedFrom ex: DC-Heroes-Identity ; prov: wasDerivedFrom ex: Marvel-Heroes-Identity . }","title":"2. Intersection"},{"location":"06.LinkManipulation/#3-difference","text":"Contrarily to the UNION and INTERSECTION operators, the DIFFERENCE operator requires assigning values to the following two properties: void:subjectsTarget and void:objectsTarget . This allows for the explicit and accurate documentation of the lens resulting from performing the Difference manipulation over linksets, lenses or the combination of both a linkset and a lens. This specification is not to put a particular emphasis on the direction of the links instead, it is for knowing the linkset or lens from which the resulting links will stem from. Example 5: DIFFERENCE for extracting triples only existing in void:subjectsTarget . ex: Comics-Heroes-Identity a voidPlus: Lens ; voidPlus: has-lens-operator voidPlus: Difference ; dcterms: description \"Quality Check: Identifying superheroes from both Marvel and DC comics\" ; voidPlus: expression \"ex:DC-Heroes-Identity DIFFERENCE ex:Marvel-Heroes-Identity\" ; void: target ex: DC-Heroes-Identity , ex: Marvel-Heroes-Identity ; void: triples 8 ; \u2022 \u2022 \u2022 ex: DC-Heroes-Identity { << hero: Superman owl: sameAs person: Clark-Kent >> validation: status \"True\" . << hero: Batman owl: sameAs person: Bruce-Wane >> validation: status \"True\" . << hero: Flash owl: sameAs person: Barry-Allen >> validation: status \"True\" . << hero: GreenLantern owl: sameAs person: Alan-Scott >> validation: status \"True\" . << hero: WonderWoman owl: sameAs person: Diana-Prince >> validation: status \"True\" . << hero: Aquaman owl: sameAs person: Arthur-Curry >> validation: status \"True\" . << hero: GreenArrow owl: sameAs person: OliverQueen >> validation: status \"True\" . << hero: BoosterGold owl: sameAs person: Michael-Jon-Carter >> validation: status \"True\" . }","title":"3. Difference"},{"location":"06.LinkManipulation/#4-composition","text":"","title":"4. Composition"},{"location":"06.LinkManipulation/#5-in-set","text":"Imagine being a movie fan particularly interested in knowing more on a set of ten fictional characters carefully handpicked. This intellectual knowledge includes discovering for example knowing in what movies a fictional character played in, what was the rate of the movies, and so on\u2026 Example 6 exhaustively lists these movie characters of interest. Example 6: ex:preference , set of movie characters. ex: preference rdf : _ 4735532571260424746 hero: Captain-Marvel , person: Carol-Danvers , hero: Captain-America , person: Steve-Rogers , hero: Deadpool , person: Wade-Wilson , hero: Black-Panther , person: T-Challa , hero: Spider-man , person: Peter-Parker , hero: Iron-man , person: Tony-Stark , hero: Ant-man , person: Tony-Stark , hero: Black-Widow , person: Natasha-Romanoff , hero: Hulk , person: Bruce-Banner , hero: Hawkeye , person: Clint-Barton . To know more about these handpicked characters, we have isolated ex:MovieInfo , a dataset where information such as movie\u2019s fictional character and movie\u2019s rate are documented. Example 7: ex:MovieCharacter , a movie database. ex: MovieInfo { movie: WonderWoman schema: character hero: WonderWoman ; schema: contentRating 7.4 . movie: WonderWoman-Bloodlines schema: character hero : WonderWoman ; schema: contentRating 5.8 . movie: Superman schema: character hero: Superman ; schema: contentRating 7.3 . movie: Superman-Returns schema: character hero: Superman ; schema: contentRating 6 . movie: Man-of-Steel schema: character hero: Superman ; schema: contentRating 7 . movie: Batman schema: character hero: Batman ; schema: contentRating 7.5 . movie: Batman-Returns schema: character hero: Batman ; schema: contentRating 7 . movie: Batman-Robin schema: character hero: Batman ; schema: contentRating 3.7 . movie: Spider-man schema: character hero: Spider-man ; schema: contentRating 7.3 . movie: The-amazing-Spider-man schema: character hero: Spider-man ; schema: contentRating 6.5 . movie: Spider-man-home-coming schema: character hero: Spider-man ; schema: contentRating 7.4 . } From the dataset ex:MovieInfo , an embedded linkset defined by the link predicate schema:character is extracted and presented in Example 8. In this example, four fictional characters (hero:WonderWoman, Superman, Batman and Spider-man) are linked to various superhero-movies leading to a total of eleven links. Example 8: ex:LinksetMovieCharacter , the movie character linkset. ex: LinksetMovieCharacter { movie: WonderWoman schema: character hero: WonderWoman . movie: WonderWoman-Bloodlines schema: character hero: WonderWoman . movie: Superman schema: character hero: Superman . movie: Superman-Return schema: character hero: Superman . movie: Man-of-Steel schema: character hero: Superman . movie: Batman schema: character hero: Batman . movie: Batman-Returns schema: character hero: Batman . movie: Batman-Robin schema: character hero: Batman . movie: Spider-man schema: character hero: Spider-man . movie: The-amazing-Spider-man schema: character hero: Spider-man . movie: Spider-man-home-coming schema: character hero: Spider-man . } A close look at Example 6 reveals that the set of handpicked characters is a subset of the Marvel Universe. Now, overlaying this set ( ex:preference ) onto the linkset of movie characters ( ex:LinksetMovieCharacter ) implies extracting the links in ex:LinksetMovieCharacter where entities at the subject or object position of the link can be find in ex:preference . Formally, this can be translated into: ex:LinksetMovieCharacter InSet ex:preference . Example 9: Movie Characters from ex:LinksetMovieCharacter that are derived from Marvel\u2019s matched universe set. ex: MovieCharacter { movie: Spider-man schema: character hero: Spider-man . movie: The-amazing-Spider-man schema: character hero: Spider-man . movie: Spider-man-home-coming schema: character hero: Spider-man . }","title":"5. In Set"},{"location":"07.LinkVisualisation/","text":"Visualisation Support for Identity Network \u00b6","title":"7. Visualising link Network"},{"location":"07.LinkVisualisation/#visualisation-support-for-identity-network","text":"","title":"Visualisation Support for Identity Network"},{"location":"08.LinkValidation/","text":"LINK VALIDATION \u00b6 Imagine a researcher in the need of integrating data on publications, authors and education institutions. Wrongly executing this integration task could mean, for example, assigning the h-index of author A to author B or wrongly saying that author A is affiliated to an institution he has never been involved with. Hardly any matching algorithm returns only perfect results. In light of this, to reach a solid investigation result, it is of importance to support human validation once links have been created and optionally improved. 1. Validation and Links\u2019 Context \u00b6 intrinsic properties the purpose or task for which the links are used. 2. Voting Strategies \u00b6 In the Semantic Web, the standard semantic OWL/DL interpretation of identity between two resources entails full equality , i.e. they are necessarily the same and share all their properties. Such semantic applies independently of context and therefore no validation or dispute apply since that semantic does not take any of it into account: things are either the same or they are not. [ Idrissou 2017 ] In real life problems, the equality between resources may depend (i) not only on their intrinsic properties (ii) but also on the purpose or task for which they are used. For example, an organisation A and B are the same in context 1 but not not the same in context 2. Instead of the rigid owl:sameAs standard semantics, if an alternative semantics is considered where context is taken into account, then things can be the same or not depending on the context that applies. Moreover, within a common context there can still be divergences when, for example, there is not enough information for reaching a correct (indisputable) outcome. In other words, for the same identity link, multiple \u201ctruths\u201d (multiple possible interpretations) can co-exist once we agree on the context in which these \u201ctruths\u201d are cast. As a result, the Lenticular Lens tool allows for a single link to be both (i) established within a context and (ii) validated countless times, and then, by continuity, it allows for a collection of links (linkset or lens) to have various validations by different users. Even thought this is a desirable feature, before using the links for integration one needs to make a decision about their validity. This brings us to what we denote as Voting which is the merging of Validations sharing the same context. The Lenticular Lens tool provides five ways for merging validations. These include: Accepted Once , Rejected Once , Majority , Disputed , Weighted Experts. and Highest Ranking Experts . In the next section, we discuss the aforementioned options. 2.1 Consistent Validations \u00b6 This is the best scenario. A link has been validated several times with the same outcome, meaning not once a contradiction has occurred. The validation is consistent and therefore remains as it is. 2.2 Disputed Validations \u00b6 Disputes occur when a link has been validated several times but with contradicting truth statements (inconsistently). For example, when a links has been ACCEPTED three times but REJECTED twice. In this scenario, we follow a simple protocol: The link with contradicting validations is flagged as DISPUTED . The following options can be chosen for reaching an agreement: Accepted Once. Consider the link as ACCEPTED if it has been accepted at least once. Rejected Once. Consider the link as REJECTED if it has been rejected at least once. Majority. Consider the link as ACCEPTED if it has been accepted more times than being rejected, otherwise consider the link as REJECTED . Weighted Experts. In this situation, a weighted sum is performed within each voting group ( ACCEPTED vs REJECTED ). The group with the highest weighted sum gets to cast its vote. Highest Ranking Experts. Deciding on how to merge several validations on the basis of the authority with the highest rank is also possible. The decision to accept or reject the link is solely made by the highest ranking expert. It is easy to see here that there can be still disputes among highest ranked experts. In this case, the majority among experts applies. No matter the option, in the event of a tie , the link is REJECTED unless stated otherwise by the user. 3. Validation Support \u00b6 3.1 Individual Validation \u00b6 3.2 Group Validation \u00b6 Linkset \u00b6 Lens \u00b6 Cluster-based validation \u00b6 3.3 Visualisation \u00b6","title":"8. Link Validation"},{"location":"08.LinkValidation/#link-validation","text":"Imagine a researcher in the need of integrating data on publications, authors and education institutions. Wrongly executing this integration task could mean, for example, assigning the h-index of author A to author B or wrongly saying that author A is affiliated to an institution he has never been involved with. Hardly any matching algorithm returns only perfect results. In light of this, to reach a solid investigation result, it is of importance to support human validation once links have been created and optionally improved.","title":"LINK VALIDATION"},{"location":"08.LinkValidation/#1-validation-and-links-context","text":"intrinsic properties the purpose or task for which the links are used.","title":"1. Validation and Links' Context"},{"location":"08.LinkValidation/#2-voting-strategies","text":"In the Semantic Web, the standard semantic OWL/DL interpretation of identity between two resources entails full equality , i.e. they are necessarily the same and share all their properties. Such semantic applies independently of context and therefore no validation or dispute apply since that semantic does not take any of it into account: things are either the same or they are not. [ Idrissou 2017 ] In real life problems, the equality between resources may depend (i) not only on their intrinsic properties (ii) but also on the purpose or task for which they are used. For example, an organisation A and B are the same in context 1 but not not the same in context 2. Instead of the rigid owl:sameAs standard semantics, if an alternative semantics is considered where context is taken into account, then things can be the same or not depending on the context that applies. Moreover, within a common context there can still be divergences when, for example, there is not enough information for reaching a correct (indisputable) outcome. In other words, for the same identity link, multiple \u201ctruths\u201d (multiple possible interpretations) can co-exist once we agree on the context in which these \u201ctruths\u201d are cast. As a result, the Lenticular Lens tool allows for a single link to be both (i) established within a context and (ii) validated countless times, and then, by continuity, it allows for a collection of links (linkset or lens) to have various validations by different users. Even thought this is a desirable feature, before using the links for integration one needs to make a decision about their validity. This brings us to what we denote as Voting which is the merging of Validations sharing the same context. The Lenticular Lens tool provides five ways for merging validations. These include: Accepted Once , Rejected Once , Majority , Disputed , Weighted Experts. and Highest Ranking Experts . In the next section, we discuss the aforementioned options.","title":"2. Voting Strategies"},{"location":"08.LinkValidation/#21-consistent-validations","text":"This is the best scenario. A link has been validated several times with the same outcome, meaning not once a contradiction has occurred. The validation is consistent and therefore remains as it is.","title":"2.1 Consistent Validations"},{"location":"08.LinkValidation/#22-disputed-validations","text":"Disputes occur when a link has been validated several times but with contradicting truth statements (inconsistently). For example, when a links has been ACCEPTED three times but REJECTED twice. In this scenario, we follow a simple protocol: The link with contradicting validations is flagged as DISPUTED . The following options can be chosen for reaching an agreement: Accepted Once. Consider the link as ACCEPTED if it has been accepted at least once. Rejected Once. Consider the link as REJECTED if it has been rejected at least once. Majority. Consider the link as ACCEPTED if it has been accepted more times than being rejected, otherwise consider the link as REJECTED . Weighted Experts. In this situation, a weighted sum is performed within each voting group ( ACCEPTED vs REJECTED ). The group with the highest weighted sum gets to cast its vote. Highest Ranking Experts. Deciding on how to merge several validations on the basis of the authority with the highest rank is also possible. The decision to accept or reject the link is solely made by the highest ranking expert. It is easy to see here that there can be still disputes among highest ranked experts. In this case, the majority among experts applies. No matter the option, in the event of a tie , the link is REJECTED unless stated otherwise by the user.","title":"2.2 Disputed Validations"},{"location":"08.LinkValidation/#3-validation-support","text":"","title":"3. Validation Support"},{"location":"08.LinkValidation/#31-individual-validation","text":"","title":"3.1 Individual Validation"},{"location":"08.LinkValidation/#32-group-validation","text":"","title":"3.2 Group Validation"},{"location":"08.LinkValidation/#linkset","text":"","title":"Linkset"},{"location":"08.LinkValidation/#lens","text":"","title":"Lens"},{"location":"08.LinkValidation/#cluster-based-validation","text":"","title":"Cluster-based validation"},{"location":"08.LinkValidation/#33-visualisation","text":"","title":"3.3 Visualisation"},{"location":"09.LinkExport/","text":".katex img { display: block; position: absolute; width: 100%; height: inherit; } LINK EXPORT \u00b6 At this point, linksets and/or Lenses have already been created and possibly validated. Now, new interesting questions come in mind: Could these links be exported for external usage? In what format are there available for export? Can metadata be exported in combination with the links? Can the linktype be modified prior to an export? All these questions will be answered here. 1. Link Metadata Structure \u00b6 The Lenticular Lens design imposes to itself and motivates its users to provide as much explicit settings as possible in support for describing why (clarity) and how (reproducibility) a set of links has been generated. Links metadata in the tool is organised into Generic and Specific metadata. Indeed, all links residing in the Lenticular Lens can be exported. However, prior to doing that, one has to choose whether the metadata is to be included or not. If it is to be included, further directives are needed as to whether it should include Generic and/or Specific metadata. Specific metadata is the annotation that applies to a single link. Generic metadata is the annotation that applies to a collection of links as a whole. 1.1 Specific Metadata \u00b6 Example-1 presents in a turtle format, a standard identity set of nine links where equivalent resources are linked with the well known linktype owl:sameAs . As shown in this example, the links are meant to reside in the default graph of a triplestore as no named graph is explicitly associated to them. Example 1: Unnamed identity-set. hero: BlackWidow owl: sameAs person: Nat . hero: BlackWidow owl: sameAs person: Romanoff . hero: BlackWidow owl: sameAs person: Natalia-Romanova . hero: BlackWidow owl: sameAs person: Natasha . hero: Spiderman owl: sameAs person: Peter-parker . hero: Spiderman owl: sameAs person: Tom-Holland . hero: Superman owl: sameAs person: Clark-Kent . hero: Superman owl: sameAs person: Joseph . hero: Superman owl: sameAs person: Kal-El . In Example-2, the triples of Example-1 are now presented with specific annotations . With this type of annotation, one can for example specify the confidence strength of each of the nine triples. In new example, seven out of the nine links are now annotated with a validation statement. The triple hero:Spiderman owl:sameAs person:Tom-Holland for example is the only triple annotated as a non valid statement followed by the rational supporting its rejection. Another added value beside being able to make new statements about a link is that, the annotation itself can be used as a way of filtering links. For example, one can select for example, the 8 validated triples or the 7 triples validated as \u201ctrue\u201d. Example 2: Annotation of individual links. << hero: BlackWidow owl: sameAs person: Nat >> validation: status \"True\" . << hero: BlackWidow owl: sameAs person: Romanoff >> validation: status \"True\" . << hero: BlackWidow owl: sameAs person: Natalia-Romanova >> validation: status \"True\" . << hero: BlackWidow owl: sameAs person: Natasha >> validation: status \"True\" . << hero: Spiderman owl: sameAs person: Peter-parker >> validation: status \"True\" . << hero: Spiderman owl: sameAs person: Tom-Holland >> validation: status \"False\" . validation: Rational \"Tom-Holland does not have Spiderman properties which Peter-parker (fictitious) a.k.a Spiderman has.\" . << hero: Superman owl: sameAs person: Clark-Kent >> validation: status \"True\" . << hero: Superman owl: sameAs person: Joseph >> validation: status \"True\" . hero: Superman owl: sameAs person: Kal-El . 1.2 Generic Metadata \u00b6 The set of links illustrated in Example-1 as triples populating the default graph can now be referred to as ex:heroes-Identity in Example-3 as they have now been grouped in this named-graph. As illustrated in Example-4, this named-graph IRI can now be used to document any generic information deemed relevant such as the source and target datasets, the aligning method\u2026 As opposed to Example-1 and Example-2, Example-3 highlights that in need of generic metadata , links in the spotlight need a referent to be annotated. In other words, there is no need to export the links in a named graph (.trig extension) when meta data is not required by the user . However, there is a grate advantage when need is to gather all links at once. Example 3: Named identity-set. . ex: heroes-Identity { hero: BlackWidow owl: sameAs person: Nat . hero: BlackWidow owl: sameAs person: Romanoff . hero: BlackWidow owl: sameAs person: Natalia-Romanova . hero: BlackWidow owl: sameAs person: Natasha . hero: Spiderman owl: sameAs person: Peter-parker . hero: Spiderman owl: sameAs person: Tom-Holland . hero: Superman owl: sameAs person: Clark-Kent . hero: Superman owl: sameAs person: Joseph . hero: Superman owl: sameAs person: Kal-El . } Example-4: Annotation of a set of links in the Lenticular Lens. Generic Metadata. The linkset ex:heroes-Identity is presented with both generic and specific metadata. The generic metadata in the default graph (triple without a specific named graph) conveys information about the identity set: ex:heroes-Identity . This information includes among other, the type, subjects, license, description, format, number of triples (9), number of distinct entities (12), number of identity clusters (3)\u2026 As stated in the generic metadata of ex:heroes-Identity , the linkset contains 9 triples. Of these triples, the metadata informs us that 7 are validated as accepted, one as rejected and another one as remains (not validated). ex: heroes-Identity a void: Linkset ; dcterms: description \"Identifying Marvel's superheroes\" ; dcterms: license law: odc-public-domain-dedication-and-licence ; dcterms: subject <http://example.org/resource/Person> ; dcterms: subject <http://example.org/resource/Hero> ; void: subjectsTarget dataset: Fictive-Persons ; void: objectsTarget dataset: Superheroes ; void: feature format: Turtle ; void: linkPredicate owl: sameAs ; void: triples 9 ; void: entities 12 ; void: distinctSubjects 3 ; void: distinctObjects 9 ; voidPlus: clusters 3 ; validation: count 8 ; validation: accepted 7 ; validation: rejected 1 ; validation: remains 1 ; 1.3 Complete Metadata \u00b6 Example-3 illustrates the complete structure of linksets and lenses in the Lenticular Lens . Here, by default, a linkset/lens is annotated with both, generic and specific metadata. Example 5: Complete metadata in RDF* turtle syntax annotation. ex: heroes-Identity a void: Linkset ; dcterms: description \"Identifying Marvel's superheroes\" ; dcterms: license law: odc-public-domain-dedication-and-licence ; dcterms: subject <http://example.org/resource/Person> ; dcterms: subject <http://example.org/resource/Hero> ; void: subjectsTarget dataset: Fictive-Persons ; void: objectsTarget dataset: Superheroes ; void: feature format: Turtle ; void: linkPredicate owl: sameAs ; void: triples 9 ; void: entities 12 ; void: distinctSubjects 3 ; void: distinctObjects 9 ; voidPlus: clusters 3 ; validation: count 8 ; validation: accepted 7 ; validation: rejected 1 ; validation: remains 1 ; ex: heroes-Identity { << hero: BlackWidow owl: sameAs person: Nat >> validation: status \"True\" . << hero: BlackWidow owl: sameAs person: Romanoff >> validation: status \"True\" . << hero: BlackWidow owl: sameAs person: Natalia-Romanova >> validation: status \"True\" . << hero: BlackWidow owl: sameAs person: Natasha >> validation: status \"True\" . << hero: Spiderman owl: sameAs person: Peter-parker >> validation: status \"True\" . << hero: Spiderman owl: sameAs person: Tom-Holland >> validation: status \"False\" . validation: Rational \"Tom-Holland does not have Spiderman properties which Peter-parker (fictitious) a.k.a Spiderman has.\" . << hero: Superman owl: sameAs person: Clark-Kent >> validation: status \"True\" . << hero: Superman owl: sameAs person: Joseph >> validation: status \"True\" . hero: Superman owl: sameAs person: Kal-El . } Separation of Concern. The linkset and lens presentation enable separation of concern in the sense that it provides the user with a number of options: Flat Representation: No reified triples and optionally within a named graph. Partial Representation: Choice of exclusively including either the generic or the specific metadata. Full Representation: as intended in the Lenticular Lens , set of links comes along with its generic and specific metadata if applicable. 2. RDF Link Reifications \u00b6 The verb reify is defined in Lexico , the Oxford supported dictionary, as a way to make (something abstract) more concrete or real . In RDF \u2013 a data model that allows for the description of a resource (subject position of a triple) in the form \u27e8 subject predicate object. \u27e9 \\lang \\text{subject predicate object.} \\rang \u27e8 subject predicate object. \u27e9 \u2013, reification offers means to define a triple as a resource as such that the triple could be described . Several reification approaches exist: N-ary relations, RDF reification, Rdfstar and Singleton properties. In the next subsections we briefly describe them. 2.1 N-ary relations \u00b6 The [ N-ary relations ] syntax provides a means to model a non binary relation, a relation that holds among more than two objects, as an object itself. Example 6: The Purchase relation into an N-ary relations. : Purchase_1 a : Purchase ; : has_buyer : John ; : has_object : Lenny_The_Lion ; : has_purpose : Birthday_Gift ; : has_amount 15 ; : has_seller : books . example . com . 2.2 Standard reification \u00b6 RDF reification is the standard reification proposed by W3C . As depicted in Example-6, it introduces a new resource of type rdf:Statement and three predicates to identify the rdf:subject, rdf:predicate, and rdf:object of the reified triple. Example 7: Standard RDF reification. ### BlackWidow Triple. hero: BlackWidow owl: sameAs person: Nat . ### Standard RDF reification of BlackWidow Triple ex: reification-1 rdf: type rdf: Statement ; rdf: subject hero: BlackWidow ; rdf: predicate owl: sameAs ; rdf: object person: Nat ; validation: status \"True\" . 2.3 Singleton \u00b6 The [ Singleton properties ] approach offers the latitude to make uniquely identifiable the predicate of the triple to reified where the new property is an rdf:singletonPropertyOf a more generic property Example 8: Singleton. ### BlackWidow Triple. hero: BlackWidow owl: sameAs person: Nat . ### Modification of BlackWidow Triple. hero: BlackWidow singleton: sameAs-1 person: Nat . ### Singleton reification of BlackWidow Triple. singleton: sameAs-1 rdf: type rdf: SingletonProperty ; rdf: singletonPropertyOf owl: sameAs . validation: status \"True\" . 2.4 RDFstar \u00b6 RDF * : An in-line simple reification syntax that requires RDF * and SPARQL * . Example 9: RDFstar / RDF * . ### BlackWidow Triple. hero: BlackWidow owl: sameAs person: Nat . ### RDFstar reification BlackWidow Triple. << hero: BlackWidow owl: sameAs person: Nat >> validation: status \"True\" . 3. Export Formats \u00b6 The Lenticular Lens offers a variety of four file formats for exporting a collection of links. These are: CSV (Example-10), JSON-LD (Example-11), RDF Turtle (Example-12), and RDF* Turtle (Example-13). 3.1 CSV file format \u00b6 In our attend to export a linkset/lens with its complete metadata, in a CSV format, the Lenticular Lens generates two CSV tables. As available in Example-9, the first table is an illustration of a linkset generic metadata while the second table is an illustration of links with specific metadata (annotated triples). Example 10: Linkset in a CSV format. Keep in mind that the table below are a visual representation of a CSV table -------------------- -- METADATA TABLE -- -------------------- --------------------------------------------------------------------------------------------------------- | Vocabulary Value | --------------------------------------------------------------------------------------------------------- http : //www . w 3 . org/ns/sparql-service-description #namedGraph http://example.org/#heroesIdentity http : //www . w 3 . org/ 1999 / 02 / 22 -rdf-syntax-ns #type http://rdfs.org/ns/void#Linkset http : //purl . org/dc/terms/description Identifying Marvel 's superheroes http : //purl . org/dc/terms/license law: odc-public-domain-dedication-and-licence http : //purl . org/dc/terms/subject http : //example . org/resource/Person http : //purl . org/dc/terms/subject http : //example . org/resource/Hero http : //rdfs . org/ns/void #subjectsTarget dataset:Fictive-Persons http : //rdfs . org/ns/void #objectsTarget dataset:Superheroes http : //rdfs . org/ns/void #feature format:Turtle http : //rdfs . org/ns/void #linkPredicate owl:sameAs http : //rdfs . org/ns/void #triples 9 http : //rdfs . org/ns/void #entities 12 http : //rdfs . org/ns/void #distinctSubjects 3 http : //rdfs . org/ns/void #distinctObjects 9 http : //vocabulary/voidPlus #clusters 3 http : //vocabulary/validation #count 8 http : //vocabulary/validation #accepted 7 http : //vocabulary/validation #rejected 1 http : //vocabulary/validation #remains 1 ------------------------ -- LINKSET/LENS TABLE -- ------------------------ ------------------------------------------------------------------------------------------------------------------------------------------------ | NamedGraph Source Target ValStatus ValRational | ------------------------------------------------------------------------------------------------------------------------------------------------ http : //example . org/ #heroesIdentity http://example.org/hero#BlackWidow http://example.org/person#Nat True http : //example . org/ #heroesIdentity http://example.org/hero#BlackWidow http://example.org/person#Romanoff True http : //example . org/ #heroesIdentity http://example.org/hero#BlackWidow http://example.org/person#Natalia-Romanova True http : //example . org/ #heroesIdentity http://example.org/hero#BlackWidow http://example.org/person#Natasha True http : //example . org/ #heroesIdentity http://example.org/hero#Spiderman http://example.org/person#Peter-parker True http : //example . org/ #heroesIdentity http://example.org/hero#Spiderman http://example.org/person#Tom-Holland False Tom-Holland does not have Spiderman properties which Peter-parker (fictitious) a.k.a Spiderman has. http : //example . org/ #heroesIdentity http://example.org/hero#Superman http://example.org/person#Clark-Kent True http : //example . org/ #heroesIdentity http://example.org/hero#Superman http://example.org/person#Joseph True http : //example . org/ #heroesIdentity http://example.org/hero#Superman http://example.org/person#Kal-El True 3.2 JSON-LD file format \u00b6 JSON-LD OUTPUT. TODO.... Example 11 Linkset in a JSON-LD format.. { \"@context\" : { \"name\" : \"http://xmlns.com/foaf/0.1/name\" , \"homepage\" : { \"@id\" : \"http://xmlns.com/foaf/0.1/workplaceHomepage\" , \"@type\" : \"@id\" }, \"Person\" : \"http://xmlns.com/foaf/0.1/Person\" }, \"@id\" : \"https://me.example.com\" , \"@type\" : \"Person\" , \"name\" : \"John Smith\" , \"homepage\" : \"https://www.example.com/\" } 3.3 RDF file formats \u00b6 Knowing the right RDF file format in which to export a collection of links depends on a number of parameters. Depending on whether the collection of links is unnamed , named and/or annotated , one can respectively have the export output in Turtle or Trig . A Trig file implies a named graph but it says little about the reification approach taken for annotating individual triples or the graph of collection. In the event of annotation, one can choose whether to go for an RDF standard reification , singleton properties or RDFstar . In this pile of options, our choice goes for always having a named-graph reified using the RDFstar syntax if one has RDF * and SPAQRL * in place. If not, our second option goes for singletons . Example 12: n Linkset in an RDF Turtle format using singletons. Our preference goes to an RDF* Turtle Output as illustrated in Example-6. However, because RDF* is not deployed on all triple stores, we provide the singleton, and RDF standard reification representation alternatives as well. An example of singletons in available here. ex: heroes-Identity a void: Linkset ; dcterms: description \"Identifying Marvel's heroes\" ; dcterms: license law: odc-public-domain-dedication-and-licence ; dcterms: subject <http://example.org/resource/Person> ; dcterms: subject <http://example.org/resource/Hero> ; void: subjectsTarget dataset: Fictive-Persons ; void: objectsTarget dataset: Superheroes ; void: feature format: Turtle ; void: linkPredicate owl: sameAs ; void: triples 9 ; void: entities 12 ; void: distinctSubjects 3 ; void: distinctObjects 9 ; voidPlus: clusters 3 ; validation: count 8 ; validation: accepted 7 ; validation: rejected 1 ; validation: remains 1 ; ex: heroes-Identity { hero: BlackWidow singleton: sameAs-1 person: Nat . hero: BlackWidow singleton: sameAs-2 person: Romanoff . hero: BlackWidow singleton: sameAs-3 person: Natalia-Romanova . hero: BlackWidow singleton: sameAs-4 person: Natasha . hero: Spiderman singleton: sameAs-5 person: Peter-parker . hero: Spiderman singleton: sameAs-6 person: Tom-Holland . hero: Superman singleton: sameAs-7 person: Clark-Kent . hero: Superman singleton: sameAs-8 person: Joseph . hero: Superman singleton: sameAs-9 person: Kal-El . } ex: heroes-Identity-singletons { singleton: sameAs-1 rdf: subPropertyOf owl: sameAs ; validation: status \"True\" . singleton: sameAs-2 rdf: subPropertyOf owl: sameAs ; validation: status \"True\" . singleton: sameAs-3 rdf: subPropertyOf owl: sameAs ; validation: status \"True\" . singleton: sameAs-4 rdf: subPropertyOf owl: sameAs ; validation: status \"True\" . singleton: sameAs-5 rdf: subPropertyOf owl: sameAs ; validation: status \"True\" . singleton: sameAs-1 rdf: subPropertyOf owl: sameAs ; validation: status \"True\" . singleton: sameAs-1 rdf: subPropertyOf owl: sameAs ; validation: status \"True\" . hero: Superman owl: sameAs person: Kal-El . singleton: sameAs-6 rdf: subPropertyOf owl: sameAs ; validation: status \"False\" ; validation: Rational \"Tom-Holland does not have Spiderman properties which Peter-parker (fictitious) a.k.a Spiderman has.\" . } 4. Link Restrictions \u00b6 Whenever links are annotated, the Lenticular Lens offers a way to take advantage of it. It provides the user with options to filter out links of no interest, an alternative to the inconvenience of having to download all links when not needed. Example-12 lists all possible link restrictions options. For example to make sure that only accepted links are exported, the options Accepted is chosen in Example-12. Example 13: Link Restrictions Options. All : Export all links Accepted : Export only accepted links. Rejected : Export only rejected links. Validated : Export rejected or validated links Not Validated : Export links with no accepted or rejected annotation. Threshold : Export links that pass a predefined threshold condition. This feature applies to links annotated with confidence values. 5. Default Export Table \u00b6 Example-14 summarises the various options for exporting a linkset or lens. In each set of selection category, a default selection is checked in. This means that, by default, an exported linkset or lens comes along with all its links and its complete annotation in a CSV format . Example 13: Export Table. METADATA STRUCTURE RDF REIFICATION SYNTAX LINK EXPORT FORMAT LINK RESTRICTIONS Partial:Generic Standard RDF reification RDF Turtle-trig All Partial:Specific RDFstar RDF Turtle Accepted Singleton JSON-LD Rejected CSV Validated Not Validated Threshold","title":"9. Link Export"},{"location":"09.LinkExport/#link-export","text":"At this point, linksets and/or Lenses have already been created and possibly validated. Now, new interesting questions come in mind: Could these links be exported for external usage? In what format are there available for export? Can metadata be exported in combination with the links? Can the linktype be modified prior to an export? All these questions will be answered here.","title":"LINK EXPORT"},{"location":"09.LinkExport/#1-link-metadata-structure","text":"The Lenticular Lens design imposes to itself and motivates its users to provide as much explicit settings as possible in support for describing why (clarity) and how (reproducibility) a set of links has been generated. Links metadata in the tool is organised into Generic and Specific metadata. Indeed, all links residing in the Lenticular Lens can be exported. However, prior to doing that, one has to choose whether the metadata is to be included or not. If it is to be included, further directives are needed as to whether it should include Generic and/or Specific metadata. Specific metadata is the annotation that applies to a single link. Generic metadata is the annotation that applies to a collection of links as a whole.","title":"1. Link Metadata Structure"},{"location":"09.LinkExport/#11-specific-metadata","text":"Example-1 presents in a turtle format, a standard identity set of nine links where equivalent resources are linked with the well known linktype owl:sameAs . As shown in this example, the links are meant to reside in the default graph of a triplestore as no named graph is explicitly associated to them. Example 1: Unnamed identity-set. hero: BlackWidow owl: sameAs person: Nat . hero: BlackWidow owl: sameAs person: Romanoff . hero: BlackWidow owl: sameAs person: Natalia-Romanova . hero: BlackWidow owl: sameAs person: Natasha . hero: Spiderman owl: sameAs person: Peter-parker . hero: Spiderman owl: sameAs person: Tom-Holland . hero: Superman owl: sameAs person: Clark-Kent . hero: Superman owl: sameAs person: Joseph . hero: Superman owl: sameAs person: Kal-El . In Example-2, the triples of Example-1 are now presented with specific annotations . With this type of annotation, one can for example specify the confidence strength of each of the nine triples. In new example, seven out of the nine links are now annotated with a validation statement. The triple hero:Spiderman owl:sameAs person:Tom-Holland for example is the only triple annotated as a non valid statement followed by the rational supporting its rejection. Another added value beside being able to make new statements about a link is that, the annotation itself can be used as a way of filtering links. For example, one can select for example, the 8 validated triples or the 7 triples validated as \u201ctrue\u201d. Example 2: Annotation of individual links. << hero: BlackWidow owl: sameAs person: Nat >> validation: status \"True\" . << hero: BlackWidow owl: sameAs person: Romanoff >> validation: status \"True\" . << hero: BlackWidow owl: sameAs person: Natalia-Romanova >> validation: status \"True\" . << hero: BlackWidow owl: sameAs person: Natasha >> validation: status \"True\" . << hero: Spiderman owl: sameAs person: Peter-parker >> validation: status \"True\" . << hero: Spiderman owl: sameAs person: Tom-Holland >> validation: status \"False\" . validation: Rational \"Tom-Holland does not have Spiderman properties which Peter-parker (fictitious) a.k.a Spiderman has.\" . << hero: Superman owl: sameAs person: Clark-Kent >> validation: status \"True\" . << hero: Superman owl: sameAs person: Joseph >> validation: status \"True\" . hero: Superman owl: sameAs person: Kal-El .","title":"1.1 Specific Metadata"},{"location":"09.LinkExport/#12-generic-metadata","text":"The set of links illustrated in Example-1 as triples populating the default graph can now be referred to as ex:heroes-Identity in Example-3 as they have now been grouped in this named-graph. As illustrated in Example-4, this named-graph IRI can now be used to document any generic information deemed relevant such as the source and target datasets, the aligning method\u2026 As opposed to Example-1 and Example-2, Example-3 highlights that in need of generic metadata , links in the spotlight need a referent to be annotated. In other words, there is no need to export the links in a named graph (.trig extension) when meta data is not required by the user . However, there is a grate advantage when need is to gather all links at once. Example 3: Named identity-set. . ex: heroes-Identity { hero: BlackWidow owl: sameAs person: Nat . hero: BlackWidow owl: sameAs person: Romanoff . hero: BlackWidow owl: sameAs person: Natalia-Romanova . hero: BlackWidow owl: sameAs person: Natasha . hero: Spiderman owl: sameAs person: Peter-parker . hero: Spiderman owl: sameAs person: Tom-Holland . hero: Superman owl: sameAs person: Clark-Kent . hero: Superman owl: sameAs person: Joseph . hero: Superman owl: sameAs person: Kal-El . } Example-4: Annotation of a set of links in the Lenticular Lens. Generic Metadata. The linkset ex:heroes-Identity is presented with both generic and specific metadata. The generic metadata in the default graph (triple without a specific named graph) conveys information about the identity set: ex:heroes-Identity . This information includes among other, the type, subjects, license, description, format, number of triples (9), number of distinct entities (12), number of identity clusters (3)\u2026 As stated in the generic metadata of ex:heroes-Identity , the linkset contains 9 triples. Of these triples, the metadata informs us that 7 are validated as accepted, one as rejected and another one as remains (not validated). ex: heroes-Identity a void: Linkset ; dcterms: description \"Identifying Marvel's superheroes\" ; dcterms: license law: odc-public-domain-dedication-and-licence ; dcterms: subject <http://example.org/resource/Person> ; dcterms: subject <http://example.org/resource/Hero> ; void: subjectsTarget dataset: Fictive-Persons ; void: objectsTarget dataset: Superheroes ; void: feature format: Turtle ; void: linkPredicate owl: sameAs ; void: triples 9 ; void: entities 12 ; void: distinctSubjects 3 ; void: distinctObjects 9 ; voidPlus: clusters 3 ; validation: count 8 ; validation: accepted 7 ; validation: rejected 1 ; validation: remains 1 ;","title":"1.2 Generic Metadata"},{"location":"09.LinkExport/#13-complete-metadata","text":"Example-3 illustrates the complete structure of linksets and lenses in the Lenticular Lens . Here, by default, a linkset/lens is annotated with both, generic and specific metadata. Example 5: Complete metadata in RDF* turtle syntax annotation. ex: heroes-Identity a void: Linkset ; dcterms: description \"Identifying Marvel's superheroes\" ; dcterms: license law: odc-public-domain-dedication-and-licence ; dcterms: subject <http://example.org/resource/Person> ; dcterms: subject <http://example.org/resource/Hero> ; void: subjectsTarget dataset: Fictive-Persons ; void: objectsTarget dataset: Superheroes ; void: feature format: Turtle ; void: linkPredicate owl: sameAs ; void: triples 9 ; void: entities 12 ; void: distinctSubjects 3 ; void: distinctObjects 9 ; voidPlus: clusters 3 ; validation: count 8 ; validation: accepted 7 ; validation: rejected 1 ; validation: remains 1 ; ex: heroes-Identity { << hero: BlackWidow owl: sameAs person: Nat >> validation: status \"True\" . << hero: BlackWidow owl: sameAs person: Romanoff >> validation: status \"True\" . << hero: BlackWidow owl: sameAs person: Natalia-Romanova >> validation: status \"True\" . << hero: BlackWidow owl: sameAs person: Natasha >> validation: status \"True\" . << hero: Spiderman owl: sameAs person: Peter-parker >> validation: status \"True\" . << hero: Spiderman owl: sameAs person: Tom-Holland >> validation: status \"False\" . validation: Rational \"Tom-Holland does not have Spiderman properties which Peter-parker (fictitious) a.k.a Spiderman has.\" . << hero: Superman owl: sameAs person: Clark-Kent >> validation: status \"True\" . << hero: Superman owl: sameAs person: Joseph >> validation: status \"True\" . hero: Superman owl: sameAs person: Kal-El . } Separation of Concern. The linkset and lens presentation enable separation of concern in the sense that it provides the user with a number of options: Flat Representation: No reified triples and optionally within a named graph. Partial Representation: Choice of exclusively including either the generic or the specific metadata. Full Representation: as intended in the Lenticular Lens , set of links comes along with its generic and specific metadata if applicable.","title":"1.3 Complete Metadata"},{"location":"09.LinkExport/#2-rdf-link-reifications","text":"The verb reify is defined in Lexico , the Oxford supported dictionary, as a way to make (something abstract) more concrete or real . In RDF \u2013 a data model that allows for the description of a resource (subject position of a triple) in the form \u27e8 subject predicate object. \u27e9 \\lang \\text{subject predicate object.} \\rang \u27e8 subject predicate object. \u27e9 \u2013, reification offers means to define a triple as a resource as such that the triple could be described . Several reification approaches exist: N-ary relations, RDF reification, Rdfstar and Singleton properties. In the next subsections we briefly describe them.","title":"2. RDF Link Reifications"},{"location":"09.LinkExport/#21-n-ary-relations","text":"The [ N-ary relations ] syntax provides a means to model a non binary relation, a relation that holds among more than two objects, as an object itself. Example 6: The Purchase relation into an N-ary relations. : Purchase_1 a : Purchase ; : has_buyer : John ; : has_object : Lenny_The_Lion ; : has_purpose : Birthday_Gift ; : has_amount 15 ; : has_seller : books . example . com .","title":"2.1 N-ary relations"},{"location":"09.LinkExport/#22-standard-reification","text":"RDF reification is the standard reification proposed by W3C . As depicted in Example-6, it introduces a new resource of type rdf:Statement and three predicates to identify the rdf:subject, rdf:predicate, and rdf:object of the reified triple. Example 7: Standard RDF reification. ### BlackWidow Triple. hero: BlackWidow owl: sameAs person: Nat . ### Standard RDF reification of BlackWidow Triple ex: reification-1 rdf: type rdf: Statement ; rdf: subject hero: BlackWidow ; rdf: predicate owl: sameAs ; rdf: object person: Nat ; validation: status \"True\" .","title":"2.2 Standard reification"},{"location":"09.LinkExport/#23-singleton","text":"The [ Singleton properties ] approach offers the latitude to make uniquely identifiable the predicate of the triple to reified where the new property is an rdf:singletonPropertyOf a more generic property Example 8: Singleton. ### BlackWidow Triple. hero: BlackWidow owl: sameAs person: Nat . ### Modification of BlackWidow Triple. hero: BlackWidow singleton: sameAs-1 person: Nat . ### Singleton reification of BlackWidow Triple. singleton: sameAs-1 rdf: type rdf: SingletonProperty ; rdf: singletonPropertyOf owl: sameAs . validation: status \"True\" .","title":"2.3 Singleton"},{"location":"09.LinkExport/#24-rdfstar","text":"RDF * : An in-line simple reification syntax that requires RDF * and SPARQL * . Example 9: RDFstar / RDF * . ### BlackWidow Triple. hero: BlackWidow owl: sameAs person: Nat . ### RDFstar reification BlackWidow Triple. << hero: BlackWidow owl: sameAs person: Nat >> validation: status \"True\" .","title":"2.4 RDFstar"},{"location":"09.LinkExport/#3-export-formats","text":"The Lenticular Lens offers a variety of four file formats for exporting a collection of links. These are: CSV (Example-10), JSON-LD (Example-11), RDF Turtle (Example-12), and RDF* Turtle (Example-13).","title":"3. Export Formats"},{"location":"09.LinkExport/#31-csv-file-format","text":"In our attend to export a linkset/lens with its complete metadata, in a CSV format, the Lenticular Lens generates two CSV tables. As available in Example-9, the first table is an illustration of a linkset generic metadata while the second table is an illustration of links with specific metadata (annotated triples). Example 10: Linkset in a CSV format. Keep in mind that the table below are a visual representation of a CSV table -------------------- -- METADATA TABLE -- -------------------- --------------------------------------------------------------------------------------------------------- | Vocabulary Value | --------------------------------------------------------------------------------------------------------- http : //www . w 3 . org/ns/sparql-service-description #namedGraph http://example.org/#heroesIdentity http : //www . w 3 . org/ 1999 / 02 / 22 -rdf-syntax-ns #type http://rdfs.org/ns/void#Linkset http : //purl . org/dc/terms/description Identifying Marvel 's superheroes http : //purl . org/dc/terms/license law: odc-public-domain-dedication-and-licence http : //purl . org/dc/terms/subject http : //example . org/resource/Person http : //purl . org/dc/terms/subject http : //example . org/resource/Hero http : //rdfs . org/ns/void #subjectsTarget dataset:Fictive-Persons http : //rdfs . org/ns/void #objectsTarget dataset:Superheroes http : //rdfs . org/ns/void #feature format:Turtle http : //rdfs . org/ns/void #linkPredicate owl:sameAs http : //rdfs . org/ns/void #triples 9 http : //rdfs . org/ns/void #entities 12 http : //rdfs . org/ns/void #distinctSubjects 3 http : //rdfs . org/ns/void #distinctObjects 9 http : //vocabulary/voidPlus #clusters 3 http : //vocabulary/validation #count 8 http : //vocabulary/validation #accepted 7 http : //vocabulary/validation #rejected 1 http : //vocabulary/validation #remains 1 ------------------------ -- LINKSET/LENS TABLE -- ------------------------ ------------------------------------------------------------------------------------------------------------------------------------------------ | NamedGraph Source Target ValStatus ValRational | ------------------------------------------------------------------------------------------------------------------------------------------------ http : //example . org/ #heroesIdentity http://example.org/hero#BlackWidow http://example.org/person#Nat True http : //example . org/ #heroesIdentity http://example.org/hero#BlackWidow http://example.org/person#Romanoff True http : //example . org/ #heroesIdentity http://example.org/hero#BlackWidow http://example.org/person#Natalia-Romanova True http : //example . org/ #heroesIdentity http://example.org/hero#BlackWidow http://example.org/person#Natasha True http : //example . org/ #heroesIdentity http://example.org/hero#Spiderman http://example.org/person#Peter-parker True http : //example . org/ #heroesIdentity http://example.org/hero#Spiderman http://example.org/person#Tom-Holland False Tom-Holland does not have Spiderman properties which Peter-parker (fictitious) a.k.a Spiderman has. http : //example . org/ #heroesIdentity http://example.org/hero#Superman http://example.org/person#Clark-Kent True http : //example . org/ #heroesIdentity http://example.org/hero#Superman http://example.org/person#Joseph True http : //example . org/ #heroesIdentity http://example.org/hero#Superman http://example.org/person#Kal-El True","title":"3.1 CSV file format"},{"location":"09.LinkExport/#32-json-ld-file-format","text":"JSON-LD OUTPUT. TODO.... Example 11 Linkset in a JSON-LD format.. { \"@context\" : { \"name\" : \"http://xmlns.com/foaf/0.1/name\" , \"homepage\" : { \"@id\" : \"http://xmlns.com/foaf/0.1/workplaceHomepage\" , \"@type\" : \"@id\" }, \"Person\" : \"http://xmlns.com/foaf/0.1/Person\" }, \"@id\" : \"https://me.example.com\" , \"@type\" : \"Person\" , \"name\" : \"John Smith\" , \"homepage\" : \"https://www.example.com/\" }","title":"3.2 JSON-LD file format"},{"location":"09.LinkExport/#33-rdf-file-formats","text":"Knowing the right RDF file format in which to export a collection of links depends on a number of parameters. Depending on whether the collection of links is unnamed , named and/or annotated , one can respectively have the export output in Turtle or Trig . A Trig file implies a named graph but it says little about the reification approach taken for annotating individual triples or the graph of collection. In the event of annotation, one can choose whether to go for an RDF standard reification , singleton properties or RDFstar . In this pile of options, our choice goes for always having a named-graph reified using the RDFstar syntax if one has RDF * and SPAQRL * in place. If not, our second option goes for singletons . Example 12: n Linkset in an RDF Turtle format using singletons. Our preference goes to an RDF* Turtle Output as illustrated in Example-6. However, because RDF* is not deployed on all triple stores, we provide the singleton, and RDF standard reification representation alternatives as well. An example of singletons in available here. ex: heroes-Identity a void: Linkset ; dcterms: description \"Identifying Marvel's heroes\" ; dcterms: license law: odc-public-domain-dedication-and-licence ; dcterms: subject <http://example.org/resource/Person> ; dcterms: subject <http://example.org/resource/Hero> ; void: subjectsTarget dataset: Fictive-Persons ; void: objectsTarget dataset: Superheroes ; void: feature format: Turtle ; void: linkPredicate owl: sameAs ; void: triples 9 ; void: entities 12 ; void: distinctSubjects 3 ; void: distinctObjects 9 ; voidPlus: clusters 3 ; validation: count 8 ; validation: accepted 7 ; validation: rejected 1 ; validation: remains 1 ; ex: heroes-Identity { hero: BlackWidow singleton: sameAs-1 person: Nat . hero: BlackWidow singleton: sameAs-2 person: Romanoff . hero: BlackWidow singleton: sameAs-3 person: Natalia-Romanova . hero: BlackWidow singleton: sameAs-4 person: Natasha . hero: Spiderman singleton: sameAs-5 person: Peter-parker . hero: Spiderman singleton: sameAs-6 person: Tom-Holland . hero: Superman singleton: sameAs-7 person: Clark-Kent . hero: Superman singleton: sameAs-8 person: Joseph . hero: Superman singleton: sameAs-9 person: Kal-El . } ex: heroes-Identity-singletons { singleton: sameAs-1 rdf: subPropertyOf owl: sameAs ; validation: status \"True\" . singleton: sameAs-2 rdf: subPropertyOf owl: sameAs ; validation: status \"True\" . singleton: sameAs-3 rdf: subPropertyOf owl: sameAs ; validation: status \"True\" . singleton: sameAs-4 rdf: subPropertyOf owl: sameAs ; validation: status \"True\" . singleton: sameAs-5 rdf: subPropertyOf owl: sameAs ; validation: status \"True\" . singleton: sameAs-1 rdf: subPropertyOf owl: sameAs ; validation: status \"True\" . singleton: sameAs-1 rdf: subPropertyOf owl: sameAs ; validation: status \"True\" . hero: Superman owl: sameAs person: Kal-El . singleton: sameAs-6 rdf: subPropertyOf owl: sameAs ; validation: status \"False\" ; validation: Rational \"Tom-Holland does not have Spiderman properties which Peter-parker (fictitious) a.k.a Spiderman has.\" . }","title":"3.3 RDF file formats"},{"location":"09.LinkExport/#4-link-restrictions","text":"Whenever links are annotated, the Lenticular Lens offers a way to take advantage of it. It provides the user with options to filter out links of no interest, an alternative to the inconvenience of having to download all links when not needed. Example-12 lists all possible link restrictions options. For example to make sure that only accepted links are exported, the options Accepted is chosen in Example-12. Example 13: Link Restrictions Options. All : Export all links Accepted : Export only accepted links. Rejected : Export only rejected links. Validated : Export rejected or validated links Not Validated : Export links with no accepted or rejected annotation. Threshold : Export links that pass a predefined threshold condition. This feature applies to links annotated with confidence values.","title":"4. Link Restrictions"},{"location":"09.LinkExport/#5-default-export-table","text":"Example-14 summarises the various options for exporting a linkset or lens. In each set of selection category, a default selection is checked in. This means that, by default, an exported linkset or lens comes along with all its links and its complete annotation in a CSV format . Example 13: Export Table. METADATA STRUCTURE RDF REIFICATION SYNTAX LINK EXPORT FORMAT LINK RESTRICTIONS Partial:Generic Standard RDF reification RDF Turtle-trig All Partial:Specific RDFstar RDF Turtle Accepted Singleton JSON-LD Rejected CSV Validated Not Validated Threshold","title":"5. Default Export Table"},{"location":"10.DataIntegration/","text":"DATA INTEGRATION \u00b6 The Lenticular Lens is a mean (link creation, manipulation and validation for data integration) to an end (data extraction for analysis). Here, we show how one can extract the right information for analysis given an integration model that can be achieve using existing linksets and lenses. 1. Integration Model \u00b6 2. Data Extraction \u00b6","title":"10. Data Integration"},{"location":"10.DataIntegration/#data-integration","text":"The Lenticular Lens is a mean (link creation, manipulation and validation for data integration) to an end (data extraction for analysis). Here, we show how one can extract the right information for analysis given an integration model that can be achieve using existing linksets and lenses.","title":"DATA INTEGRATION "},{"location":"10.DataIntegration/#1-integration-model","text":"","title":"1. Integration Model "},{"location":"10.DataIntegration/#2-data-extraction","text":"","title":"2. Data Extraction"},{"location":"11.Installation/","text":"Using the Lenticular Lens \u00b6 1. Installation \u00b6 To install a local version of the Lenticular Lens, follow the installation steps described below. Make sure Docker and Docker Compose are installe For Windows and Mac users : install Docker Desktop . Use the provided docker-compose.yml as a baseline. Run docker-compose Visit http://localhost:8000 in your browser Note : This will create a folder pgdata with the database data. To clean up the database and start from scratch, simply remove this folder. 2. API \u00b6 Through Github, the Lenticular Lens API is made available with a set of functions and procedures allowing for the code to be reused and/or extended .","title":"11. Using Lenticular Lens"},{"location":"11.Installation/#using-the-lenticular-lens","text":"","title":"Using the Lenticular Lens"},{"location":"11.Installation/#1-installation","text":"To install a local version of the Lenticular Lens, follow the installation steps described below. Make sure Docker and Docker Compose are installe For Windows and Mac users : install Docker Desktop . Use the provided docker-compose.yml as a baseline. Run docker-compose Visit http://localhost:8000 in your browser Note : This will create a folder pgdata with the database data. To clean up the database and start from scratch, simply remove this folder.","title":"1. Installation"},{"location":"11.Installation/#2-api","text":"Through Github, the Lenticular Lens API is made available with a set of functions and procedures allowing for the code to be reused and/or extended .","title":"2. API"},{"location":"12.References/","text":"REFERENCES \u00b6 [Euzenat2013] J. Euzenat and P. Shvaiko. Ontology matching. Springer-Verlag, Heidelberg (DE), 2 nd edition, 2013. [Idrissou2017] Idrissou, A. K. et al. (2017) \u2018Is my:sameAs the same as your:sameAs?\u2019, in Proceedings of the Knowledge Capture Conference on - K-CAP 2017. New York, New York, USA: ACM Press, pp. 1\u20138. doi: 10.1145/3148011.3148029. [Idrissou2018] Idrissou, A. K., van Harmelen, F. and van den Besselaar, P. (2018) \u2018Network metrics for assessing the quality of entity resolution between multiple datasets\u2019, in Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics). Springer Verlag, pp. 147\u2013162. doi: 10.1007/978-3-030-03667-6_10. [Idrissou2019] Idrissou, A. et al. (2019) \u2018Contextual entity disambiguation in domains with weak identity criteria: Disambiguating golden age amsterdamers\u2019, in K-CAP 2019 - Proceedings of the 10 th International Conference on Knowledge Capture. Association for Computing Machinery, Inc, pp. 259\u2013262. doi: 10.1145/3360901.3364440. [LINKED DATA] T. Berners-Lee. Linked Data \u2013 Design issues. 27 July 2006. URL: https://www.w3.org/DesignIssues/LinkedData.html [Nguyen2014] Nguyen, V., Bodenreider, O., & Sheth, A. (2014). Don\u2019t like RDF reification? making statements about statements using singleton property. In Proceedings of the 23 rd international conference on World wide web (pp. 759\u2013770). [N-ary Relations] Rector, A. and Noy, N. (2006) Defining N-ary Relations on the Semantic Web. Available at: https://www.w3.org/TR/2006/NOTE-swbp-n-aryRelations-20060412/ . [OpenPhacts] Batchelor, C. et al. (2014) \u2018Scientific Lenses to Support Multiple Views over Linked Chemistry Data\u2019, in. Springer International Publishing, pp. 98\u2013113. doi: 10.1007/978-3-319-11964-9_7. [RDF11-CONCEPTS] Richard Cyganiak, David Wood, Markus Lanthaler. RDF 1.1 Concepts and Abstract Syntax. W3C Recommendation, 25 February 2014. URL: http://www.w3.org/TR/2014/REC-rdf11-concepts-20140225/ . The latest edition is available at http://www.w3.org/TR/rdf11-concepts/ [RFC2141] R. Moats. URN Syntax. May 1997. RFC. URL: http://www.ietf.org/rfc/rfc2141.txt [RFC3305] M. Mealling; R. Denenberg. Report from the Joint W3C/IETF URI Planning Interest Group: Uniform Resource Identifiers (URIs), URLs, and Uniform Resource Names (URNs): Clarifications and Recommendations. August 2002. RFC. URL: http://www.ietf.org/rfc/rfc3305.txt [RFC3986] T. Berners-Lee; R. Fielding; L. Masinter. Uniform Resource Identifier (URI): Generic Syntax. January 2005. RFC. URL: http://www.ietf.org/rfc/rfc3986.txt [RFC3987] M. D\u00fcrst; M. Suignard. Internationalized Resource Identifiers (IRIs). January 2005. RFC. URL: http://www.ietf.org/rfc/rfc3987.txt [RDF * ] [VoID] K. Alexander, R. Cyganiak, M. Hausenblas, and J. Zhao. Describing LinkedDatasets with the VoID Vocabulary. Technical report, 2011. W3C Note. URL: https://www.w3.org/TR/void/ .","title":"12. References"},{"location":"12.References/#references","text":"[Euzenat2013] J. Euzenat and P. Shvaiko. Ontology matching. Springer-Verlag, Heidelberg (DE), 2 nd edition, 2013. [Idrissou2017] Idrissou, A. K. et al. (2017) \u2018Is my:sameAs the same as your:sameAs?\u2019, in Proceedings of the Knowledge Capture Conference on - K-CAP 2017. New York, New York, USA: ACM Press, pp. 1\u20138. doi: 10.1145/3148011.3148029. [Idrissou2018] Idrissou, A. K., van Harmelen, F. and van den Besselaar, P. (2018) \u2018Network metrics for assessing the quality of entity resolution between multiple datasets\u2019, in Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics). Springer Verlag, pp. 147\u2013162. doi: 10.1007/978-3-030-03667-6_10. [Idrissou2019] Idrissou, A. et al. (2019) \u2018Contextual entity disambiguation in domains with weak identity criteria: Disambiguating golden age amsterdamers\u2019, in K-CAP 2019 - Proceedings of the 10 th International Conference on Knowledge Capture. Association for Computing Machinery, Inc, pp. 259\u2013262. doi: 10.1145/3360901.3364440. [LINKED DATA] T. Berners-Lee. Linked Data \u2013 Design issues. 27 July 2006. URL: https://www.w3.org/DesignIssues/LinkedData.html [Nguyen2014] Nguyen, V., Bodenreider, O., & Sheth, A. (2014). Don\u2019t like RDF reification? making statements about statements using singleton property. In Proceedings of the 23 rd international conference on World wide web (pp. 759\u2013770). [N-ary Relations] Rector, A. and Noy, N. (2006) Defining N-ary Relations on the Semantic Web. Available at: https://www.w3.org/TR/2006/NOTE-swbp-n-aryRelations-20060412/ . [OpenPhacts] Batchelor, C. et al. (2014) \u2018Scientific Lenses to Support Multiple Views over Linked Chemistry Data\u2019, in. Springer International Publishing, pp. 98\u2013113. doi: 10.1007/978-3-319-11964-9_7. [RDF11-CONCEPTS] Richard Cyganiak, David Wood, Markus Lanthaler. RDF 1.1 Concepts and Abstract Syntax. W3C Recommendation, 25 February 2014. URL: http://www.w3.org/TR/2014/REC-rdf11-concepts-20140225/ . The latest edition is available at http://www.w3.org/TR/rdf11-concepts/ [RFC2141] R. Moats. URN Syntax. May 1997. RFC. URL: http://www.ietf.org/rfc/rfc2141.txt [RFC3305] M. Mealling; R. Denenberg. Report from the Joint W3C/IETF URI Planning Interest Group: Uniform Resource Identifiers (URIs), URLs, and Uniform Resource Names (URNs): Clarifications and Recommendations. August 2002. RFC. URL: http://www.ietf.org/rfc/rfc3305.txt [RFC3986] T. Berners-Lee; R. Fielding; L. Masinter. Uniform Resource Identifier (URI): Generic Syntax. January 2005. RFC. URL: http://www.ietf.org/rfc/rfc3986.txt [RFC3987] M. D\u00fcrst; M. Suignard. Internationalized Resource Identifiers (IRIs). January 2005. RFC. URL: http://www.ietf.org/rfc/rfc3987.txt [RDF * ] [VoID] K. Alexander, R. Cyganiak, M. Hausenblas, and J. Zhao. Describing LinkedDatasets with the VoID Vocabulary. Technical report, 2011. W3C Note. URL: https://www.w3.org/TR/void/ .","title":"REFERENCES"},{"location":"Menu/","text":"3. THE LENTICULAR LENS MENUS \u00b6 As a preview of what can be done with the Lenticular Lens tool, we list here the main menus composing the tool and provide a brief description of what can be done in each of the menu. RESEARCH. In this menu, we illustrates how to defined the scope of a research. SELECT. In this menu, we illustrates how to: Use the default Golden Agent\u2019s endpoint or to provide other GraphQL locations so that remote datasources can be located and made available to the user; Select (datasources and data-types) from the available list of datasources at the remote location so that data can be integrated and vital information can be extracted in order to conduct our experiment; Define restrictions over selected entity-types. CREATE. In this menu, we show how to use and combine resolution methods. MANIPULATE. In this menu, we show how to apply set like operations (Union, Intersection, Difference, Composition and In-Set) over linksets and lenses. VALIDATE. In this menu, we show how to validate existing links (accept, reject, validation rational) for analysis or method accuracy. We also show in this menu how to use the visualisation feature to ease to some extent the validation task. EXPORT. This menu illustrates the reach options supporting the export of a linkset or lens. EXTRACT. In this last menu, we show how the user can materialise the entity-based integration of her selected datasource for the extraction of information vital to her analysis. The rest of the manual will first discuss LINK CONSTRUCTION (it includes the RESEARCH , SELECT and CREATE options), then LINK MANIPULATION (it includes the MANIPULATE , and VALIDATION options), followed by LINK EXPORT (it is about the EXPORT option) and finally INTEGRATION MODEL (it is about the EXTRACT option).","title":"<span style=\"color:purple\"> 3. THE LENTICULAR LENS MENUS </span>"},{"location":"Menu/#3-the-lenticular-lens-menus","text":"As a preview of what can be done with the Lenticular Lens tool, we list here the main menus composing the tool and provide a brief description of what can be done in each of the menu. RESEARCH. In this menu, we illustrates how to defined the scope of a research. SELECT. In this menu, we illustrates how to: Use the default Golden Agent\u2019s endpoint or to provide other GraphQL locations so that remote datasources can be located and made available to the user; Select (datasources and data-types) from the available list of datasources at the remote location so that data can be integrated and vital information can be extracted in order to conduct our experiment; Define restrictions over selected entity-types. CREATE. In this menu, we show how to use and combine resolution methods. MANIPULATE. In this menu, we show how to apply set like operations (Union, Intersection, Difference, Composition and In-Set) over linksets and lenses. VALIDATE. In this menu, we show how to validate existing links (accept, reject, validation rational) for analysis or method accuracy. We also show in this menu how to use the visualisation feature to ease to some extent the validation task. EXPORT. This menu illustrates the reach options supporting the export of a linkset or lens. EXTRACT. In this last menu, we show how the user can materialise the entity-based integration of her selected datasource for the extraction of information vital to her analysis. The rest of the manual will first discuss LINK CONSTRUCTION (it includes the RESEARCH , SELECT and CREATE options), then LINK MANIPULATION (it includes the MANIPULATE , and VALIDATION options), followed by LINK EXPORT (it is about the EXPORT option) and finally INTEGRATION MODEL (it is about the EXTRACT option).","title":" 3. THE LENTICULAR LENS MENUS "}]}